# Hypothesis Testing
## The Scientific Method of Statistical Decision Making ğŸ”¬

---

## The Art of Making Decisions with Data

Every day, we face questions that require evidence-based decisions:

- Does this new medicine actually work?
- Is this coin fair or biased?
- Did the marketing campaign increase sales?
- Is the factory producing defective products?

**Hypothesis Testing** is the formal statistical framework for answering such questions using data.

---

## ğŸ“– Story: The Suspicious Coin

Karim suspects his friend's coin is biased. He flips it 100 times and gets **65 heads**.

**The Question:** Is this enough evidence to conclude the coin is unfair?

- If the coin is fair, we'd expect about 50 heads
- But 65 seems high... is it "too high" to be just luck?
- Or could a fair coin reasonably produce 65 heads?

**This is exactly the kind of question hypothesis testing answers!**

---

## What is Hypothesis Testing?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚              HYPOTHESIS TESTING                              â”‚
â”‚                                                             â”‚
â”‚   A formal procedure for using sample data to evaluate      â”‚
â”‚   a claim (hypothesis) about a population parameter.        â”‚
â”‚                                                             â”‚
â”‚   Key Idea:                                                 â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€                                                 â”‚
â”‚   We assume the claim is TRUE, then check if our data       â”‚
â”‚   is consistent with that assumption.                       â”‚
â”‚                                                             â”‚
â”‚   If the data is VERY UNLIKELY under the assumption,        â”‚
â”‚   we REJECT the claim.                                      â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## The Two Hypotheses

Every hypothesis test involves two competing claims:

### The Null Hypothesis (Hâ‚€)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   NULL HYPOTHESIS (Hâ‚€)                                       â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                      â”‚
â”‚                                                             â”‚
â”‚   â€¢ The "default" or "status quo" claim                     â”‚
â”‚   â€¢ Usually states "no effect" or "no difference"           â”‚
â”‚   â€¢ What we assume is TRUE unless proven otherwise          â”‚
â”‚   â€¢ Contains an equality (=, â‰¤, or â‰¥)                       â”‚
â”‚                                                             â”‚
â”‚   Examples:                                                 â”‚
â”‚   â€¢ Hâ‚€: The coin is fair (p = 0.5)                         â”‚
â”‚   â€¢ Hâ‚€: The drug has no effect (Î¼_treatment = Î¼_control)   â”‚
â”‚   â€¢ Hâ‚€: The mean is 100 (Î¼ = 100)                          â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### The Alternative Hypothesis (Hâ‚ or Hâ‚)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   ALTERNATIVE HYPOTHESIS (Hâ‚ or Hâ‚)                         â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                         â”‚
â”‚                                                             â”‚
â”‚   â€¢ The "research" claim we want to support                 â”‚
â”‚   â€¢ States there IS an effect or difference                 â”‚
â”‚   â€¢ What we conclude if we reject Hâ‚€                        â”‚
â”‚   â€¢ Contains inequality (â‰ , <, or >)                        â”‚
â”‚                                                             â”‚
â”‚   Examples:                                                 â”‚
â”‚   â€¢ Hâ‚: The coin is biased (p â‰  0.5)                       â”‚
â”‚   â€¢ Hâ‚: The drug has an effect (Î¼_treatment â‰  Î¼_control)   â”‚
â”‚   â€¢ Hâ‚: The mean is not 100 (Î¼ â‰  100)                      â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## The Logic of Hypothesis Testing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚              THE LOGIC (Proof by Contradiction)              â”‚
â”‚                                                             â”‚
â”‚   1. ASSUME Hâ‚€ is true                                      â”‚
â”‚                                                             â”‚
â”‚   2. CALCULATE probability of observing data this          â”‚
â”‚      extreme (or more extreme) if Hâ‚€ were true              â”‚
â”‚                                                             â”‚
â”‚   3. DECIDE:                                                â”‚
â”‚      â€¢ If probability is LOW â†’ Reject Hâ‚€ (data too rare)   â”‚
â”‚      â€¢ If probability is HIGH â†’ Fail to reject Hâ‚€          â”‚
â”‚                                                             â”‚
â”‚   It's like a court trial:                                  â”‚
â”‚   â€¢ Hâ‚€: Defendant is innocent (default assumption)          â”‚
â”‚   â€¢ Hâ‚: Defendant is guilty                                 â”‚
â”‚   â€¢ Evidence (data) is evaluated                            â”‚
â”‚   â€¢ Verdict: Guilty (reject Hâ‚€) or Not Guilty (fail to     â”‚
â”‚     reject Hâ‚€)                                              â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## The Hypothesis Testing Framework

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  State Hypotheses   â”‚
                    â”‚    Hâ‚€ and Hâ‚        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Choose Significance â”‚
                    â”‚   Level (Î±)         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ Select Appropriate  â”‚
                    â”‚   Test Statistic    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Collect Data and   â”‚
                    â”‚ Calculate Statistic â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Calculate p-value  â”‚
                    â”‚  or Critical Value  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Make Decision     â”‚
                    â”‚ Reject or Fail to   â”‚
                    â”‚    Reject Hâ‚€        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ State Conclusion in â”‚
                    â”‚      Context        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Step 1: State the Hypotheses

### Types of Alternative Hypotheses

```
TWO-TAILED TEST (â‰ )                 
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  
Hâ‚€: Î¼ = Î¼â‚€                          
Hâ‚: Î¼ â‰  Î¼â‚€                          
                                    
"Is there ANY difference?"          

         â•­â”€â”€â”€â•®
       â•­â”€â•¯   â•°â”€â•®
      â•­â•¯       â•°â•®
     â–ˆâ•¯         â•°â–ˆ    â† Rejection regions
    â–ˆâ•¯           â•°â–ˆ      on BOTH sides
   â–ˆâ•¯             â•°â–ˆ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        Î¼â‚€


LEFT-TAILED TEST (<)                RIGHT-TAILED TEST (>)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Hâ‚€: Î¼ â‰¥ Î¼â‚€                          Hâ‚€: Î¼ â‰¤ Î¼â‚€
Hâ‚: Î¼ < Î¼â‚€                          Hâ‚: Î¼ > Î¼â‚€

"Is it LESS than?"                  "Is it GREATER than?"

         â•­â”€â”€â”€â•®                               â•­â”€â”€â”€â•®
       â•­â”€â•¯   â•°â”€â•®                           â•­â”€â•¯   â•°â”€â•®
      â•­â•¯       â•°â•®                         â•­â•¯       â•°â•®
     â–ˆâ•¯         â•°â•®                       â•­â•¯         â•°â–ˆ
    â–ˆâ•¯           â•°â•®                     â•­â•¯           â•°â–ˆ
   â–ˆâ•¯             â•°â•®                   â•­â•¯             â•°â–ˆ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        Î¼â‚€                                Î¼â‚€

Rejection on LEFT                   Rejection on RIGHT
```

### Choosing the Right Test

| Research Question | Hâ‚€ | Hâ‚ | Test Type |
|-------------------|----|----|-----------|
| Is there any difference? | Î¼ = Î¼â‚€ | Î¼ â‰  Î¼â‚€ | Two-tailed |
| Is it greater? | Î¼ â‰¤ Î¼â‚€ | Î¼ > Î¼â‚€ | Right-tailed |
| Is it less? | Î¼ â‰¥ Î¼â‚€ | Î¼ < Î¼â‚€ | Left-tailed |

---

## Step 2: Choose Significance Level (Î±)

The **significance level (Î±)** is the probability of rejecting Hâ‚€ when it's actually true (false positive rate).

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   SIGNIFICANCE LEVEL (Î±)                                     â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                    â”‚
â”‚                                                             â”‚
â”‚   Common values:                                            â”‚
â”‚   â€¢ Î± = 0.05 (5%)  â€” Most common, "statistically           â”‚
â”‚                       significant"                          â”‚
â”‚   â€¢ Î± = 0.01 (1%)  â€” More stringent                        â”‚
â”‚   â€¢ Î± = 0.10 (10%) â€” More lenient                          â”‚
â”‚   â€¢ Î± = 0.001      â€” Very stringent (particle physics)     â”‚
â”‚                                                             â”‚
â”‚   Î± determines:                                             â”‚
â”‚   â€¢ How much evidence we need to reject Hâ‚€                 â”‚
â”‚   â€¢ The probability of Type I error                        â”‚
â”‚   â€¢ The critical value(s) for our test                     â”‚
â”‚                                                             â”‚
â”‚   Smaller Î± = Harder to reject Hâ‚€ = More conservative      â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### How Î± Affects the Test

```
Î± = 0.10 (Lenient)          Î± = 0.05 (Standard)         Î± = 0.01 (Strict)

      â•­â”€â”€â”€â•®                       â•­â”€â”€â”€â•®                       â•­â”€â”€â”€â•®
    â•­â”€â•¯   â•°â”€â•®                   â•­â”€â•¯   â•°â”€â•®                   â•­â”€â•¯   â•°â”€â•®
   â•­â•¯       â•°â•®                 â•­â•¯       â•°â•®                 â•­â•¯       â•°â•®
  â–ˆâ•¯         â•°â–ˆ               â–ˆâ•¯         â•°â–ˆ               â–ˆâ•¯         â•°â–ˆ
 â–ˆâ–ˆâ•¯         â•°â–ˆâ–ˆ             â–ˆâ•¯           â•°â–ˆ             â–ˆâ•¯           â•°â–ˆ
â–ˆâ–ˆâ–ˆ           â–ˆâ–ˆâ–ˆ           â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€                 Î¼â‚€                          Î¼â‚€
        Î¼â‚€
                            
Large rejection             Medium rejection            Small rejection
regions (easy to reject)    regions                     regions (hard to reject)
```

---

## Step 3: Select the Test Statistic

A **test statistic** measures how far our sample result is from what Hâ‚€ predicts.

### Common Test Statistics

| Situation | Test | Statistic | Distribution |
|-----------|------|-----------|--------------|
| Mean (Ïƒ known) | Z-test | Z = (XÌ„ - Î¼â‚€)/(Ïƒ/âˆšn) | Standard Normal |
| Mean (Ïƒ unknown) | t-test | t = (XÌ„ - Î¼â‚€)/(s/âˆšn) | t with df = n-1 |
| Proportion | Z-test | Z = (pÌ‚ - pâ‚€)/âˆš(pâ‚€(1-pâ‚€)/n) | Standard Normal |
| Variance | Chi-square | Ï‡Â² = (n-1)sÂ²/Ïƒâ‚€Â² | Chi-square |
| Two means | t-test | t = (XÌ„â‚ - XÌ„â‚‚)/SE | t distribution |
| Independence | Chi-square | Ï‡Â² = Î£(O-E)Â²/E | Chi-square |

### The General Form

```
                 Sample Statistic - Hypothesized Value
Test Statistic = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                      Standard Error of Statistic

         Î¸Ì‚ - Î¸â‚€
    Z = â”€â”€â”€â”€â”€â”€â”€â”€â”€
         SE(Î¸Ì‚)
```

---

## Step 4: Calculate the Test Statistic

### ğŸ“– Back to the Coin Example

Karim got 65 heads in 100 flips. Is the coin biased?

**Setup:**
```
Hâ‚€: p = 0.5 (coin is fair)
Hâ‚: p â‰  0.5 (coin is biased)
Î± = 0.05

Sample: n = 100, pÌ‚ = 65/100 = 0.65
```

**Calculate Test Statistic:**
```
       pÌ‚ - pâ‚€              0.65 - 0.50
Z = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    âˆš(pâ‚€(1-pâ‚€)/n)       âˆš(0.5 Ã— 0.5 / 100)

       0.15           0.15
Z = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ = â”€â”€â”€â”€â”€â”€â”€ = 3.0
    âˆš(0.25/100)       0.05
```

**Result: Z = 3.0**

This means our sample proportion is **3 standard errors away** from what we'd expect if the coin were fair!

---

## Step 5: Calculate the p-value

The **p-value** is the probability of observing data as extreme as (or more extreme than) what we got, assuming Hâ‚€ is true.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   p-value = P(observing this extreme result | Hâ‚€ is true)  â”‚
â”‚                                                             â”‚
â”‚   Small p-value â†’ Data is unlikely under Hâ‚€                â”‚
â”‚                 â†’ Evidence against Hâ‚€                       â”‚
â”‚                                                             â”‚
â”‚   Large p-value â†’ Data is consistent with Hâ‚€               â”‚
â”‚                 â†’ No strong evidence against Hâ‚€             â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Visualizing p-value

```
For Z = 3.0 (two-tailed test):

p-value = P(|Z| â‰¥ 3.0) = P(Z â‰¤ -3.0) + P(Z â‰¥ 3.0)

                    â•­â”€â”€â”€â•®
                  â•­â”€â•¯   â•°â”€â•®
                 â•­â•¯       â•°â•®
                â•­â•¯         â•°â•®
              â•­â”€â•¯           â•°â”€â•®
          â–ˆâ–ˆâ–ˆâ•¯               â•°â–ˆâ–ˆâ–ˆ     â† Shaded areas
         â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€       = p-value
            -3       0       3
            
p-value = 2 Ã— 0.00135 = 0.0027 = 0.27%

Very small! Only 0.27% chance of getting 65+ or 35- heads
if the coin were truly fair!
```

### p-value for Different Test Types

```
LEFT-TAILED:               TWO-TAILED:                RIGHT-TAILED:
p = P(Z â‰¤ z_obs)           p = 2 Ã— P(Z â‰¥ |z_obs|)     p = P(Z â‰¥ z_obs)

     â•­â”€â”€â”€â•®                      â•­â”€â”€â”€â•®                      â•­â”€â”€â”€â•®
   â•­â”€â•¯   â•°â”€â•®                  â•­â”€â•¯   â•°â”€â•®                  â•­â”€â•¯   â•°â”€â•®
  â•­â•¯       â•°â•®                â•­â•¯       â•°â•®                â•­â•¯       â•°â•®
 â•­â•¯         â•°â•®              â•­â•¯         â•°â•®              â•­â•¯         â•°â•®
â–ˆâ•¯           â•°â•®            â–ˆâ•¯           â•°â–ˆ            â•­â•¯           â•°â–ˆ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      z_obs                -|z|       |z|                  z_obs
```

---

## Step 6: Make a Decision

### Decision Rule

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   THE DECISION RULE                                          â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                         â”‚
â”‚                                                             â”‚
â”‚   If p-value â‰¤ Î±:  REJECT Hâ‚€                                â”‚
â”‚                    "Statistically significant"               â”‚
â”‚                    "Evidence supports Hâ‚"                   â”‚
â”‚                                                             â”‚
â”‚   If p-value > Î±:  FAIL TO REJECT Hâ‚€                        â”‚
â”‚                    "Not statistically significant"          â”‚
â”‚                    "Insufficient evidence against Hâ‚€"       â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### For Our Coin Example

```
p-value = 0.0027
Î± = 0.05

Since 0.0027 < 0.05:

DECISION: REJECT Hâ‚€

CONCLUSION: There is statistically significant evidence
that the coin is biased (p = 0.0027).
```

---

## Alternative Approach: Critical Values

Instead of p-values, we can use **critical values** to define rejection regions.

### Critical Value Method

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   CRITICAL VALUE METHOD                                      â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚                                                             â”‚
â”‚   1. Find critical value(s) that cut off Î± in the tails    â”‚
â”‚   2. Compare test statistic to critical value              â”‚
â”‚   3. If test statistic is in rejection region â†’ Reject Hâ‚€  â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Critical Values for Common Î± Levels

| Î± | Two-tailed (z*) | One-tailed (z*) |
|---|-----------------|-----------------|
| 0.10 | Â±1.645 | Â±1.28 |
| 0.05 | Â±1.96 | Â±1.645 |
| 0.01 | Â±2.576 | Â±2.33 |
| 0.001 | Â±3.29 | Â±3.09 |

### Visual: Rejection Regions

```
Two-tailed test, Î± = 0.05:

                        â•­â”€â”€â”€â•®
                      â•­â”€â•¯   â•°â”€â•®
                     â•­â•¯       â•°â•®
                    â•­â•¯         â•°â•®
                   â•­â•¯           â•°â•®
              â–ˆâ–ˆâ–ˆâ–ˆâ•­â•¯             â•°â•®â–ˆâ–ˆâ–ˆâ–ˆ
             â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•¯               â•°â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
         â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€
            -1.96         0         1.96
              â”‚                       â”‚
              â”‚    FAIL TO REJECT     â”‚
              â”‚                       â”‚
        REJECTâ”‚                       â”‚REJECT
         Hâ‚€   â”‚                       â”‚  Hâ‚€
         
If |Z| > 1.96 â†’ Reject Hâ‚€
Our Z = 3.0 > 1.96 â†’ REJECT Hâ‚€ âœ“
```

---

## Step 7: State the Conclusion

### Writing a Proper Conclusion

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   A GOOD CONCLUSION INCLUDES:                                â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                               â”‚
â”‚                                                             â”‚
â”‚   1. Decision (Reject or Fail to Reject Hâ‚€)                 â”‚
â”‚   2. Significance level used                                â”‚
â”‚   3. Context-specific interpretation                        â”‚
â”‚   4. p-value (or test statistic)                           â”‚
â”‚                                                             â”‚
â”‚   Example:                                                  â”‚
â”‚   "At the Î± = 0.05 significance level, we reject Hâ‚€.       â”‚
â”‚    There is statistically significant evidence that the     â”‚
â”‚    coin is biased (Z = 3.0, p = 0.0027)."                  â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Important Language

| Say This | NOT This |
|----------|----------|
| "Fail to reject Hâ‚€" | "Accept Hâ‚€" |
| "Evidence against Hâ‚€" | "Proved Hâ‚" |
| "Statistically significant" | "Definitely true" |
| "Suggests" or "indicates" | "Proves" |

---

## Type I and Type II Errors

### The Two Types of Mistakes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚                    TRUTH (Unknown)                          â”‚
â”‚                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚                 â”‚   Hâ‚€ True   â”‚  Hâ‚€ False   â”‚               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤               â”‚
â”‚   â”‚ Reject Hâ‚€   â”‚  TYPE I     â”‚  CORRECT    â”‚               â”‚
â”‚ D â”‚             â”‚  ERROR (Î±)  â”‚  (Power)    â”‚               â”‚
â”‚ E â”‚             â”‚ False       â”‚  True       â”‚               â”‚
â”‚ C â”‚             â”‚ Positive    â”‚  Positive   â”‚               â”‚
â”‚ I â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤               â”‚
â”‚ S â”‚ Fail to     â”‚  CORRECT    â”‚  TYPE II    â”‚               â”‚
â”‚ I â”‚ Reject Hâ‚€   â”‚  (1-Î±)      â”‚  ERROR (Î²)  â”‚               â”‚
â”‚ O â”‚             â”‚  True       â”‚  False      â”‚               â”‚
â”‚ N â”‚             â”‚  Negative   â”‚  Negative   â”‚               â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Understanding the Errors

```
TYPE I ERROR (Î±)                    TYPE II ERROR (Î²)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â€¢ Rejecting Hâ‚€ when Hâ‚€ is TRUE      â€¢ Failing to reject Hâ‚€ when Hâ‚€
â€¢ "False Positive"                     is FALSE
â€¢ "False Alarm"                      â€¢ "False Negative"
â€¢ "Convicting an innocent person"    â€¢ "Missing the effect"
                                     â€¢ "Letting a guilty person go free"

P(Type I Error) = Î±                  P(Type II Error) = Î²

We CONTROL Î± (we choose it)          Î² depends on:
                                     â€¢ Sample size (n)
                                     â€¢ Effect size
                                     â€¢ Î± level
                                     â€¢ Variability
```

### Real-World Examples

| Context | Hâ‚€ | Type I Error | Type II Error |
|---------|----|--------------| --------------|
| Medical Test | No disease | Diagnosing disease when healthy | Missing actual disease |
| Court Trial | Innocent | Convicting innocent | Acquitting guilty |
| Quality Control | Product OK | Rejecting good batch | Accepting bad batch |
| Drug Trial | Drug doesn't work | Approving ineffective drug | Rejecting effective drug |

### The Error Tradeoff

```
                    Î± (Type I)
                         â–²
                         â”‚
                     â”Œâ”€â”€â”€â”´â”€â”€â”€â”
                     â”‚       â”‚
              High Î± â”‚       â”‚ Low Î±
            Low Î²    â”‚       â”‚ High Î²
            (Good    â”‚       â”‚ (Poor
             Power)  â”‚       â”‚  Power)
                     â”‚       â”‚
                     â””â”€â”€â”€â”¬â”€â”€â”€â”˜
                         â”‚
                         â–¼
                    Î² (Type II)

As Î± decreases â†’ Î² increases (and vice versa)
The only way to reduce BOTH is to increase sample size!
```

---

## Power of a Test

**Power** is the probability of correctly rejecting Hâ‚€ when it's false.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   POWER = 1 - Î² = P(Reject Hâ‚€ | Hâ‚€ is false)               â”‚
â”‚                                                             â”‚
â”‚   Power tells us: "How likely are we to detect a real      â”‚
â”‚   effect if one exists?"                                    â”‚
â”‚                                                             â”‚
â”‚   Good power: â‰¥ 0.80 (80%)                                 â”‚
â”‚   Ideal power: â‰¥ 0.90 (90%)                                â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Factors Affecting Power

```
POWER INCREASES WHEN:

1. Sample size (n) increases     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                 â”‚                 â”‚
2. Effect size increases         â”‚     POWER       â”‚
                                 â”‚     = 1 - Î²     â”‚
3. Î± increases                   â”‚                 â”‚
                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
4. Variability (Ïƒ) decreases

5. One-tailed test (vs two-tailed)
```

### Visual: Power and Effect Size

```
Hâ‚€ Distribution          Hâ‚ Distribution (True)
(Under null)             (Effect exists)

       â•­â”€â”€â”€â•®                    â•­â”€â”€â”€â•®
     â•­â”€â•¯   â•°â”€â•®                â•­â”€â•¯   â•°â”€â•®
    â•­â•¯       â•°â•®              â•­â•¯       â•°â•®
   â•­â•¯         â•°â•®            â•­â•¯    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•°â•®
  â•­â•¯           â•°â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•­â•¯     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â•°â•®
 â•­â•¯            â”‚â•°â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•­â•¯      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   â•°â•®
â•¯              â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ•°â•¯        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    â•°
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”€â”€â”€â”€â”€
              Î¼â‚€          â”‚      Î¼â‚
               â”‚          â”‚
               â”‚  Criticalâ”‚
               â”‚  Value   â”‚
               â”‚          â”‚
        Î²      â”‚          â”‚   Power = 1-Î²
  (Type II     â”‚          â”‚   (Correct
   Error)      â”‚          â”‚    Rejection)
```

---

## Effect Size

**Effect Size** measures the magnitude of the difference, independent of sample size.

### Why Effect Size Matters

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   Statistical significance â‰  Practical importance!          â”‚
â”‚                                                             â”‚
â”‚   With large n, even TINY differences can be significant.  â”‚
â”‚   With small n, even LARGE differences may not be.         â”‚
â”‚                                                             â”‚
â”‚   Effect size tells us: "How BIG is the effect?"           â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Common Effect Size Measures

#### Cohen's d (for means)

```
        XÌ„ - Î¼â‚€       Mean Difference
d = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          s        Standard Deviation

Interpretation:
â€¢ |d| < 0.2:  Small effect
â€¢ |d| â‰ˆ 0.5:  Medium effect
â€¢ |d| > 0.8:  Large effect
```

#### Correlation (r)

```
r = correlation between variables

Interpretation:
â€¢ |r| < 0.1:  Small
â€¢ |r| â‰ˆ 0.3:  Medium
â€¢ |r| > 0.5:  Large
```

#### Odds Ratio and Risk Ratio

For categorical outcomes, measuring association strength.

---

## ğŸ“– Complete Example: Drug Effectiveness

A pharmaceutical company tests a new blood pressure medication.

### Step 1: State Hypotheses

```
Hâ‚€: Î¼ = 0 (no change in blood pressure)
Hâ‚: Î¼ â‰  0 (blood pressure changes)

Two-tailed test
Î± = 0.05
```

### Step 2: Collect Data

```
n = 50 patients
Mean BP change: XÌ„ = -8.5 mmHg (decrease)
Standard deviation: s = 15 mmHg
```

### Step 3: Calculate Test Statistic

```
       XÌ„ - Î¼â‚€      -8.5 - 0       -8.5
t = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ = â”€â”€â”€â”€â”€â”€â”€â”€â”€
      s/âˆšn        15/âˆš50        2.12

t = -4.01

df = n - 1 = 49
```

### Step 4: Find p-value

```
For t = -4.01 with df = 49:

p-value = 2 Ã— P(t < -4.01) â‰ˆ 0.0002
```

### Step 5: Make Decision

```
p-value = 0.0002 < Î± = 0.05

REJECT Hâ‚€
```

### Step 6: Calculate Effect Size

```
       XÌ„ - Î¼â‚€     -8.5
d = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ = â”€â”€â”€â”€â”€â”€ = -0.57
         s          15

Medium effect size (Cohen's d â‰ˆ 0.5)
```

### Step 7: Conclusion

```
"At the Î± = 0.05 significance level, we reject Hâ‚€. 
There is statistically significant evidence that the 
medication changes blood pressure (t = -4.01, p = 0.0002).

The medication reduced blood pressure by an average of 
8.5 mmHg, which represents a medium effect size (d = 0.57).
This reduction appears to be both statistically significant 
and clinically meaningful."
```

---

## Common Hypothesis Tests

### 1. One-Sample Z-Test (Ïƒ known)

```
Use when: Testing a mean with known population Ïƒ
Statistic: Z = (XÌ„ - Î¼â‚€)/(Ïƒ/âˆšn)
Distribution: Standard Normal
```

### 2. One-Sample t-Test (Ïƒ unknown)

```
Use when: Testing a mean with unknown Ïƒ
Statistic: t = (XÌ„ - Î¼â‚€)/(s/âˆšn)
Distribution: t with df = n - 1
```

### 3. Two-Sample t-Test

```
Use when: Comparing means of two independent groups
Statistic: t = (XÌ„â‚ - XÌ„â‚‚)/SE
Distribution: t with df (various formulas)
```

### 4. Paired t-Test

```
Use when: Comparing means of paired/matched samples
Statistic: t = dÌ„/(s_d/âˆšn)
Distribution: t with df = n - 1
Where dÌ„ = mean of differences
```

### 5. Z-Test for Proportion

```
Use when: Testing a population proportion
Statistic: Z = (pÌ‚ - pâ‚€)/âˆš(pâ‚€(1-pâ‚€)/n)
Distribution: Standard Normal
```

### 6. Chi-Square Test

```
Use when: Testing variance or independence
Statistic: Ï‡Â² = (n-1)sÂ²/Ïƒâ‚€Â² (variance)
           Ï‡Â² = Î£(O-E)Â²/E (independence)
Distribution: Chi-square
```

### 7. F-Test (ANOVA)

```
Use when: Comparing means of 3+ groups
Statistic: F = MS_between/MS_within
Distribution: F distribution
```

---

## Summary Table: Test Selection

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   What are you testing?          â”‚  Test to use                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ One mean (Ïƒ known)               â”‚  Z-test                       â”‚
â”‚ One mean (Ïƒ unknown)             â”‚  One-sample t-test            â”‚
â”‚ One proportion                   â”‚  Z-test for proportion        â”‚
â”‚ Two means (independent)          â”‚  Two-sample t-test            â”‚
â”‚ Two means (paired)               â”‚  Paired t-test                â”‚
â”‚ Two proportions                  â”‚  Two-proportion Z-test        â”‚
â”‚ One variance                     â”‚  Chi-square test              â”‚
â”‚ Two variances                    â”‚  F-test                       â”‚
â”‚ 3+ means                         â”‚  ANOVA (F-test)               â”‚
â”‚ Independence (categorical)       â”‚  Chi-square test              â”‚
â”‚ Correlation                      â”‚  t-test for r                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Python Implementation

### One-Sample t-Test

```python
import numpy as np
from scipy import stats

# Sample data
data = np.array([98.6, 98.4, 99.0, 98.8, 98.5, 98.9, 98.7, 98.3, 99.1, 98.6])

# Hypothesis: Is mean body temperature different from 98.6Â°F?
# Hâ‚€: Î¼ = 98.6
# Hâ‚: Î¼ â‰  98.6

mu_0 = 98.6  # Hypothesized mean
alpha = 0.05

# Perform one-sample t-test
t_stat, p_value = stats.ttest_1samp(data, mu_0)

print(f"Sample mean: {np.mean(data):.4f}")
print(f"Sample std: {np.std(data, ddof=1):.4f}")
print(f"t-statistic: {t_stat:.4f}")
print(f"p-value: {p_value:.4f}")

# Decision
if p_value < alpha:
    print(f"\nReject Hâ‚€ at Î± = {alpha}")
else:
    print(f"\nFail to reject Hâ‚€ at Î± = {alpha}")

# Effect size (Cohen's d)
d = (np.mean(data) - mu_0) / np.std(data, ddof=1)
print(f"Cohen's d: {d:.4f}")
```

### Two-Sample t-Test

```python
import numpy as np
from scipy import stats

# Two independent groups
group1 = np.array([85, 90, 88, 92, 87, 89, 91, 86, 88, 90])
group2 = np.array([78, 82, 80, 85, 79, 81, 83, 77, 80, 82])

# Hâ‚€: Î¼â‚ = Î¼â‚‚ (no difference)
# Hâ‚: Î¼â‚ â‰  Î¼â‚‚ (different means)

alpha = 0.05

# Perform two-sample t-test (assuming equal variances)
t_stat, p_value = stats.ttest_ind(group1, group2)

print(f"Group 1 mean: {np.mean(group1):.2f}")
print(f"Group 2 mean: {np.mean(group2):.2f}")
print(f"Difference: {np.mean(group1) - np.mean(group2):.2f}")
print(f"t-statistic: {t_stat:.4f}")
print(f"p-value: {p_value:.6f}")

# Decision
if p_value < alpha:
    print(f"\nReject Hâ‚€: Groups have significantly different means")
else:
    print(f"\nFail to reject Hâ‚€: No significant difference")

# Effect size (Cohen's d for two groups)
pooled_std = np.sqrt(((len(group1)-1)*np.var(group1, ddof=1) + 
                       (len(group2)-1)*np.var(group2, ddof=1)) / 
                      (len(group1) + len(group2) - 2))
d = (np.mean(group1) - np.mean(group2)) / pooled_std
print(f"Cohen's d: {d:.4f}")
```

### Z-Test for Proportion

```python
import numpy as np
from scipy import stats

# Sample data
n = 500       # Sample size
x = 280       # Number of successes
p_hat = x / n  # Sample proportion

# Hâ‚€: p = 0.5
# Hâ‚: p â‰  0.5
p_0 = 0.5
alpha = 0.05

# Calculate Z-statistic
se = np.sqrt(p_0 * (1 - p_0) / n)
z_stat = (p_hat - p_0) / se

# Calculate p-value (two-tailed)
p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))

print(f"Sample proportion: {p_hat:.4f}")
print(f"Z-statistic: {z_stat:.4f}")
print(f"p-value: {p_value:.6f}")

# Decision
if p_value < alpha:
    print(f"\nReject Hâ‚€: Proportion is significantly different from {p_0}")
else:
    print(f"\nFail to reject Hâ‚€: No significant difference from {p_0}")
```

### Chi-Square Test for Independence

```python
import numpy as np
from scipy import stats

# Contingency table
#              | Smoker | Non-smoker |
# -------------|--------|------------|
# Heart Disease|   30   |     20     |
# No Disease   |   25   |     75     |

observed = np.array([[30, 20],
                     [25, 75]])

# Hâ‚€: Smoking and heart disease are independent
# Hâ‚: They are associated

chi2, p_value, dof, expected = stats.chi2_contingency(observed)

print("Observed frequencies:")
print(observed)
print("\nExpected frequencies (under independence):")
print(expected)
print(f"\nChi-square statistic: {chi2:.4f}")
print(f"Degrees of freedom: {dof}")
print(f"p-value: {p_value:.6f}")

# Decision
alpha = 0.05
if p_value < alpha:
    print(f"\nReject Hâ‚€: Variables are associated")
else:
    print(f"\nFail to reject Hâ‚€: No significant association")
```

### Power Analysis

```python
from scipy import stats
import numpy as np

def calculate_power(n, effect_size, alpha=0.05, alternative='two-sided'):
    """
    Calculate power for a one-sample t-test
    """
    # Critical value
    if alternative == 'two-sided':
        t_crit = stats.t.ppf(1 - alpha/2, df=n-1)
    else:
        t_crit = stats.t.ppf(1 - alpha, df=n-1)
    
    # Non-centrality parameter
    ncp = effect_size * np.sqrt(n)
    
    # Power = P(reject Hâ‚€ | Hâ‚ is true)
    if alternative == 'two-sided':
        power = 1 - stats.nct.cdf(t_crit, df=n-1, nc=ncp) + \
                stats.nct.cdf(-t_crit, df=n-1, nc=ncp)
    else:
        power = 1 - stats.nct.cdf(t_crit, df=n-1, nc=ncp)
    
    return power

# Example: What power do we have to detect d = 0.5 with n = 30?
n = 30
d = 0.5
power = calculate_power(n, d)
print(f"Power with n={n}, d={d}: {power:.4f}")

# What n do we need for 80% power?
for n in range(10, 100, 5):
    power = calculate_power(n, d)
    if power >= 0.80:
        print(f"Need n â‰¥ {n} for 80% power")
        break
```

---

## Common Mistakes to Avoid âš ï¸

### Mistake 1: Accepting Hâ‚€

âŒ **Wrong:** "We accept Hâ‚€"

âœ… **Correct:** "We fail to reject Hâ‚€"

*We can never "prove" Hâ‚€ is true; we only say we don't have enough evidence against it.*

---

### Mistake 2: p-value is NOT P(Hâ‚€ is true)

âŒ **Wrong:** "p = 0.03 means 3% chance Hâ‚€ is true"

âœ… **Correct:** "p = 0.03 means 3% chance of seeing this data (or more extreme) if Hâ‚€ were true"

---

### Mistake 3: Significant â‰  Important

âŒ **Wrong:** "p < 0.05 means the effect is large"

âœ… **Correct:** Statistical significance doesn't imply practical importance. Always report effect size!

---

### Mistake 4: One-Tailed Tests to Get Significance

âŒ **Wrong:** Switching to one-tailed after seeing the data

âœ… **Correct:** Choose the test direction BEFORE seeing the data, based on research question

---

### Mistake 5: Multiple Testing Without Correction

âŒ **Wrong:** Running 20 tests at Î± = 0.05 and finding 1 "significant"

âœ… **Correct:** Use Bonferroni correction (Î±/k) or control False Discovery Rate

---

## Practice Problems ğŸ“

### Problem 1: Setting Up Hypotheses
A school claims average SAT score is 1100. You suspect it's higher. Set up the hypotheses.

<details>
<summary>Click for Answer</summary>

```
Hâ‚€: Î¼ â‰¤ 1100 (or Î¼ = 1100)
Hâ‚: Î¼ > 1100

This is a RIGHT-TAILED test because we're testing 
if the mean is GREATER than the claimed value.
```

</details>

---

### Problem 2: Calculating Test Statistic
Sample: n = 36, XÌ„ = 52, s = 6. Test Hâ‚€: Î¼ = 50 vs Hâ‚: Î¼ â‰  50.

<details>
<summary>Click for Answer</summary>

```
       XÌ„ - Î¼â‚€      52 - 50
t = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ = â”€â”€â”€â”€â”€â”€â”€â”€â”€
      s/âˆšn         6/âˆš36

       2
t = â”€â”€â”€â”€â”€ = 2.0
       1

t = 2.0 with df = 35

For two-tailed test at Î± = 0.05:
Critical values: Â±2.03

Since |2.0| < 2.03, we FAIL TO REJECT Hâ‚€
(Or: p-value â‰ˆ 0.053 > 0.05)
```

</details>

---

### Problem 3: Interpreting p-value
You get p-value = 0.08 with Î± = 0.05. What's your conclusion?

<details>
<summary>Click for Answer</summary>

```
Since p-value (0.08) > Î± (0.05):

DECISION: Fail to reject Hâ‚€

INTERPRETATION: 
"At the Î± = 0.05 significance level, there is 
insufficient evidence to reject Hâ‚€. The results 
are not statistically significant."

Note: This does NOT mean Hâ‚€ is true! We simply 
don't have enough evidence against it.
```

</details>

---

### Problem 4: Type I and Type II Errors
In a drug trial, what are the Type I and Type II errors?

<details>
<summary>Click for Answer</summary>

```
Hâ‚€: Drug has no effect
Hâ‚: Drug has an effect

TYPE I ERROR (Î±):
Concluding the drug works when it actually doesn't.
â€¢ Consequence: Ineffective drug gets approved
â€¢ Patients receive useless treatment
â€¢ Called "false positive"

TYPE II ERROR (Î²):
Concluding the drug doesn't work when it actually does.
â€¢ Consequence: Effective drug gets rejected
â€¢ Patients miss out on beneficial treatment
â€¢ Called "false negative"

In drug trials, Type I errors are often considered 
more serious (hence we use small Î± like 0.05 or 0.01).
```

</details>

---

### Problem 5: Power Calculation
With n = 25, Ïƒ = 10, Î± = 0.05, what's the power to detect Î¼ = 52 when Hâ‚€: Î¼ = 50?

<details>
<summary>Click for Answer</summary>

```
Effect size (standardized):
d = (52 - 50) / 10 = 0.2 (small effect)

For one-sample Z-test, power formula:
Power = P(Z > z_Î± - dâˆšn) for right-tailed

z_Î± = 1.645 (for Î± = 0.05, one-tailed)
dâˆšn = 0.2 Ã— âˆš25 = 0.2 Ã— 5 = 1.0

Power = P(Z > 1.645 - 1.0)
      = P(Z > 0.645)
      = 1 - 0.740
      â‰ˆ 0.26 = 26%

This is LOW power! We'd need larger n to reliably 
detect such a small effect.

For 80% power: n â‰ˆ (z_Î± + z_Î²)Â²/dÂ² 
             = (1.645 + 0.84)Â²/0.04 â‰ˆ 155
```

</details>

---

## Summary: The Essence of Hypothesis Testing

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    HYPOTHESIS TESTING                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   "Making data-driven decisions about population claims"         â”‚
â”‚                                                                  â”‚
â”‚   THE FRAMEWORK:                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  1. State Hâ‚€ and Hâ‚                                      â”‚   â”‚
â”‚   â”‚  2. Choose Î± (significance level)                        â”‚   â”‚
â”‚   â”‚  3. Calculate test statistic                             â”‚   â”‚
â”‚   â”‚  4. Find p-value (or critical value)                     â”‚   â”‚
â”‚   â”‚  5. Make decision: Reject or Fail to Reject Hâ‚€           â”‚   â”‚
â”‚   â”‚  6. State conclusion in context                          â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â”‚   KEY CONCEPTS:                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  â€¢ p-value: P(data this extreme | Hâ‚€ true)              â”‚   â”‚
â”‚   â”‚  â€¢ Type I Error (Î±): Rejecting true Hâ‚€                  â”‚   â”‚
â”‚   â”‚  â€¢ Type II Error (Î²): Not rejecting false Hâ‚€            â”‚   â”‚
â”‚   â”‚  â€¢ Power (1-Î²): Detecting real effects                   â”‚   â”‚
â”‚   â”‚  â€¢ Effect Size: Practical magnitude of difference        â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â”‚   DECISION RULE:                                                 â”‚
â”‚   â€¢ p-value â‰¤ Î± â†’ Reject Hâ‚€ ("significant")                     â”‚
â”‚   â€¢ p-value > Î± â†’ Fail to reject Hâ‚€ ("not significant")         â”‚
â”‚                                                                  â”‚
â”‚   REMEMBER:                                                      â”‚
â”‚   â€¢ Statistical significance â‰  Practical importance             â”‚
â”‚   â€¢ Always report effect sizes                                   â”‚
â”‚   â€¢ "Fail to reject" â‰  "Accept"                                 â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## The Big Picture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚     POPULATION                         SAMPLE                    â”‚
â”‚   (Unknown Truth)                    (Our Data)                  â”‚
â”‚                                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚   â”‚           â”‚     Sample          â”‚           â”‚                â”‚
â”‚   â”‚    Î¸      â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚    Î¸Ì‚     â”‚                â”‚
â”‚   â”‚ (unknown) â”‚                     â”‚(estimate) â”‚                â”‚
â”‚   â”‚           â”‚                     â”‚           â”‚                â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                           â”‚                      â”‚
â”‚   We make a CLAIM                         â”‚ Test                 â”‚
â”‚   about Î¸ (Hâ‚€)                            â”‚ Statistic            â”‚
â”‚                                           â”‚                      â”‚
â”‚                                           â–¼                      â”‚
â”‚                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚                                    â”‚  p-value   â”‚                â”‚
â”‚                                    â”‚            â”‚                â”‚
â”‚                                    â”‚ How likely â”‚                â”‚
â”‚                                    â”‚ is this    â”‚                â”‚
â”‚                                    â”‚ data if Hâ‚€ â”‚                â”‚
â”‚                                    â”‚ is true?   â”‚                â”‚
â”‚                                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                                           â”‚                      â”‚
â”‚                                           â–¼                      â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚                              â”‚       DECISION         â”‚          â”‚
â”‚                              â”‚                        â”‚          â”‚
â”‚                              â”‚  p â‰¤ Î±: Reject Hâ‚€     â”‚          â”‚
â”‚                              â”‚  p > Î±: Fail to Rejectâ”‚          â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

> **"Hypothesis testing is the statistical courtroom where data serves as evidence, probability acts as judge, and conclusions are the verdict â€” never certain, but supported by the weight of evidence."**

Master hypothesis testing, and you've mastered the core of statistical inference â€” the ability to make principled, evidence-based decisions in the face of uncertainty! âš–ï¸

---

*From claims to conclusions, from data to decisions â€” that's the power of hypothesis testing!* ğŸ”¬