# Z-Test vs T-Test
## The Ultimate Comparison Guide ğŸ¯

---

## The Fundamental Question

You have sample data and want to test a hypothesis about a population mean. Which test do you use?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   THE CORE DIFFERENCE                                        â”‚
â”‚                                                             â”‚
â”‚   Z-TEST: Use when Ïƒ (population std dev) is KNOWN          â”‚
â”‚   T-TEST: Use when Ïƒ is UNKNOWN (use sample s instead)      â”‚
â”‚                                                             â”‚
â”‚   In practice: T-test is used ~99% of the time!             â”‚
â”‚   Why? We almost NEVER know the true population Ïƒ.          â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“– Story: Two Quality Inspectors

### Inspector Amir (The Veteran)

Amir has worked at the light bulb factory for 30 years. Over decades, the factory has established that bulb lifetimes have a **known population standard deviation of Ïƒ = 50 hours**.

When testing a new batch, Amir can use this historical Ïƒ:

```
       XÌ„ - Î¼â‚€
Z = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â† Uses known Ïƒ
       Ïƒ / âˆšn
```

**Amir uses the Z-test!**

### Inspector Fatima (The New Hire)

Fatima joins a startup making innovative LED bulbs. There's **no historical data** â€” she doesn't know Ïƒ.

She must estimate the standard deviation from her sample:

```
       XÌ„ - Î¼â‚€
t = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â† Uses sample s (estimate of Ïƒ)
       s / âˆšn
```

**Fatima uses the T-test!**

---

## The Key Difference: Known vs Unknown Ïƒ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚                    Z-TEST                                    â”‚
â”‚                    â”€â”€â”€â”€â”€â”€                                   â”‚
â”‚                                                             â”‚
â”‚   â€¢ Population Ïƒ is KNOWN (rare!)                          â”‚
â”‚   â€¢ Test statistic follows Standard Normal N(0,1)          â”‚
â”‚   â€¢ Critical values don't depend on sample size            â”‚
â”‚   â€¢ Fixed critical values: Â±1.96 for 95%                   â”‚
â”‚                                                             â”‚
â”‚   Formula:        XÌ„ - Î¼â‚€                                   â”‚
â”‚              Z = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                 â”‚
â”‚                    Ïƒ / âˆšn                                   â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚                    T-TEST                                    â”‚
â”‚                    â”€â”€â”€â”€â”€â”€                                   â”‚
â”‚                                                             â”‚
â”‚   â€¢ Population Ïƒ is UNKNOWN (common!)                      â”‚
â”‚   â€¢ Must estimate Ïƒ using sample s                         â”‚
â”‚   â€¢ Test statistic follows t-distribution                  â”‚
â”‚   â€¢ Critical values DEPEND on sample size (df)             â”‚
â”‚   â€¢ Heavier tails than normal                              â”‚
â”‚                                                             â”‚
â”‚   Formula:        XÌ„ - Î¼â‚€                                   â”‚
â”‚              t = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                 â”‚
â”‚                    s / âˆšn                                   â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Why Does This Matter?

### The Extra Uncertainty Problem

When we use s instead of Ïƒ, we introduce **additional uncertainty**:

```
Ïƒ is FIXED (if known):
â€¢ Every sample gives the same standard error Ïƒ/âˆšn
â€¢ No extra variability from estimating Ïƒ

s VARIES from sample to sample:
â€¢ Different samples give different s values
â€¢ Sometimes s < Ïƒ (underestimate â†’ t inflated)
â€¢ Sometimes s > Ïƒ (overestimate â†’ t deflated)
â€¢ This extra variability spreads out the distribution!
```

### Visual: The Extra Uncertainty

```
Sample 1: sâ‚ = 48  â†’ SEâ‚ = 48/âˆš25 = 9.6  â†’ tâ‚ = 10/9.6 = 1.04
Sample 2: sâ‚‚ = 55  â†’ SEâ‚‚ = 55/âˆš25 = 11.0 â†’ tâ‚‚ = 10/11.0 = 0.91
Sample 3: sâ‚ƒ = 42  â†’ SEâ‚ƒ = 42/âˆš25 = 8.4  â†’ tâ‚ƒ = 10/8.4 = 1.19
Sample 4: sâ‚„ = 60  â†’ SEâ‚„ = 60/âˆš25 = 12.0 â†’ tâ‚„ = 10/12.0 = 0.83

Even with the SAME true difference, t varies because s varies!
This extra variability â†’ heavier tails in t-distribution
```

---

## Distribution Comparison

### Visual: Z vs t Distributions

```
                    Standard Normal (Z) vs t-Distribution
                    
                              â•­â”€â•®  â† Z (taller, thinner)
                            â•­â”€â•¯ â•°â”€â•®
                           â•­â•¯     â•°â•®
                          â•­â•¯  â•­â”€â•®  â•°â•®  â† t (shorter, fatter tails)
                         â•­â•¯  â•­â•¯ â•°â•®  â•°â•®
                        â•­â•¯  â•­â•¯   â•°â•®  â•°â•®
                       â•­â•¯ â•­â”€â•¯     â•°â”€â•® â•°â•®
                     â•­â”€â•¯â•­â”€â•¯         â•°â”€â•®â•°â”€â•®
               â–“â–“â–“â–“â•­â”€â•¯â•­â”€â•¯             â•°â”€â•®â•°â”€â•®â–“â–“â–“â–“  â† More area in tails (t)
             â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                              0
                              
    Z: Thinner tails â†’ Extreme values are RARE
    t: Heavier tails â†’ Extreme values are MORE LIKELY
    
    As sample size â†‘, t-distribution â†’ Z-distribution
```

### Why Heavier Tails?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   The t-distribution has HEAVIER TAILS because:            â”‚
â”‚                                                             â”‚
â”‚   1. We're uncertain about Ïƒ (estimated by s)              â”‚
â”‚   2. s can be too small â†’ inflates the t-statistic         â”‚
â”‚   3. s can be too large â†’ deflates the t-statistic         â”‚
â”‚   4. This variability spreads out the distribution         â”‚
â”‚                                                             â”‚
â”‚   Result:                                                   â”‚
â”‚   â€¢ More probability in the tails                          â”‚
â”‚   â€¢ Need LARGER critical values to achieve same Î±          â”‚
â”‚   â€¢ More conservative (harder to reject Hâ‚€)                â”‚
â”‚                                                             â”‚
â”‚   The smaller the sample, the more uncertain s is,         â”‚
â”‚   and the heavier the tails become!                        â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Critical Values Comparison

### The Numbers Tell the Story

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                    â”‚
â”‚   95% CONFIDENCE CRITICAL VALUES (Two-Tailed, Î± = 0.05)           â”‚
â”‚                                                                    â”‚
â”‚   Sample Size â”‚   Z-Test   â”‚   T-Test   â”‚   Difference            â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”‚
â”‚   n = 5       â”‚   1.960    â”‚   2.776    â”‚   +0.816 (42% larger!)  â”‚
â”‚   n = 10      â”‚   1.960    â”‚   2.262    â”‚   +0.302 (15% larger)   â”‚
â”‚   n = 15      â”‚   1.960    â”‚   2.145    â”‚   +0.185 (9% larger)    â”‚
â”‚   n = 20      â”‚   1.960    â”‚   2.093    â”‚   +0.133 (7% larger)    â”‚
â”‚   n = 30      â”‚   1.960    â”‚   2.045    â”‚   +0.085 (4% larger)    â”‚
â”‚   n = 50      â”‚   1.960    â”‚   2.010    â”‚   +0.050 (3% larger)    â”‚
â”‚   n = 100     â”‚   1.960    â”‚   1.984    â”‚   +0.024 (1% larger)    â”‚
â”‚   n = âˆ       â”‚   1.960    â”‚   1.960    â”‚   0 (identical!)        â”‚
â”‚                                                                    â”‚
â”‚   Key insight: With small n, t-test requires MUCH stronger        â”‚
â”‚   evidence to reject Hâ‚€!                                          â”‚
â”‚                                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Visual: Critical Values Across Sample Sizes

```
Critical Value (95%, two-tailed)
    â”‚
3.0 â”¤                                              
    â”‚  â—  t-distribution (varies with n)
2.8 â”¤  
    â”‚
2.6 â”¤     â—
    â”‚
2.4 â”¤        â—
    â”‚           â—
2.2 â”¤              â—
    â”‚                 â—  â—
2.0 â”¤â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—â”€â”€â—â”€â”€â—â”€â”€â—â”€â”€â—â”€â”€ Z = 1.96 (constant)
    â”‚                              
1.8 â”¤
    â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€ Sample Size
         5   10   15   20   30   50  100  âˆ
         
As n â†’ âˆ, t-critical â†’ Z-critical = 1.96
```

---

## Side-by-Side Formula Comparison

### One-Sample Tests

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚   ONE-SAMPLE Z-TEST              ONE-SAMPLE T-TEST               â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€               â”‚
â”‚                                                                  â”‚
â”‚         XÌ„ - Î¼â‚€                         XÌ„ - Î¼â‚€                   â”‚
â”‚   Z = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                 t = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                  â”‚
â”‚         Ïƒ / âˆšn                         s / âˆšn                    â”‚
â”‚                                                                  â”‚
â”‚   â€¢ Uses Ïƒ (KNOWN)               â€¢ Uses s (sample estimate)     â”‚
â”‚   â€¢ Z ~ N(0, 1)                  â€¢ t ~ t(df = n-1)              â”‚
â”‚   â€¢ Fixed critical values        â€¢ Critical values depend on df â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Two-Sample Tests

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚   TWO-SAMPLE Z-TEST              TWO-SAMPLE T-TEST               â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€               â”‚
â”‚                                                                  â”‚
â”‚         XÌ„â‚ - XÌ„â‚‚                       XÌ„â‚ - XÌ„â‚‚                   â”‚
â”‚   Z = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          t = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”‚
â”‚       âˆš(Ïƒâ‚Â²/nâ‚ + Ïƒâ‚‚Â²/nâ‚‚)            âˆš(sâ‚Â²/nâ‚ + sâ‚‚Â²/nâ‚‚)          â”‚
â”‚                                                                  â”‚
â”‚   â€¢ Uses Ïƒâ‚, Ïƒâ‚‚ (KNOWN)          â€¢ Uses sâ‚, sâ‚‚ (estimates)      â”‚
â”‚   â€¢ Z ~ N(0, 1)                  â€¢ t ~ t(df = Welch formula)    â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Proportion Tests (Z-Test Only!)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚   PROPORTION Z-TEST (No t-test equivalent!)                      â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                             â”‚
â”‚                                                                  â”‚
â”‚   One-Sample:                    Two-Sample:                     â”‚
â”‚                                                                  â”‚
â”‚         pÌ‚ - pâ‚€                         pÌ‚â‚ - pÌ‚â‚‚                  â”‚
â”‚   Z = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              Z = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€       â”‚
â”‚       âˆš(pâ‚€(1-pâ‚€)/n)                  âˆš(pÌ‚(1-pÌ‚)(1/nâ‚+1/nâ‚‚))       â”‚
â”‚                                                                  â”‚
â”‚   For proportions, we always use Z-test because:                â”‚
â”‚   â€¢ The variance is determined by p: Var = p(1-p)/n             â”‚
â”‚   â€¢ No separate Ïƒ to estimate                                   â”‚
â”‚   â€¢ Large sample ensures normality (np â‰¥ 10, n(1-p) â‰¥ 10)      â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## When to Use Which Test

### The Decision Flowchart

```
                              START
                                â”‚
                                â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ What are you testing? â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚                 â”‚                 â”‚
              â–¼                 â–¼                 â–¼
          MEAN(S)          PROPORTION(S)      VARIANCE
              â”‚                 â”‚                 â”‚
              â–¼                 â–¼                 â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   Always use        Chi-square
    â”‚ Is Ïƒ KNOWN?     â”‚    Z-TEST             test
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
      â”‚             â”‚
     YES           NO
      â”‚             â”‚
      â–¼             â–¼
   Z-TEST        T-TEST
      â”‚             â”‚
      â–¼             â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚N(0,1) â”‚   â”‚Is n â‰¥ 30?    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
              â”‚             â”‚
             YES           NO
              â”‚             â”‚
              â–¼             â–¼
         T-test is     T-test (check
         robust        normality!)
```

### Quick Decision Table

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                    â”‚
â”‚   SITUATION                              â”‚  TEST TO USE            â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚   Testing mean, Ïƒ KNOWN                  â”‚  Z-test                 â”‚
â”‚   Testing mean, Ïƒ UNKNOWN                â”‚  T-test                 â”‚
â”‚   Testing mean, Ïƒ unknown, n â‰¥ 30        â”‚  T-test (â‰ˆ Z-test)     â”‚
â”‚   Testing mean, Ïƒ unknown, n < 30        â”‚  T-test (important!)   â”‚
â”‚   Testing proportion                     â”‚  Z-test                 â”‚
â”‚   Comparing two means, Ïƒ's known         â”‚  Two-sample Z-test     â”‚
â”‚   Comparing two means, Ïƒ's unknown       â”‚  Two-sample T-test     â”‚
â”‚   Paired data (before/after)             â”‚  Paired T-test         â”‚
â”‚   Comparing two proportions              â”‚  Two-proportion Z-test â”‚
â”‚                                                                    â”‚
â”‚   GOLDEN RULE: When in doubt, use T-test! It's always valid.      â”‚
â”‚                                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Practical Reality Check

### When is Ïƒ Actually Known?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚   Ïƒ MIGHT BE KNOWN (rare):                                       â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                     â”‚
â”‚   â€¢ Manufacturing with decades of quality control data          â”‚
â”‚   â€¢ Standardized tests (IQ: Ïƒ = 15, SAT: Ïƒ â‰ˆ 200)              â”‚
â”‚   â€¢ Well-established physical measurements                      â”‚
â”‚   â€¢ Government statistics with huge historical datasets         â”‚
â”‚                                                                  â”‚
â”‚   Ïƒ IS ALMOST CERTAINLY UNKNOWN (common):                        â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”‚
â”‚   â€¢ Medical/clinical research                                   â”‚
â”‚   â€¢ Social science studies                                      â”‚
â”‚   â€¢ Business analytics                                          â”‚
â”‚   â€¢ Scientific experiments                                       â”‚
â”‚   â€¢ Any new or novel measurement                                â”‚
â”‚   â€¢ Basically... everything in real research!                   â”‚
â”‚                                                                  â”‚
â”‚   PRACTICAL ADVICE:                                              â”‚
â”‚   Unless you have a VERY good reason to believe Ïƒ is known,    â”‚
â”‚   use the T-test. It's always valid and more conservative.     â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### The "Large Sample" Shortcut

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚   WHEN n IS LARGE (n â‰¥ 30):                                      â”‚
â”‚                                                                  â”‚
â”‚   â€¢ s becomes a good estimate of Ïƒ                              â”‚
â”‚   â€¢ t-distribution â‰ˆ normal distribution                        â”‚
â”‚   â€¢ Z-test and T-test give nearly identical results            â”‚
â”‚                                                                  â”‚
â”‚   Example with n = 50, Î± = 0.05 (two-tailed):                   â”‚
â”‚   Z-critical = 1.960                                            â”‚
â”‚   t-critical = 2.010 (only 2.5% larger!)                        â”‚
â”‚                                                                  â”‚
â”‚   HOWEVER: Even with large n, using the T-test is:             â”‚
â”‚   â€¢ Technically correct (we're still estimating Ïƒ)             â”‚
â”‚   â€¢ More conservative                                           â”‚
â”‚   â€¢ What modern software does by default                        â”‚
â”‚                                                                  â”‚
â”‚   Bottom line: Use T-test. With large n, it won't matter.      â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Complete Example Comparison

### Scenario: Testing Average Package Weight

A shipping company claims packages weigh 50 lbs on average. You sample 16 packages:

**Sample data:** XÌ„ = 52.5 lbs, s = 6 lbs, n = 16

**Two scenarios:**
- **Scenario A:** You know from historical data that Ïƒ = 6 lbs
- **Scenario B:** You don't know Ïƒ, so you estimate it with s = 6 lbs

### Scenario A: Z-Test (Ïƒ = 6 Known)

```
Hâ‚€: Î¼ = 50
Hâ‚: Î¼ â‰  50
Î± = 0.05, two-tailed

Step 1: Calculate Z-statistic
       XÌ„ - Î¼â‚€     52.5 - 50     2.5
Z = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ = â”€â”€â”€â”€â”€ = 1.67
       Ïƒ/âˆšn        6/âˆš16        1.5

Step 2: Find critical value
Z-critical (Î± = 0.05, two-tailed) = Â±1.96

Step 3: Compare
|Z| = 1.67 < 1.96 = Z-critical

Step 4: p-value
p-value = 2 Ã— P(Z > 1.67) = 2 Ã— 0.0475 = 0.095

Step 5: Decision
p-value = 0.095 > 0.05 â†’ FAIL TO REJECT Hâ‚€

Conclusion: Insufficient evidence that mean weight â‰  50 lbs.
```

### Scenario B: T-Test (Ïƒ Unknown, s = 6)

```
Hâ‚€: Î¼ = 50
Hâ‚: Î¼ â‰  50
Î± = 0.05, two-tailed

Step 1: Calculate t-statistic
       XÌ„ - Î¼â‚€     52.5 - 50     2.5
t = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ = â”€â”€â”€â”€â”€ = 1.67
       s/âˆšn        6/âˆš16        1.5

(Same value! Because s = Ïƒ in this example)

Step 2: Find critical value
df = n - 1 = 15
t-critical (Î± = 0.05, df = 15, two-tailed) = Â±2.131

Step 3: Compare
|t| = 1.67 < 2.131 = t-critical

Step 4: p-value
p-value = 2 Ã— P(t > 1.67 | df = 15) = 2 Ã— 0.058 = 0.116

Step 5: Decision
p-value = 0.116 > 0.05 â†’ FAIL TO REJECT Hâ‚€

Conclusion: Insufficient evidence that mean weight â‰  50 lbs.
```

### Comparing the Results

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚                    Z-TEST          T-TEST                        â”‚
â”‚                    â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€                        â”‚
â”‚   Test statistic   1.67            1.67 (same!)                 â”‚
â”‚   Critical value   Â±1.96           Â±2.131 (larger!)             â”‚
â”‚   p-value          0.095           0.116 (larger!)              â”‚
â”‚   Decision         Fail to reject  Fail to reject               â”‚
â”‚                                                                  â”‚
â”‚   KEY OBSERVATIONS:                                              â”‚
â”‚   â€¢ Same test statistic (because s = Ïƒ here)                    â”‚
â”‚   â€¢ T-test has LARGER critical value (more conservative)       â”‚
â”‚   â€¢ T-test has LARGER p-value (harder to reject)               â”‚
â”‚   â€¢ T-test accounts for uncertainty in estimating Ïƒ            â”‚
â”‚                                                                  â”‚
â”‚   In this case, both give the same decision, but in a         â”‚
â”‚   borderline case (p â‰ˆ 0.05), they could differ!              â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## When Results Differ: A Borderline Case

### Same Data, Different Conclusions

Suppose we got XÌ„ = 53.5 instead of 52.5:

```
Test statistic = (53.5 - 50)/1.5 = 2.33

Z-TEST:
|Z| = 2.33 > 1.96 = Z-critical
p-value = 0.020 < 0.05
â†’ REJECT Hâ‚€ âœ“

T-TEST (df = 15):
|t| = 2.33 > 2.131 = t-critical
p-value = 0.034 < 0.05
â†’ REJECT Hâ‚€ âœ“

Both reject, but t-test p-value is larger.
```

Now suppose we got XÌ„ = 53.0:

```
Test statistic = (53.0 - 50)/1.5 = 2.00

Z-TEST:
|Z| = 2.00 > 1.96 = Z-critical
p-value = 0.046 < 0.05
â†’ REJECT Hâ‚€ âœ“

T-TEST (df = 15):
|t| = 2.00 < 2.131 = t-critical
p-value = 0.064 > 0.05
â†’ FAIL TO REJECT Hâ‚€ âœ—

DIFFERENT CONCLUSIONS!
The t-test is more conservative and doesn't reject.
```

### Why This Matters

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚   Using the WRONG test can lead to:                             â”‚
â”‚                                                                  â”‚
â”‚   If you use Z-test when you should use T-test:                â”‚
â”‚   â€¢ Critical values are too small                               â”‚
â”‚   â€¢ p-values are too small                                      â”‚
â”‚   â€¢ You reject Hâ‚€ more often than you should                   â”‚
â”‚   â€¢ Type I error rate > Î± (false positives!)                   â”‚
â”‚                                                                  â”‚
â”‚   This is called "LIBERAL" â€” too willing to reject             â”‚
â”‚                                                                  â”‚
â”‚   The T-test is CONSERVATIVE:                                   â”‚
â”‚   â€¢ Accounts for uncertainty in estimating Ïƒ                   â”‚
â”‚   â€¢ Maintains the correct Type I error rate                    â”‚
â”‚   â€¢ Harder to reject when you shouldn't                        â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Effect of Sample Size

### Convergence of Z and T

```
As n increases, T-test â†’ Z-test:

n = 5:   t-critical = 2.776   vs   Z-critical = 1.960   (41% diff)
n = 10:  t-critical = 2.262   vs   Z-critical = 1.960   (15% diff)
n = 20:  t-critical = 2.093   vs   Z-critical = 1.960   (7% diff)
n = 30:  t-critical = 2.045   vs   Z-critical = 1.960   (4% diff)
n = 50:  t-critical = 2.010   vs   Z-critical = 1.960   (3% diff)
n = 100: t-critical = 1.984   vs   Z-critical = 1.960   (1% diff)
n â†’ âˆ:   t-critical â†’ 1.960 = Z-critical               (0% diff)
```

### Visual Convergence

```
                   Distribution Shape
                   
n = 5 (df = 4):
                    â•­â”€â”€â•®
                  â•­â”€â•¯  â•°â”€â•®
               â–“â–“â–“â•¯      â•°â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“  Very heavy tails
            â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

n = 15 (df = 14):
                    â•­â”€â”€â”€â•®
                  â•­â”€â•¯   â•°â”€â•®
                â–“â–“â•¯       â•°â–“â–“â–“â–“â–“â–“  Moderate tails
            â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

n = 30 (df = 29):
                    â•­â”€â”€â”€â•®
                  â•­â”€â•¯   â•°â”€â•®
                 â–“â•¯       â•°â–“â–“  Nearly normal
            â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

n â†’ âˆ:
                    â•­â”€â”€â”€â•®
                  â•­â”€â•¯   â•°â”€â•®    Identical to
                 â•­â•¯       â•°â•®   Standard Normal!
            â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

---

## Summary Comparison Table

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                    â”‚
â”‚   FEATURE              â”‚    Z-TEST         â”‚    T-TEST             â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚   Population Ïƒ         â”‚    KNOWN          â”‚    UNKNOWN            â”‚
â”‚   Estimate of Ïƒ        â”‚    Not needed     â”‚    Uses sample s      â”‚
â”‚   Distribution         â”‚    N(0, 1)        â”‚    t(df)              â”‚
â”‚   Tails                â”‚    Standard       â”‚    Heavier            â”‚
â”‚   Critical values      â”‚    Fixed (1.96)   â”‚    Depend on df       â”‚
â”‚   Sample size impact   â”‚    None           â”‚    Larger n â†’ Z-like  â”‚
â”‚   Conservativeness     â”‚    Less           â”‚    More               â”‚
â”‚   Real-world use       â”‚    Rare (~1%)     â”‚    Common (~99%)      â”‚
â”‚   For proportions      â”‚    Yes            â”‚    No (use Z)         â”‚
â”‚   For small samples    â”‚    Risky          â”‚    Appropriate        â”‚
â”‚   With large samples   â”‚    OK             â”‚    Also OK (â‰ˆ Z)      â”‚
â”‚                                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Common Misconceptions

### Misconception 1: "Use Z for large n, T for small n"

```
âŒ WRONG: "If n â‰¥ 30, use Z-test. If n < 30, use T-test."

âœ… CORRECT: The choice depends on whether Ïƒ is KNOWN, not on n!

â€¢ If Ïƒ is known â†’ Z-test (regardless of n)
â€¢ If Ïƒ is unknown â†’ T-test (regardless of n)

The "n = 30 rule" is about when Z and T give SIMILAR results,
not about which test to choose!
```

### Misconception 2: "T-test is only for small samples"

```
âŒ WRONG: "T-test is a small-sample version of Z-test"

âœ… CORRECT: T-test is for when Ïƒ is UNKNOWN (any sample size)

With large n:
â€¢ T-test is still technically correct
â€¢ Results will be nearly identical to Z-test
â€¢ Modern software uses T-test by default
```

### Misconception 3: "The test statistic value is different"

```
âŒ WRONG: "Z and t give different test statistic values"

âœ… CORRECT: If Ïƒ = s, the test statistics are IDENTICAL!

       XÌ„ - Î¼â‚€              XÌ„ - Î¼â‚€
Z = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  and  t = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  give same value if Ïƒ = s
       Ïƒ / âˆšn              s / âˆšn

The DIFFERENCE is in:
â€¢ What distribution we compare to
â€¢ The critical values used
â€¢ The p-value calculation
```

### Misconception 4: "Z-test is better because it's simpler"

```
âŒ WRONG: "Z-test is preferred when possible"

âœ… CORRECT: T-test is preferred in almost all real situations!

â€¢ T-test is always valid (accounts for uncertainty in s)
â€¢ Z-test requires knowing Ïƒ (rarely true)
â€¢ Using Z-test incorrectly inflates Type I error
â€¢ Modern software defaults to T-test for good reason
```

---

## Python Implementation

### Complete Comparison

```python
import numpy as np
from scipy import stats

def compare_z_and_t_tests(data, mu_0, sigma=None, alpha=0.05):
    """
    Compare Z-test and T-test results
    
    Parameters:
    - data: sample data
    - mu_0: hypothesized mean
    - sigma: population std dev (if known, for Z-test)
    - alpha: significance level
    """
    data = np.array(data)
    n = len(data)
    x_bar = np.mean(data)
    s = np.std(data, ddof=1)
    
    print("=" * 60)
    print("Z-TEST vs T-TEST COMPARISON")
    print("=" * 60)
    print(f"\nSample Statistics:")
    print(f"  n = {n}")
    print(f"  XÌ„ = {x_bar:.4f}")
    print(f"  s = {s:.4f}")
    print(f"  Î¼â‚€ = {mu_0}")
    print(f"  Î± = {alpha}")
    
    # T-TEST (always possible)
    print("\n" + "-" * 60)
    print("T-TEST (Ïƒ unknown, using s)")
    print("-" * 60)
    
    se_t = s / np.sqrt(n)
    t_stat = (x_bar - mu_0) / se_t
    df = n - 1
    t_crit = stats.t.ppf(1 - alpha/2, df)
    p_value_t = 2 * (1 - stats.t.cdf(abs(t_stat), df))
    
    print(f"  Standard Error: s/âˆšn = {se_t:.4f}")
    print(f"  t-statistic: {t_stat:.4f}")
    print(f"  Degrees of freedom: {df}")
    print(f"  Critical value (two-tailed): Â±{t_crit:.4f}")
    print(f"  p-value: {p_value_t:.4f}")
    print(f"  Decision: {'REJECT Hâ‚€' if p_value_t < alpha else 'FAIL TO REJECT Hâ‚€'}")
    
    # Z-TEST (only if sigma provided)
    if sigma is not None:
        print("\n" + "-" * 60)
        print(f"Z-TEST (Ïƒ = {sigma} known)")
        print("-" * 60)
        
        se_z = sigma / np.sqrt(n)
        z_stat = (x_bar - mu_0) / se_z
        z_crit = stats.norm.ppf(1 - alpha/2)
        p_value_z = 2 * (1 - stats.norm.cdf(abs(z_stat)))
        
        print(f"  Standard Error: Ïƒ/âˆšn = {se_z:.4f}")
        print(f"  Z-statistic: {z_stat:.4f}")
        print(f"  Critical value (two-tailed): Â±{z_crit:.4f}")
        print(f"  p-value: {p_value_z:.4f}")
        print(f"  Decision: {'REJECT Hâ‚€' if p_value_z < alpha else 'FAIL TO REJECT Hâ‚€'}")
        
        # Comparison
        print("\n" + "-" * 60)
        print("COMPARISON")
        print("-" * 60)
        print(f"  Test statistic: Z = {z_stat:.4f}, t = {t_stat:.4f}")
        print(f"  Critical values: Z = Â±{z_crit:.4f}, t = Â±{t_crit:.4f}")
        print(f"  Critical value difference: {((t_crit - z_crit)/z_crit)*100:.1f}%")
        print(f"  p-values: Z = {p_value_z:.4f}, t = {p_value_t:.4f}")
        print(f"  Same decision? {'Yes' if (p_value_z < alpha) == (p_value_t < alpha) else 'NO!'}")
    
    return {'t_stat': t_stat, 'p_value_t': p_value_t, 
            'z_stat': z_stat if sigma else None, 'p_value_z': p_value_z if sigma else None}

# Example: Package weights
np.random.seed(42)
packages = [52, 53, 49, 54, 51, 55, 48, 53, 50, 52, 
            51, 54, 49, 53, 52, 50]

result = compare_z_and_t_tests(packages, mu_0=50, sigma=6)
```

### Visualization Function

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

def visualize_z_vs_t(df, alpha=0.05):
    """Visualize Z and t distributions with critical regions"""
    
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    x = np.linspace(-4, 4, 1000)
    
    # Plot 1: Overlay both distributions
    ax1 = axes[0]
    ax1.plot(x, stats.norm.pdf(x), 'b-', linewidth=2, label='Z (Normal)')
    ax1.plot(x, stats.t.pdf(x, df), 'r--', linewidth=2, label=f't (df={df})')
    ax1.fill_between(x, stats.norm.pdf(x), alpha=0.2, color='blue')
    ax1.fill_between(x, stats.t.pdf(x, df), alpha=0.2, color='red')
    ax1.set_xlabel('Value', fontsize=12)
    ax1.set_ylabel('Density', fontsize=12)
    ax1.set_title(f'Z vs t Distribution (df = {df})', fontsize=14)
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # Plot 2: Critical regions comparison
    ax2 = axes[1]
    
    z_crit = stats.norm.ppf(1 - alpha/2)
    t_crit = stats.t.ppf(1 - alpha/2, df)
    
    ax2.plot(x, stats.norm.pdf(x), 'b-', linewidth=2, label='Z')
    ax2.plot(x, stats.t.pdf(x, df), 'r--', linewidth=2, label=f't (df={df})')
    
    # Z critical regions
    ax2.axvline(z_crit, color='blue', linestyle=':', linewidth=1.5, label=f'Z crit = Â±{z_crit:.3f}')
    ax2.axvline(-z_crit, color='blue', linestyle=':', linewidth=1.5)
    
    # t critical regions
    ax2.axvline(t_crit, color='red', linestyle=':', linewidth=1.5, label=f't crit = Â±{t_crit:.3f}')
    ax2.axvline(-t_crit, color='red', linestyle=':', linewidth=1.5)
    
    ax2.set_xlabel('Value', fontsize=12)
    ax2.set_ylabel('Density', fontsize=12)
    ax2.set_title(f'Critical Values (Î± = {alpha}, two-tailed)', fontsize=14)
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()

# Visualize for different df values
for df in [5, 15, 30]:
    visualize_z_vs_t(df)
```

### Critical Values Table Generator

```python
import numpy as np
from scipy import stats

def print_critical_value_comparison():
    """Print comparison table of Z and t critical values"""
    
    sample_sizes = [5, 10, 15, 20, 25, 30, 40, 50, 100, 500, 1000]
    alphas = [0.10, 0.05, 0.01]
    
    print("=" * 80)
    print("Z-TEST vs T-TEST CRITICAL VALUES (Two-Tailed)")
    print("=" * 80)
    
    for alpha in alphas:
        z_crit = stats.norm.ppf(1 - alpha/2)
        print(f"\nÎ± = {alpha} (Confidence = {(1-alpha)*100:.0f}%)")
        print("-" * 80)
        print(f"{'n':>6} â”‚ {'df':>4} â”‚ {'Z-crit':>8} â”‚ {'t-crit':>8} â”‚ {'Diff':>8} â”‚ {'% Diff':>8}")
        print("-" * 80)
        
        for n in sample_sizes:
            df = n - 1
            t_crit = stats.t.ppf(1 - alpha/2, df)
            diff = t_crit - z_crit
            pct_diff = (diff / z_crit) * 100
            
            print(f"{n:>6} â”‚ {df:>4} â”‚ {z_crit:>8.4f} â”‚ {t_crit:>8.4f} â”‚ {diff:>8.4f} â”‚ {pct_diff:>7.2f}%")
        
        print(f"{'âˆ':>6} â”‚ {'âˆ':>4} â”‚ {z_crit:>8.4f} â”‚ {z_crit:>8.4f} â”‚ {'0.0000':>8} â”‚ {'0.00%':>8}")

print_critical_value_comparison()
```

---

## Practice Problems ğŸ“

### Problem 1: Choosing the Right Test
A researcher measures IQ scores (known to have Ïƒ = 15 in the general population) for 25 students at a special school. Which test should they use?

<details>
<summary>Click for Answer</summary>

```
ANSWER: Z-TEST

Reason: Ïƒ = 15 is KNOWN (IQ tests are standardized with 
known population parameters).

Since Ïƒ is known, use the Z-test:
Z = (XÌ„ - 100)/(15/âˆš25) = (XÌ„ - 100)/3

Note: This is one of the rare cases where Ïƒ is actually known!
```

</details>

---

### Problem 2: Impact of Sample Size
Two researchers test the same hypothesis with:
- Researcher A: n = 10, gets t = 2.10
- Researcher B: n = 100, gets t = 2.10

Who is more likely to reject Hâ‚€ at Î± = 0.05?

<details>
<summary>Click for Answer</summary>

```
ANSWER: Researcher B (larger sample)

Researcher A (n = 10, df = 9):
t-critical = 2.262
|t| = 2.10 < 2.262 â†’ FAIL TO REJECT Hâ‚€

Researcher B (n = 100, df = 99):
t-critical â‰ˆ 1.984
|t| = 2.10 > 1.984 â†’ REJECT Hâ‚€

Same test statistic, DIFFERENT conclusions!

With larger n:
â€¢ df is larger
â€¢ t-distribution is closer to normal
â€¢ Critical values are smaller
â€¢ Easier to reject Hâ‚€ (more power)
```

</details>

---

### Problem 3: When Tests Disagree
With n = 12, XÌ„ = 105, s = 15, Î¼â‚€ = 100, Î± = 0.05 (two-tailed):

a) Would Z-test reject Hâ‚€?
b) Would T-test reject Hâ‚€?

<details>
<summary>Click for Answer</summary>

```
Calculate test statistic:
(105 - 100)/(15/âˆš12) = 5/4.33 = 1.15

a) Z-TEST:
Z-critical = Â±1.96
|Z| = 1.15 < 1.96 â†’ FAIL TO REJECT Hâ‚€
p-value = 0.25

b) T-TEST (df = 11):
t-critical = Â±2.201
|t| = 1.15 < 2.201 â†’ FAIL TO REJECT Hâ‚€
p-value = 0.27

In this case, both tests agree (fail to reject).

But the t-test is MORE conservative:
â€¢ Larger critical value (2.201 vs 1.96)
â€¢ Larger p-value (0.27 vs 0.25)

If the test statistic were closer to the boundary 
(e.g., t = 2.0), they could disagree!
```

</details>

---

### Problem 4: Proportions
A political poll of 400 voters finds 55% support Candidate A. 
Which test do you use to determine if this differs from 50%?

<details>
<summary>Click for Answer</summary>

```
ANSWER: Z-TEST

For proportions, we always use Z-test because:

1. The population variance is determined by p:
   Var(pÌ‚) = p(1-p)/n
   There's no separate Ïƒ to estimate!

2. With large n (np â‰¥ 10, n(1-p) â‰¥ 10), normal approximation applies

Calculation:
pÌ‚ = 0.55, pâ‚€ = 0.50, n = 400

Z = (0.55 - 0.50)/âˆš(0.50Ã—0.50/400)
  = 0.05/âˆš0.000625
  = 0.05/0.025
  = 2.0

p-value = 2 Ã— P(Z > 2.0) = 0.046 < 0.05 â†’ REJECT Hâ‚€

There is significant evidence that support differs from 50%.
```

</details>

---

## Summary: The Final Verdict

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚                    Z-TEST vs T-TEST                              â”‚
â”‚                    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                              â”‚
â”‚                                                                  â”‚
â”‚   THE KEY DIFFERENCE:                                            â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  Z-Test: Ïƒ is KNOWN â†’ Use Ïƒ in formula                  â”‚   â”‚
â”‚   â”‚  T-Test: Ïƒ is UNKNOWN â†’ Estimate with s                 â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â”‚   THE CONSEQUENCE:                                               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  T-test has heavier tails â†’ More conservative          â”‚   â”‚
â”‚   â”‚  T-test has larger critical values                      â”‚   â”‚
â”‚   â”‚  T-test is harder to reject Hâ‚€ (appropriately so!)     â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â”‚   THE CONVERGENCE:                                               â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  As n â†’ âˆ, t-distribution â†’ normal distribution        â”‚   â”‚
â”‚   â”‚  Large samples: Z-test â‰ˆ T-test                        â”‚   â”‚
â”‚   â”‚  Rule of thumb: n â‰¥ 30 gives similar results           â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â”‚   THE PRACTICAL ADVICE:                                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  â€¢ Use T-test for means (almost always!)                â”‚   â”‚
â”‚   â”‚  â€¢ Use Z-test for proportions                           â”‚   â”‚
â”‚   â”‚  â€¢ When in doubt, use T-test!                          â”‚   â”‚
â”‚   â”‚  â€¢ Modern software defaults to T-test for good reason  â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Quick Reference Card

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     QUICK REFERENCE                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   Z-TEST                        T-TEST                          â”‚
â”‚   â”€â”€â”€â”€â”€â”€                        â”€â”€â”€â”€â”€â”€                          â”‚
â”‚   Ïƒ known                       Ïƒ unknown                       â”‚
â”‚   Z = (XÌ„-Î¼â‚€)/(Ïƒ/âˆšn)            t = (XÌ„-Î¼â‚€)/(s/âˆšn)              â”‚
â”‚   Compare to N(0,1)             Compare to t(df)                â”‚
â”‚   95% crit: Â±1.96              95% crit: depends on df          â”‚
â”‚                                                                  â”‚
â”‚   PROPORTIONS: Always Z-test                                    â”‚
â”‚   MEANS: Almost always T-test                                   â”‚
â”‚                                                                  â”‚
â”‚   95% t-critical values:                                        â”‚
â”‚   df=5: 2.571 â”‚ df=10: 2.228 â”‚ df=30: 2.042 â”‚ df=âˆ: 1.960      â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

> **"The difference between Z-test and T-test is simple: do you know Ïƒ or not? In practice, you almost never know Ïƒ, so use the T-test. It's always valid, properly accounts for uncertainty, and with large samples gives the same answer as Z-test anyway."**

Understanding when to use each test is fundamental to statistical inference. Now you know! ğŸ¯

---

*From known to unknown, from Z to t â€” that's the journey of estimating Ïƒ!* ğŸ“Š