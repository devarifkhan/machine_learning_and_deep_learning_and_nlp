# Types of Probability Distributions
## A Complete Guide Through Real-Life Stories ğŸ²ğŸ“Š

---

## The Big Picture

Imagine you're trying to predict random events in life. Different situations follow different **patterns**. These patterns are called **probability distributions**.

```
                    PROBABILITY DISTRIBUTIONS
                            â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                               â”‚
      â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”                   â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
      â”‚ DISCRETE  â”‚                   â”‚ CONTINUOUSâ”‚
      â”‚ (Countable)â”‚                   â”‚(Measurable)â”‚
      â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
            â”‚                               â”‚
    â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¼â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”         â”Œâ”€â”€â”€â”¬â”€â”€â”€â”¼â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”
    â”‚   â”‚   â”‚   â”‚   â”‚   â”‚         â”‚   â”‚   â”‚   â”‚   â”‚   â”‚
   Ber Bin Poi Geo NB  Hyp      Uni Nor Exp Gam Bet  t
```

---

## Quick Reference: When to Use What?

| Distribution | Use When... | Real Example |
|--------------|-------------|--------------|
| **Bernoulli** | Single yes/no trial | One coin flip |
| **Binomial** | Fixed trials, counting successes | 10 free throws, how many score? |
| **Poisson** | Counting events in time/space | Customers per hour |
| **Geometric** | Trials until first success | Attempts until first sale |
| **Negative Binomial** | Trials until k successes | Games until 3rd win |
| **Hypergeometric** | Sampling without replacement | Cards drawn from deck |
| **Uniform** | Equal chance in a range | Random number generator |
| **Normal** | Natural phenomena, averages | Heights, test scores |
| **Exponential** | Time between events | Time until next call |
| **Gamma** | Time until k events | Time for 5 customers |
| **Beta** | Probabilities/proportions | Success rates |
| **Chi-squared** | Variance testing | Goodness of fit tests |
| **Student's t** | Small sample means | Testing with n < 30 |

---

# ğŸ¯ PART 1: DISCRETE DISTRIBUTIONS
## *For things you can COUNT*

---

# 1. Bernoulli Distribution
## *The Single Coin Flip*

---

## ğŸ“– Story: The Job Interview

Fatima has a job interview tomorrow. Based on her preparation, she estimates:
- **70% chance** of getting the job (Success)
- **30% chance** of not getting it (Failure)

This is the simplest distribution â€” **one trial, two outcomes**.

### The Bernoulli Distribution

| Outcome | X | Probability |
|---------|---|-------------|
| Failure | 0 | 1 - p = 0.30 |
| Success | 1 | p = 0.70 |

### Key Properties

```
Parameter: p (probability of success)

Mean:     Î¼ = p
Variance: ÏƒÂ² = p(1-p)

For Fatima:
Mean = 0.70 (expected value)
Variance = 0.70 Ã— 0.30 = 0.21
```

### Visualization

```
P(X)
 â”‚
0.7â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—
 â”‚                        â”‚
0.3â”œâ”€â”€â”€â”€â”€â”€â”€â”€â—             â”‚
 â”‚         â”‚              â”‚
 0â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€
           0              1
        Failure        Success
```

### Real-Life Bernoulli Examples

- Will it rain today? (Yes/No)
- Does a machine produce a defective item? (Yes/No)
- Does a patient respond to treatment? (Yes/No)
- Does a customer buy? (Yes/No)

---

# 2. Binomial Distribution
## *Counting Successes in Fixed Trials*

---

## ğŸ“– Story: The Basketball Free Throws

Karim is a basketball player with a **60% free throw success rate**. He takes **10 free throws** in practice.

Question: *What's the probability he makes exactly 7 shots?*

### The Binomial Distribution

When you repeat a Bernoulli trial **n times** and count successes:

```
Parameters:
- n = number of trials (10 shots)
- p = probability of success (0.60)

X = number of successes (0, 1, 2, ..., n)
```

### The Formula

```
P(X = k) = C(n,k) Ã— p^k Ã— (1-p)^(n-k)

Where C(n,k) = n! / (k!(n-k)!)  â† "n choose k"
```

### Solving Karim's Question

```
P(X = 7) = C(10,7) Ã— (0.60)^7 Ã— (0.40)^3
P(X = 7) = 120 Ã— 0.0280 Ã— 0.064
P(X = 7) â‰ˆ 0.215 or 21.5%
```

### Visualization

```
P(X)
 â”‚
 â”‚           â—
0.2â”œ        â— â—
 â”‚        â—     â—
0.1â”œ      â—       â—
 â”‚      â—           â—
 â”‚    â—               â—
 0â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—â”€â”€
    0 1 2 3 4 5 6 7 8 9 10
         Number of successful shots
         
Peak is around np = 10 Ã— 0.6 = 6
```

### Key Properties

```
Mean:     Î¼ = np = 10 Ã— 0.60 = 6 shots
Variance: ÏƒÂ² = np(1-p) = 10 Ã— 0.60 Ã— 0.40 = 2.4
Std Dev:  Ïƒ = âˆš2.4 â‰ˆ 1.55 shots
```

### Real-Life Binomial Examples

| Scenario | n | p | X counts... |
|----------|---|---|-------------|
| 20 coin flips | 20 | 0.5 | Heads |
| 100 emails, spam check | 100 | 0.3 | Spam emails |
| 15 patients given drug | 15 | 0.8 | Patients cured |
| 50 products inspected | 50 | 0.02 | Defective items |

---

# 3. Poisson Distribution
## *Counting Events in Time or Space*

---

## ğŸ“– Story: The Call Center

Rashida manages a call center. On average, they receive **4 calls per minute**.

Question: *What's the probability of receiving exactly 6 calls in one minute?*

### The Poisson Distribution

Used when counting **how many times** something happens in a **fixed interval** (time, area, volume).

```
Parameter: Î» (lambda) = average rate of events

Î» = 4 calls per minute
```

### The Formula

```
P(X = k) = (Î»^k Ã— e^(-Î»)) / k!

Where e â‰ˆ 2.71828
```

### Solving Rashida's Question

```
P(X = 6) = (4^6 Ã— e^(-4)) / 6!
P(X = 6) = (4096 Ã— 0.0183) / 720
P(X = 6) â‰ˆ 0.104 or 10.4%
```

### Visualization

```
P(X)
 â”‚
 â”‚      â—
0.2â”œ    â— â—
 â”‚    â—   â—
0.1â”œ  â—     â—
 â”‚  â—       â—
 â”‚â—           â—
 0â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—â”€â”€â—â”€â”€â—â”€â”€
   0 1 2 3 4 5 6 7 8 9 10
        Number of calls
        
Peak is around Î» = 4
```

### Key Properties

```
Mean:     Î¼ = Î» = 4
Variance: ÏƒÂ² = Î» = 4

Special: Mean = Variance in Poisson!
```

### When to Use Poisson vs Binomial?

| Use Poisson When... | Use Binomial When... |
|---------------------|---------------------|
| Counting events in continuous time/space | Counting successes in fixed trials |
| n is very large, p is very small | n is fixed and known |
| Events occur independently at constant rate | Each trial is independent |
| Î» = np is moderate | You know exact n and p |

### Real-Life Poisson Examples

| Scenario | Î» (average rate) |
|----------|------------------|
| Typos per page | 2 typos/page |
| Car accidents per day | 5 accidents/day |
| Meteors per hour | 3 meteors/hour |
| Server requests per second | 100 requests/second |
| Earthquakes per year | 12 earthquakes/year |

---

# 4. Geometric Distribution
## *Waiting for the First Success*

---

## ğŸ“– Story: The Sales Call

Imran is a salesperson. He knows that **20% of his calls result in a sale**.

Question: *What's the probability his FIRST sale happens on the 4th call?*

### The Geometric Distribution

Counts **how many trials until the first success**.

```
Parameter: p = probability of success per trial

p = 0.20 (20% chance of sale)
```

### The Formula

```
P(X = k) = (1-p)^(k-1) Ã— p

"Fail (k-1) times, then succeed"
```

### Solving Imran's Question

```
P(X = 4) = (0.80)^3 Ã— (0.20)
P(X = 4) = 0.512 Ã— 0.20
P(X = 4) = 0.1024 or 10.24%
```

### Visualization

```
P(X)
 â”‚
0.2â”œâ—
 â”‚  â•²
0.15â”œ â—
 â”‚   â•²
0.1â”œ   â—
 â”‚     â•²â—
0.05â”œ     â•²â—
 â”‚         â•²â—â”€â”€â—â”€â”€â—â”€â”€â—
 0â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    1  2  3  4  5  6  7  8
       Trial of first success
       
Always decreasing (memoryless property)
```

### Key Properties

```
Mean:     Î¼ = 1/p = 1/0.20 = 5 calls
Variance: ÏƒÂ² = (1-p)/pÂ² = 0.80/0.04 = 20

Imran expects his first sale on the 5th call on average.
```

### The Memoryless Property

Amazing fact: The geometric distribution "forgets" the past!

If Imran has already made 10 calls with no sale, the probability of success on the next call is **still 20%** â€” not higher!

### Real-Life Geometric Examples

| Scenario | p | Counting... |
|----------|---|-------------|
| Flipping until heads | 0.5 | Flips until first heads |
| Rolling until 6 | 1/6 | Rolls until first 6 |
| Interviews until hired | 0.15 | Interviews until first offer |
| Attempts until login success | 0.9 | Tries until correct password |

---

# 5. Negative Binomial Distribution
## *Waiting for the k-th Success*

---

## ğŸ“– Story: The Cricket Match

Sabbir is watching cricket. His favorite team wins **40% of matches**.

Question: *What's the probability they achieve their 3rd win on the 7th match?*

### The Negative Binomial Distribution

Counts **trials until you get k successes** (generalization of geometric).

```
Parameters:
- k = number of successes needed (3 wins)
- p = probability of success (0.40)
```

### The Logic

For the 3rd win to happen on the 7th match:
- Matches 1-6 must have exactly 2 wins (and 4 losses)
- Match 7 must be a win

### The Formula

```
P(X = n) = C(n-1, k-1) Ã— p^k Ã— (1-p)^(n-k)
```

### Solving Sabbir's Question

```
P(X = 7) = C(6,2) Ã— (0.40)^3 Ã— (0.60)^4
P(X = 7) = 15 Ã— 0.064 Ã— 0.1296
P(X = 7) â‰ˆ 0.124 or 12.4%
```

### Key Properties

```
Mean:     Î¼ = k/p = 3/0.40 = 7.5 matches
Variance: ÏƒÂ² = k(1-p)/pÂ² = 3(0.60)/(0.16) = 11.25

On average, it takes 7.5 matches to see 3 wins.
```

### Real-Life Examples

| Scenario | k | p |
|----------|---|---|
| Wait for 5th customer | 5 | 0.3/min |
| Games until 10th win | 10 | 0.55 |
| Trials until 3rd success | 3 | 0.25 |

---

# 6. Hypergeometric Distribution
## *Sampling Without Replacement*

---

## ğŸ“– Story: The Quality Inspector

A factory has a batch of **100 phones**, and **10 are defective**. An inspector randomly selects **15 phones** (without replacement).

Question: *What's the probability exactly 2 are defective?*

### Why Not Binomial?

In binomial, each trial is **independent** (with replacement).
Here, once you pick a phone, **probabilities change**!

### The Hypergeometric Distribution

```
Parameters:
- N = population size (100 phones)
- K = successes in population (10 defective)
- n = sample size (15 selected)

X = defective phones in sample
```

### The Formula

```
P(X = k) = [C(K,k) Ã— C(N-K, n-k)] / C(N,n)

"Ways to choose k defective Ã— Ways to choose (n-k) good"
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
              "Total ways to choose n items"
```

### Solving the Inspector's Question

```
P(X = 2) = [C(10,2) Ã— C(90,13)] / C(100,15)

C(10,2) = 45
C(90,13) = [large number]
C(100,15) = [large number]

P(X = 2) â‰ˆ 0.276 or 27.6%
```

### Key Properties

```
Mean:     Î¼ = n Ã— (K/N) = 15 Ã— (10/100) = 1.5 defective
Variance: ÏƒÂ² = n Ã— (K/N) Ã— (1-K/N) Ã— (N-n)/(N-1)
```

### Binomial vs Hypergeometric

| Aspect | Binomial | Hypergeometric |
|--------|----------|----------------|
| Sampling | With replacement | Without replacement |
| Probability | Stays constant | Changes after each draw |
| Independence | Trials independent | Trials dependent |
| Population | Infinite or very large | Finite |

### Real-Life Examples

| Scenario | N | K | n |
|----------|---|---|---|
| Cards: Drawing hearts | 52 | 13 | 5 |
| Lottery numbers | 49 | 6 | 6 |
| Survey sampling | 1000 | 400 | 50 |
| Committee selection | 20 | 8 women | 5 |

---

# ğŸ“ˆ PART 2: CONTINUOUS DISTRIBUTIONS
## *For things you MEASURE*

---

# 7. Uniform Distribution
## *Equal Chance for Everything*

---

## ğŸ“– Story: The Random Bus

A bus arrives randomly between **2:00 PM and 2:30 PM**. Every moment in this 30-minute window is equally likely.

Question: *What's the probability the bus arrives between 2:10 and 2:20?*

### The Uniform Distribution

```
Parameters:
- a = minimum value (0 minutes)
- b = maximum value (30 minutes)

All values between a and b are equally likely.
```

### Visualization

```
Density
   â”‚
1/30â”œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€
   â”‚    â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚
   â”‚    â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚
   â”‚    â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚
   0â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€
        0      10      20      30
              Minutes after 2:00
              
Height = 1/(b-a) = 1/30
```

### The Formula

```
PDF:  f(x) = 1/(b-a)  for a â‰¤ x â‰¤ b
             0        otherwise

P(c < X < d) = (d-c)/(b-a)
```

### Solving the Bus Question

```
P(10 < X < 20) = (20-10)/(30-0)
P(10 < X < 20) = 10/30 = 1/3 â‰ˆ 33.3%
```

### Key Properties

```
Mean:     Î¼ = (a+b)/2 = (0+30)/2 = 15 minutes
Variance: ÏƒÂ² = (b-a)Â²/12 = 900/12 = 75
Std Dev:  Ïƒ = âˆš75 â‰ˆ 8.66 minutes
```

### Real-Life Examples

- Random number generators
- Arrival times in a window
- Rounding errors
- Random angle (0 to 360Â°)

---

# 8. Normal (Gaussian) Distribution
## *The Bell Curve â€” The Most Important Distribution!*

---

## ğŸ“– Story: The National Exam

Bangladesh's SSC exam scores follow a normal distribution with:
- **Mean (Î¼) = 65%**
- **Standard Deviation (Ïƒ) = 12%**

Question: *What percentage of students score between 53% and 77%?*

### Why Normal is So Important

The **Central Limit Theorem** says: When you add up many independent random variables, the result tends to be normal â€” regardless of the original distributions!

This is why heights, weights, test scores, measurement errors, and countless natural phenomena follow the normal distribution.

### Visualization: The Bell Curve

```
                        â”‚
                       â•­â”´â•®
                      â•­â•¯ â•°â•®
                     â•­â•¯   â•°â•®
                    â•­â•¯     â•°â•®
                   â•­â•¯       â•°â•®
                  â•­â•¯         â•°â•®
                 â•­â•¯           â•°â•®
              â•­â”€â”€â•¯             â•°â”€â”€â•®
         â•­â”€â”€â”€â”€â•¯                   â•°â”€â”€â”€â”€â•®
    â”€â”€â”€â”€â”€â•¯                             â•°â”€â”€â”€â”€â”€
    
    â”œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤
   Î¼-3Ïƒ  Î¼-2Ïƒ  Î¼-1Ïƒ    Î¼    Î¼+1Ïƒ  Î¼+2Ïƒ  Î¼+3Ïƒ
    29    41    53    65    77    89   101
```

### The 68-95-99.7 Rule (Empirical Rule)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                        â”‚
â”‚   68% of data falls within Î¼ Â± 1Ïƒ  (53% to 77%)       â”‚
â”‚   95% of data falls within Î¼ Â± 2Ïƒ  (41% to 89%)       â”‚
â”‚   99.7% of data falls within Î¼ Â± 3Ïƒ (29% to 101%)     â”‚
â”‚                                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Solving the Exam Question

Scores between 53% and 77% = Î¼ Â± 1Ïƒ

**Answer: About 68% of students!**

### The Z-Score (Standardization)

To use normal tables, convert to **standard normal** (Î¼=0, Ïƒ=1):

```
Z = (X - Î¼) / Ïƒ

Example: What Z-score is 89%?
Z = (89 - 65) / 12 = 24/12 = 2

A score of 89% is 2 standard deviations above the mean.
```

### Key Properties

```
Parameters: Î¼ (mean), Ïƒ (standard deviation)

Mean:     Î¼ (center of the curve)
Variance: ÏƒÂ²
Mode:     Î¼ (peak is at the mean)
Median:   Î¼ (symmetric distribution)

The curve is symmetric around Î¼.
```

### Real-Life Examples

| Phenomenon | Î¼ | Ïƒ |
|------------|---|---|
| Adult male height (BD) | 165 cm | 7 cm |
| IQ scores | 100 | 15 |
| Manufacturing tolerance | 50 mm | 0.5 mm |
| Daily stock returns | 0.05% | 1.5% |

---

# 9. Exponential Distribution
## *Time Between Events*

---

## ğŸ“– Story: The Emergency Room

An ER receives patients at an average rate of **3 per hour** (Poisson process).

Question: *What's the probability the next patient arrives within 30 minutes?*

### The Connection: Poisson â†” Exponential

| Poisson | Exponential |
|---------|-------------|
| Counts events in time | Time between events |
| Discrete | Continuous |
| Î» = events per unit time | Same Î» parameter |

### Visualization

```
Density f(x)
   â”‚
 Î» â”œâ—
   â”‚â•²
   â”‚ â•²
   â”‚  â•²
   â”‚   â•²
   â”‚    â•²
   â”‚     â•²â”€â”€
   â”‚        â•²â”€â”€â”€
   â”‚            â•²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   0â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         Time until next event
         
Always decreasing â€” "memoryless"
```

### The Formula

```
Parameter: Î» = rate (3 patients per hour)

PDF: f(x) = Î» Ã— e^(-Î»x)  for x â‰¥ 0

CDF: P(X â‰¤ t) = 1 - e^(-Î»t)
```

### Solving the ER Question

```
Î» = 3 per hour
t = 0.5 hours (30 minutes)

P(X â‰¤ 0.5) = 1 - e^(-3 Ã— 0.5)
P(X â‰¤ 0.5) = 1 - e^(-1.5)
P(X â‰¤ 0.5) = 1 - 0.223
P(X â‰¤ 0.5) â‰ˆ 0.777 or 77.7%
```

### Key Properties

```
Mean:     Î¼ = 1/Î» = 1/3 hour = 20 minutes
Variance: ÏƒÂ² = 1/Î»Â²

Average wait time = 20 minutes between patients.
```

### The Memoryless Property

Just like geometric distribution, exponential "forgets" the past!

If you've already waited 10 minutes, the expected additional wait is **still** 20 minutes â€” not 10 minutes!

### Real-Life Examples

| Scenario | Î» | Mean (1/Î») |
|----------|---|------------|
| Time between calls | 5/hour | 12 minutes |
| Lifetime of a lightbulb | 0.001/hour | 1000 hours |
| Time between earthquakes | 0.08/year | 12.5 years |
| Time until component failure | 0.02/day | 50 days |

---

# 10. Gamma Distribution
## *Time Until k Events*

---

## ğŸ“– Story: The Restaurant Kitchen

A busy restaurant gets orders at a rate of **6 per hour**. The chef wants to know:

*What's the average time until the 5th order arrives?*

### The Gamma Distribution

Generalization of exponential â€” waits for **k events** instead of 1.

```
Parameters:
- k (or Î±) = shape = number of events (5 orders)
- Î» (or 1/Î²) = rate (6 per hour)
```

### Visualization

```
Density
   â”‚
   â”‚       â•­â”€â”€â•®
   â”‚      â•­â•¯  â•°â•®
   â”‚     â•­â•¯    â•°â•®
   â”‚    â•­â•¯      â•°â”€â•®
   â”‚  â•­â”€â•¯         â•°â”€â”€â•®
   â”‚â•­â”€â•¯              â•°â”€â”€â”€â”€â”€â”€â”€â”€
   0â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
           Time
           
Shape depends on k:
- k=1: Exponential (always decreasing)
- k>1: Rises then falls (has a peak)
```

### Key Properties

```
Mean:     Î¼ = k/Î» = 5/6 hour â‰ˆ 50 minutes
Variance: ÏƒÂ² = k/Î»Â²

On average, 50 minutes until 5 orders.
```

### Special Cases

| k value | Distribution |
|---------|--------------|
| k = 1 | Exponential |
| k = n/2, Î» = 1/2 | Chi-squared (n degrees of freedom) |

### Real-Life Examples

- Time until nth customer
- Total rainfall over k days
- Aggregate insurance claims
- Time to complete k tasks

---

# 11. Beta Distribution
## *Modeling Probabilities*

---

## ğŸ“– Story: The A/B Test

Nadia is running an A/B test for a website. After some data:
- Version A: 80 conversions, 20 non-conversions
- She wants to model **uncertainty about the true conversion rate**

### The Beta Distribution

Perfect for modeling **unknown probabilities** or **proportions**.

```
Parameters:
- Î± (alpha) = "pseudo-successes" + 1
- Î² (beta) = "pseudo-failures" + 1

Values are between 0 and 1 (like probabilities!)
```

### Visualization

```
Different shapes based on Î± and Î²:

Î±=1,Î²=1 (Uniform)      Î±=5,Î²=2              Î±=2,Î²=5
â”‚                      â”‚      â•­â•®            â”‚   â•­â•®
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”‚     â•­â•¯â•°â•®           â”‚  â•­â•¯â•°â•®
â”‚                      â”‚    â•­â•¯  â•°â”€          â”‚â•­â”€â•¯  â•°â•®
â”‚                      â”‚  â•­â”€â•¯               â•°â•¯     â•°â”€â”€
0â”€â”€â”€â”€â”€â”€â”€â”€1             0â”€â”€â”€â”€â”€â”€â”€â”€1           0â”€â”€â”€â”€â”€â”€â”€â”€1
 "No info"              "Skewed right"       "Skewed left"
```

### Key Properties

```
Mean:     Î¼ = Î±/(Î±+Î²)
Variance: ÏƒÂ² = Î±Î²/[(Î±+Î²)Â²(Î±+Î²+1)]

For Nadia: Î±=81, Î²=21
Mean = 81/102 â‰ˆ 0.794 or 79.4% conversion rate
```

### Why Beta is Special

The Beta distribution is the **conjugate prior** for binomial likelihood in Bayesian statistics. This makes updating beliefs elegant:

```
Prior: Beta(Î±, Î²)
Data: k successes in n trials
Posterior: Beta(Î±+k, Î²+n-k)
```

### Real-Life Examples

- Conversion rates
- Batting averages
- Defect rates
- Election polling (proportion of votes)

---

# 12. Chi-Squared (Ï‡Â²) Distribution
## *Testing Variance and Fit*

---

## ğŸ“– Story: The Quality Control Test

A machine is supposed to produce bolts with diameter variance of **0.04 mmÂ²**. The quality manager takes 25 samples and calculates the sample variance.

*Is the machine variance significantly different from specification?*

### The Chi-Squared Distribution

Arises when you sum squared standard normal variables:

```
If Zâ‚, Zâ‚‚, ..., Zâ‚– are standard normal,
then Zâ‚Â² + Zâ‚‚Â² + ... + Zâ‚–Â² ~ Ï‡Â²(k)

Parameter: k = degrees of freedom
```

### Visualization

```
Density
   â”‚
   â”‚  â•­â”€â•®
   â”‚ â•­â•¯ â•°â•®
   â”‚â•­â•¯   â•°â”€â•®
   â”‚â•¯      â•°â”€â”€â•®
   â”‚          â•°â”€â”€â”€â”€â•®
   â”‚               â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   0â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          Ï‡Â² value
          
Right-skewed, becomes more normal as k increases
```

### Key Properties

```
Mean:     Î¼ = k
Variance: ÏƒÂ² = 2k

For k=25: Mean=25, Variance=50
```

### Common Uses

1. **Testing variance:** Is ÏƒÂ² equal to a specified value?
2. **Goodness of fit:** Does data follow expected distribution?
3. **Independence tests:** Are two categorical variables related?

---

# 13. Student's t-Distribution
## *Small Sample Inference*

---

## ğŸ“– Story: The New Medicine

Dr. Rahman tests a new medicine on **12 patients** and measures improvement. With such a small sample, can he trust the results?

### The Problem with Small Samples

When n is small:
- Sample mean is variable
- Sample standard deviation is unreliable
- Normal distribution assumptions don't hold well

### The t-Distribution

Accounts for uncertainty in estimating Ïƒ from small samples.

```
Parameter: Î½ (nu) = degrees of freedom = n - 1

As Î½ â†’ âˆ, t-distribution â†’ normal distribution
```

### Visualization: t vs Normal

```
         â”‚
         â”‚    â•­â”€ Normal â”€â•®
         â”‚   â•±     â”‚     â•²
         â”‚  â•±      â”‚      â•²
         â”‚ â•±   â•±â”€â”€â”€â”¼â”€â”€â”€â•²   â•²  â† t-distribution
         â”‚â•±  â•±     â”‚     â•²  â•²    (heavier tails)
    â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                   0
                   
t-distribution has "fatter tails" (more probability in extremes)
```

### Key Properties

```
Mean:     Î¼ = 0 (for Î½ > 1)
Variance: ÏƒÂ² = Î½/(Î½-2) for Î½ > 2

When Î½=10: Variance = 10/8 = 1.25 (larger than normal's 1)
```

### When to Use t vs Normal

| Sample Size | Use |
|-------------|-----|
| n < 30 | t-distribution |
| n â‰¥ 30 | Normal (approximately) |

### Real-Life Uses

- Testing means with small samples
- Confidence intervals for mean
- Regression coefficients
- A/B tests with limited data

---

# 14. F-Distribution
## *Comparing Variances*

---

## ğŸ“– Story: Two Factories

Two factories produce the same product. Management wants to know:

*Is the variance in quality the same at both factories?*

### The F-Distribution

Ratio of two chi-squared distributions:

```
F = (Ï‡â‚Â²/dâ‚) / (Ï‡â‚‚Â²/dâ‚‚)

Parameters:
- dâ‚ = numerator degrees of freedom
- dâ‚‚ = denominator degrees of freedom
```

### Key Properties

```
Mean:     Î¼ = dâ‚‚/(dâ‚‚-2)  for dâ‚‚ > 2
```

### Visualization

```
Density
   â”‚
   â”‚â•®
   â”‚â•°â•®
   â”‚ â•°â•®
   â”‚  â•°â”€â•®
   â”‚    â•°â”€â”€â•®
   â”‚       â•°â”€â”€â”€â”€â•®
   â”‚            â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   0â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          F value
          
Right-skewed, only positive values
```

### Common Uses

1. **ANOVA:** Comparing means across groups
2. **Variance comparison:** Are two variances equal?
3. **Regression:** Testing overall model significance

---

# Distribution Family Tree

```
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚    BERNOULLI    â”‚
                         â”‚   (Single trial)â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â†“             â†“             â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ BINOMIAL  â”‚  â”‚ GEOMETRIC â”‚  â”‚  POISSON  â”‚
            â”‚(n trials) â”‚  â”‚(1st success)â”‚  â”‚(rare events)
            â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                  â”‚              â”‚              â”‚
                  â†“              â†“              â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  NORMAL   â”‚  â”‚ NEGATIVE  â”‚  â”‚EXPONENTIALâ”‚
            â”‚(nâ†’âˆ, CLT) â”‚  â”‚ BINOMIAL  â”‚  â”‚(wait time)â”‚
            â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚(k successes)â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                  â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â†“
       â†“          â†“          â†“           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚   GAMMA   â”‚
 â”‚CHI-SQUAREâ”‚ â”‚  t   â”‚ â”‚ LOGNORMALâ”‚      â”‚(k waits)  â”‚
 â”‚  (ZÂ²s)   â”‚ â”‚(small n)â”‚          â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â†“
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚    F     â”‚
 â”‚(Ï‡Â² ratio)â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# Quick Reference Summary

## Discrete Distributions

| Distribution | Parameters | Mean | Variance | Use Case |
|--------------|------------|------|----------|----------|
| Bernoulli | p | p | p(1-p) | Single yes/no |
| Binomial | n, p | np | np(1-p) | Successes in n trials |
| Poisson | Î» | Î» | Î» | Events per interval |
| Geometric | p | 1/p | (1-p)/pÂ² | Trials until first success |
| Neg. Binomial | k, p | k/p | k(1-p)/pÂ² | Trials until k successes |
| Hypergeometric | N, K, n | nK/N | Complex | Sampling without replacement |

## Continuous Distributions

| Distribution | Parameters | Mean | Variance | Use Case |
|--------------|------------|------|----------|----------|
| Uniform | a, b | (a+b)/2 | (b-a)Â²/12 | Equal probability in range |
| Normal | Î¼, Ïƒ | Î¼ | ÏƒÂ² | Natural phenomena |
| Exponential | Î» | 1/Î» | 1/Î»Â² | Time between events |
| Gamma | k, Î» | k/Î» | k/Î»Â² | Time until k events |
| Beta | Î±, Î² | Î±/(Î±+Î²) | Complex | Modeling probabilities |
| Chi-squared | k | k | 2k | Variance testing |
| t | Î½ | 0 | Î½/(Î½-2) | Small sample means |
| F | dâ‚, dâ‚‚ | dâ‚‚/(dâ‚‚-2) | Complex | Comparing variances |

---

# Decision Flowchart: Which Distribution?

```
START: What are you measuring?
         â”‚
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â”‚         â”‚
Countable?  Measurable?
    â”‚         â”‚
    â†“         â†“
DISCRETE   CONTINUOUS
    â”‚         â”‚
    â”‚    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    â”‚         â”‚        â”‚          â”‚
    â”‚  Time?   Proportion? Testing?  Natural?
    â”‚    â”‚         â”‚        â”‚          â”‚
    â”‚    â†“         â†“        â†“          â†“
    â”‚  Expo/    Beta    Chi-sq/t/F  Normal
    â”‚  Gamma
    â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                        â”‚
    Fixed trials?          Events in interval?
         â”‚                        â”‚
         â†“                        â†“
      â”Œâ”€â”€â”´â”€â”€â”                  POISSON
      â”‚     â”‚
 With repl? Without?
      â”‚     â”‚
      â†“     â†“
  BINOMIAL HYPERGEOMETRIC
```

---

## Final Wisdom ğŸŒŸ

> **Every random phenomenon in nature follows some distribution.**
> 
> Your job is to recognize the pattern and choose the right tool!

Understanding distributions is the foundation of:
- Statistical inference
- Machine learning
- Quality control
- Risk analysis
- Scientific research

---

*Master these distributions, and you can model almost anything in the world! ğŸŒ*