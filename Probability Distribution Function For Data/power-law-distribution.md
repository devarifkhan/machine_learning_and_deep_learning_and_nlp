# Power Law Distribution
## The Mathematics of Extremes and Inequality ğŸ“Š

---

## The World of Extremes

Have you noticed these strange patterns?

- **Wealth:** The richest 1% own more than the bottom 50% combined ğŸ’°
- **Cities:** A few mega-cities, millions of small towns ğŸ™ï¸
- **Websites:** Google gets billions of visits; most sites get almost none ğŸŒ
- **Earthquakes:** Many tiny tremors, rare devastating quakes ğŸŒ
- **Words:** "The" appears millions of times; most words are rare ğŸ“š
- **Social Media:** A few influencers have millions of followers; most have few ğŸ“±

These aren't coincidences. They all follow **Power Law Distributions** â€” the mathematics of extreme inequality and "the rich get richer."

---

## ğŸ“– Story: The YouTube Paradox

Imagine you're analyzing YouTube channels in Bangladesh:

| Channel Size | Number of Channels | Total Subscribers |
|--------------|-------------------|-------------------|
| 10M+ subscribers | 5 | 75 million |
| 1M-10M | 50 | 150 million |
| 100K-1M | 500 | 200 million |
| 10K-100K | 5,000 | 150 million |
| 1K-10K | 50,000 | 150 million |
| < 1K | 500,000 | 75 million |

**The Pattern:**
- A tiny fraction of channels (top 0.01%) have most subscribers
- Each "tier" down has ~10Ã— more channels but similar total reach
- This is the **Power Law** at work!

---

## What is a Power Law Distribution?

A **Power Law Distribution** describes phenomena where the probability of an event decreases as a **power** of its size.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚              POWER LAW DISTRIBUTION                          â”‚
â”‚                                                             â”‚
â”‚   Basic Form:                                               â”‚
â”‚                                                             â”‚
â”‚       P(X = x) âˆ x^(-Î±)                                     â”‚
â”‚                                                             â”‚
â”‚   Where:                                                    â”‚
â”‚   â€¢ x = the value (size, frequency, etc.)                   â”‚
â”‚   â€¢ Î± = the power law exponent (typically 2 < Î± < 3)        â”‚
â”‚   â€¢ âˆ means "proportional to"                               â”‚
â”‚                                                             â”‚
â”‚   Key Feature: "HEAVY TAIL" â€” extreme events are            â”‚
â”‚                more likely than normal distributions        â”‚
â”‚                would predict!                               â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## The Power Law Formula

### Probability Density Function (PDF)

For continuous power law with minimum value x_min:

```
f(x) = (Î± - 1) / x_min Ã— (x / x_min)^(-Î±)

     = C Ã— x^(-Î±)    for x â‰¥ x_min

Where C is a normalization constant
```

### Complementary CDF (Survival Function)

The probability of being **greater than** x:

```
P(X > x) = (x / x_min)^(-Î± + 1) = (x / x_min)^(1-Î±)
```

### The Signature: Linear on Log-Log Plot

```
log(P(X > x)) = (1-Î±) Ã— log(x) + constant

On a log-log plot, power law appears as a STRAIGHT LINE!
```

---

## Visualization: The Heavy Tail

### Power Law vs Normal Distribution

```
LINEAR SCALE                          LOG-LOG SCALE
                                      
P(x)                                  log P(x)
â”‚                                     â”‚
â”‚â–ˆ                                    â”‚â—
â”‚â–ˆ                                    â”‚ â—
â”‚â–ˆ                                    â”‚  â—
â”‚â–ˆâ–‘                                   â”‚   â—
â”‚â–ˆâ–‘â–‘                                  â”‚    â—
â”‚â–ˆâ–‘â–‘â–‘                                 â”‚     â—
â”‚â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘                        â”‚      â—â—â—â—â—â—â—â—
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ x               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ log x

â–ˆ = Power Law                         Power Law = STRAIGHT LINE
â–‘ = Normal                            Normal = Curved (falls off fast)

The "heavy tail" extends much further than normal!
```

### Why "Heavy Tail" Matters

```
Normal Distribution:                 Power Law Distribution:
                                     
     â•­â”€â”€â”€â•®                           â”‚â–ˆ
    â•­â•¯   â•°â•®                          â”‚â–ˆ
   â•­â•¯     â•°â•®                         â”‚â–ˆ
  â•­â•¯       â•°â•®                        â”‚â–ˆâ–‘
 â•­â•¯         â•°â•®                       â”‚â–ˆâ–‘â–‘
â•­â•¯           â•°â•®                      â”‚â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Tails die off                        Tail extends FAR
exponentially fast                   (extreme events more likely)

P(X > 6Ïƒ) â‰ˆ 0.000000001             P(X > 100Ã—median) = significant!
```

---

## The Pareto Distribution (Type I Power Law)

The most famous power law, named after Vilfredo Pareto who studied wealth distribution.

### Definition

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚              PARETO DISTRIBUTION                             â”‚
â”‚                                                             â”‚
â”‚   PDF:  f(x) = (Î± Ã— x_min^Î±) / x^(Î±+1)    for x â‰¥ x_min    â”‚
â”‚                                                             â”‚
â”‚   CDF:  F(x) = 1 - (x_min / x)^Î±                           â”‚
â”‚                                                             â”‚
â”‚   Survival: P(X > x) = (x_min / x)^Î±                        â”‚
â”‚                                                             â”‚
â”‚   Parameters:                                               â”‚
â”‚   â€¢ x_min = minimum value (scale parameter)                 â”‚
â”‚   â€¢ Î± = shape parameter (Pareto index)                      â”‚
â”‚                                                             â”‚
â”‚   Notation: X ~ Pareto(x_min, Î±)                            â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Properties of Pareto

| Property | Formula | Condition |
|----------|---------|-----------|
| **Mean** | Î± Ã— x_min / (Î± - 1) | Î± > 1 |
| **Variance** | x_minÂ² Ã— Î± / ((Î±-1)Â² Ã— (Î±-2)) | Î± > 2 |
| **Median** | x_min Ã— 2^(1/Î±) | Always |
| **Mode** | x_min | Always |

**Warning:** Mean is **infinite** if Î± â‰¤ 1, variance is **infinite** if Î± â‰¤ 2!

---

## The 80/20 Rule (Pareto Principle)

The famous principle: **80% of effects come from 20% of causes**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚                   THE 80/20 RULE                             â”‚
â”‚                                                             â”‚
â”‚   â€¢ 80% of wealth owned by 20% of people                    â”‚
â”‚   â€¢ 80% of sales from 20% of customers                      â”‚
â”‚   â€¢ 80% of bugs in 20% of code                              â”‚
â”‚   â€¢ 80% of results from 20% of effort                       â”‚
â”‚   â€¢ 80% of complaints from 20% of customers                 â”‚
â”‚                                                             â”‚
â”‚   Mathematically: Pareto with Î± â‰ˆ 1.16 gives 80/20          â”‚
â”‚                                                             â”‚
â”‚   General form: Top p fraction has (1-p)^Î± of total         â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Visualizing 80/20

```
Cumulative % of Total
100%â”‚                              â—â”€â”€â”€â”€â”€â”€â”€â”€
    â”‚                         â—â”€â”€â”€â”€â•¯
 80%â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â•¯
    â”‚                 â—â”€â”€â”€â•¯â”‚
    â”‚            â—â”€â”€â”€â”€â•¯    â”‚
    â”‚       â—â”€â”€â”€â”€â•¯         â”‚
    â”‚  â—â”€â”€â”€â”€â•¯              â”‚
    â”‚â—â”€â•¯                   â”‚
  0%â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    0%                    20%              100%
              % of Population
              
    Top 20% owns 80% of the total!
```

---

## Zipf's Law (Discrete Power Law)

For **ranked** discrete data (like word frequencies):

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚                    ZIPF'S LAW                                â”‚
â”‚                                                             â”‚
â”‚   Frequency of rank r:  f(r) âˆ 1/r^s                        â”‚
â”‚                                                             â”‚
â”‚   Where:                                                    â”‚
â”‚   â€¢ r = rank (1st most common, 2nd most common, etc.)       â”‚
â”‚   â€¢ s = Zipf exponent (often â‰ˆ 1)                           â”‚
â”‚                                                             â”‚
â”‚   Example (Word frequencies):                               â”‚
â”‚   â€¢ "the" (rank 1): frequency = f                           â”‚
â”‚   â€¢ "of" (rank 2): frequency â‰ˆ f/2                          â”‚
â”‚   â€¢ "and" (rank 3): frequency â‰ˆ f/3                         â”‚
â”‚   â€¢ "to" (rank 4): frequency â‰ˆ f/4                          â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example: City Populations

| Rank | City | Population | Expected (Zipf) |
|------|------|------------|-----------------|
| 1 | Dhaka | 22 million | 22 million |
| 2 | Chittagong | 5 million | 11 million |
| 3 | Khulna | 1.5 million | 7.3 million |
| 4 | Rajshahi | 0.9 million | 5.5 million |

*Real data doesn't follow Zipf perfectly, but the pattern is clear!*

---

## Scale-Free Property

Power laws are **scale-free** â€” they look the same at any scale!

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚              SCALE-FREE (SELF-SIMILAR)                       â”‚
â”‚                                                             â”‚
â”‚   If you "zoom in" on a power law distribution,             â”‚
â”‚   it looks the same as the original!                        â”‚
â”‚                                                             â”‚
â”‚   Mathematically: P(X > cx) / P(X > x) = c^(-Î±+1)           â”‚
â”‚                                                             â”‚
â”‚   This ratio depends only on c, not on x!                   â”‚
â”‚                                                             â”‚
â”‚   Example:                                                  â”‚
â”‚   â€¢ P(wealth > $10M) / P(wealth > $1M) = ratio             â”‚
â”‚   â€¢ P(wealth > $100M) / P(wealth > $10M) = SAME ratio      â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Visual: Self-Similarity

```
Full Distribution        Zoomed In (Ã—10)        Zoomed In More (Ã—100)

   â”‚â–ˆ                         â”‚â–ˆ                        â”‚â–ˆ
   â”‚â–ˆ                         â”‚â–ˆ                        â”‚â–ˆ
   â”‚â–ˆâ–‘                        â”‚â–ˆâ–‘                       â”‚â–ˆâ–‘
   â”‚â–ˆâ–‘â–‘â–‘                      â”‚â–ˆâ–‘â–‘â–‘                     â”‚â–ˆâ–‘â–‘â–‘
   â”‚â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘                 â”‚â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘                â”‚â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
   
   SAME SHAPE at every scale! (Unlike normal distribution)
```

---

## "The Rich Get Richer" (Preferential Attachment)

Power laws often emerge from **preferential attachment** â€” success breeds more success.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚           PREFERENTIAL ATTACHMENT MECHANISM                  â”‚
â”‚                                                             â”‚
â”‚   "The probability of getting more is proportional          â”‚
â”‚    to how much you already have"                            â”‚
â”‚                                                             â”‚
â”‚   Examples:                                                 â”‚
â”‚   â€¢ Popular videos get recommended more â†’ more views        â”‚
â”‚   â€¢ Cited papers get noticed more â†’ more citations          â”‚
â”‚   â€¢ Rich people have more investment opportunities          â”‚
â”‚   â€¢ Big cities attract more migrants                        â”‚
â”‚   â€¢ Popular websites get more backlinks                     â”‚
â”‚                                                             â”‚
â”‚   This FEEDBACK LOOP creates power law distributions!       â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Mathematical Model (BarabÃ¡si-Albert)

```
New node connects to existing node i with probability:

P(connect to i) = k_i / Î£ k_j

Where k_i = current number of connections of node i

Result: Degree distribution follows power law!
```

---

## The Exponent Î±: What It Tells Us

The **exponent Î±** determines how "extreme" the inequality is:

| Î± Value | Inequality | Mean | Variance | Example |
|---------|------------|------|----------|---------|
| 1 < Î± â‰¤ 2 | Extreme | Infinite | Infinite | Wealth in some countries |
| 2 < Î± â‰¤ 3 | High | Finite | Infinite | City sizes, citations |
| Î± > 3 | Moderate | Finite | Finite | Word frequencies |

### Visual: Effect of Î±

```
Î± = 1.5 (Extreme)          Î± = 2.5 (Moderate)         Î± = 4 (Mild)

â”‚â–ˆ                         â”‚â–ˆ                         â”‚â–ˆâ–‘
â”‚â–ˆ                         â”‚â–ˆâ–‘                        â”‚â–ˆâ–‘â–‘
â”‚â–ˆ                         â”‚â–ˆâ–‘â–‘                       â”‚â–ˆâ–‘â–‘â–‘â–‘
â”‚â–ˆâ–‘                        â”‚â–ˆâ–‘â–‘â–‘â–‘                     â”‚â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘
â”‚â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘      â”‚â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘            â”‚â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Heavy tail, extreme         Moderate tail              Lighter tail, closer
inequality                                             to exponential
```

### Typical Î± Values in Nature

| Phenomenon | Î± Value |
|------------|---------|
| Word frequency (Zipf) | â‰ˆ 1.0 |
| City populations | â‰ˆ 1.1 |
| Wealth distribution | 1.5 - 2.0 |
| Website traffic | â‰ˆ 2.0 |
| Citations | 2.5 - 3.0 |
| Earthquake magnitude | â‰ˆ 2.0 |
| Moon crater sizes | â‰ˆ 2.0 |
| Solar flare intensity | â‰ˆ 2.0 |

---

## ğŸ“– Real-Life Examples

### Example 1: Wealth Distribution

Wealth in most countries follows a Pareto distribution:

```
X ~ Pareto(x_min = $10,000, Î± = 1.5)

Top 1%: P(X > x_99) where x_99 â‰ˆ $1.7 million
This 1% owns about 40% of total wealth!

Top 0.1%: P(X > x_99.9) where x_99.9 â‰ˆ $17 million
This 0.1% owns about 20% of total wealth!
```

### Example 2: Earthquake Magnitudes

The Gutenberg-Richter law:

```
logâ‚â‚€(N) = a - bM

Where:
N = number of earthquakes â‰¥ magnitude M
b â‰ˆ 1 (globally)

This means: For every magnitude 7 earthquake,
there are ~10 magnitude 6 earthquakes,
~100 magnitude 5 earthquakes, etc.
```

### Example 3: Website Traffic

```
Daily visits follow power law with Î± â‰ˆ 2:

â€¢ Top 100 sites: Billions of visits
â€¢ Next 1,000 sites: Millions each
â€¢ Next 10,000 sites: Thousands each
â€¢ Next 100,000 sites: Hundreds each
â€¢ Millions of sites: Single digits
```

### Example 4: Social Media Followers

```
Followers ~ PowerLaw(Î± â‰ˆ 2.1)

â€¢ 1 account: 100M+ followers (top celebrity)
â€¢ 10 accounts: 10M+ followers
â€¢ 100 accounts: 1M+ followers
â€¢ 1,000 accounts: 100K+ followers
â€¢ 10,000 accounts: 10K+ followers
â€¢ 100,000 accounts: 1K+ followers
â€¢ 1,000,000 accounts: < 100 followers
```

### Example 5: File Sizes

```
File sizes on hard drives:

â€¢ Few huge files (videos, databases)
â€¢ Some large files (photos, documents)
â€¢ Many small files (text, configs)

Size distribution â‰ˆ Pareto(Î± â‰ˆ 1.5)
```

---

## Power Law vs Other Distributions

### Comparison Table

| Property | Normal | Exponential | Power Law |
|----------|--------|-------------|-----------|
| **Tail** | Light (dies fast) | Medium | Heavy (dies slow) |
| **Extreme events** | Very rare | Rare | Not so rare! |
| **Scale-free** | No | No | Yes |
| **Mean** | Always finite | Always finite | May be infinite |
| **Variance** | Always finite | Always finite | May be infinite |
| **Log-log plot** | Curved down | Curved down | **Straight line** |

### Visual Comparison

```
P(X > x) on log-log scale

log P(X>x)
    â”‚
    â”‚â—                          
    â”‚â—â—â—‹                        â— Power Law (straight)
    â”‚  â—â—‹â—‹                      â—‹ Exponential (curved)
    â”‚   â—â—‹â—‹â—‹                    â–¡ Normal (very curved)
    â”‚    â—â—â—‹â—‹â—‹â–¡
    â”‚      â—â—â—‹â—‹â—‹â—‹â–¡â–¡
    â”‚        â—â—â—â—‹â—‹â—‹â—‹â—‹â–¡â–¡â–¡â–¡â–¡
    â”‚           â—â—â—â—â—‹â—‹â—‹â—‹â—‹â—‹â—‹â–¡â–¡â–¡â–¡â–¡â–¡â–¡â–¡â–¡
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ log x
    
Power law maintains straight line (constant slope)
Others curve downward (tail dies off faster)
```

---

## Detecting Power Laws

### Method 1: Log-Log Plot

```python
import numpy as np
import matplotlib.pyplot as plt

# If power law, log-log plot should be LINEAR
log_x = np.log10(x_values)
log_p = np.log10(probabilities)

plt.plot(log_x, log_p, 'o')
plt.xlabel('log(x)')
plt.ylabel('log(P(X > x))')
# Should see straight line!
```

### Method 2: Fit and Compare (MLE)

```python
import powerlaw  # pip install powerlaw

# Fit power law
fit = powerlaw.Fit(data)
print(f"Estimated Î±: {fit.alpha}")
print(f"x_min: {fit.xmin}")

# Compare to alternatives
R, p = fit.distribution_compare('power_law', 'exponential')
# If R > 0 and p < 0.05: power law is better fit
```

### Method 3: Kolmogorov-Smirnov Test

Compare empirical CDF to theoretical power law CDF.

---

## Mathematical Properties

### Moments

```
E[X^n] = Î± Ã— x_min^n / (Î± - n)    for n < Î±

â€¢ E[X] exists only if Î± > 1
â€¢ E[XÂ²] exists only if Î± > 2
â€¢ Higher moments require larger Î±
```

### Generating Power Law Random Variables

Using inverse transform:

```
If U ~ Uniform(0, 1), then:

X = x_min Ã— (1 - U)^(-1/Î±) ~ Pareto(x_min, Î±)

Or equivalently:

X = x_min Ã— U^(-1/Î±)
```

### Sum of Power Laws

Unlike normal distributions, sum of power law variables is **NOT** power law!

However, the **maximum** of power law variables IS power law:

```
max(Xâ‚, Xâ‚‚, ..., Xâ‚™) ~ Pareto(x_min, Î±)  (approximately, for large max)
```

---

## Python Implementation

### Using SciPy (Pareto)

```python
import numpy as np
from scipy import stats

# Pareto distribution: shape=Î±, scale=x_min
alpha = 2.5
x_min = 1

pareto = stats.pareto(b=alpha, scale=x_min)

# PDF and CDF at x = 3
print(f"f(3) = {pareto.pdf(3):.4f}")
print(f"P(X â‰¤ 3) = {pareto.cdf(3):.4f}")
print(f"P(X > 3) = {1 - pareto.cdf(3):.4f}")

# Mean (only exists if Î± > 1)
if alpha > 1:
    theoretical_mean = alpha * x_min / (alpha - 1)
    print(f"Theoretical mean: {theoretical_mean:.4f}")
    print(f"SciPy mean: {pareto.mean():.4f}")

# Generate samples
samples = pareto.rvs(size=10000)
print(f"Sample mean: {samples.mean():.4f}")
print(f"Sample median: {np.median(samples):.4f}")
```

### Using powerlaw Package

```python
import powerlaw
import numpy as np

# Generate synthetic power law data
alpha_true = 2.5
x_min = 1
n = 10000
data = x_min * np.random.pareto(alpha_true - 1, n) + x_min

# Fit power law
fit = powerlaw.Fit(data, xmin=x_min)
print(f"Estimated Î±: {fit.alpha:.4f}")
print(f"True Î±: {alpha_true}")

# Plot
fig = fit.plot_pdf(color='b', linewidth=2)
fit.power_law.plot_pdf(color='r', linestyle='--', ax=fig)
plt.show()

# Compare to other distributions
print("\nComparing to alternatives:")
R, p = fit.distribution_compare('power_law', 'exponential')
print(f"vs Exponential: R={R:.3f}, p={p:.4f}")

R, p = fit.distribution_compare('power_law', 'lognormal')
print(f"vs Log-Normal: R={R:.3f}, p={p:.4f}")
```

### Manual Implementation

```python
import numpy as np

def pareto_pdf(x, x_min, alpha):
    """Pareto PDF"""
    if x < x_min:
        return 0
    return alpha * (x_min ** alpha) / (x ** (alpha + 1))

def pareto_cdf(x, x_min, alpha):
    """Pareto CDF"""
    if x < x_min:
        return 0
    return 1 - (x_min / x) ** alpha

def pareto_survival(x, x_min, alpha):
    """P(X > x)"""
    if x < x_min:
        return 1
    return (x_min / x) ** alpha

def pareto_quantile(p, x_min, alpha):
    """Inverse CDF (quantile function)"""
    return x_min / ((1 - p) ** (1/alpha))

def generate_pareto(n, x_min, alpha):
    """Generate n Pareto random variables"""
    u = np.random.uniform(0, 1, n)
    return x_min / (u ** (1/alpha))

# Example
alpha, x_min = 2.5, 1

# Generate samples
samples = generate_pareto(10000, x_min, alpha)

# Verify
print(f"Sample mean: {samples.mean():.4f}")
print(f"Theoretical mean: {alpha * x_min / (alpha - 1):.4f}")

# Find extreme values
print(f"Max value: {samples.max():.2f}")
print(f"99th percentile: {np.percentile(samples, 99):.2f}")
```

### Visualization

```python
import matplotlib.pyplot as plt
import numpy as np
from scipy import stats

fig, axes = plt.subplots(2, 2, figsize=(14, 10))

# Parameters
alpha = 2.5
x_min = 1

# Plot 1: PDF (linear scale)
ax1 = axes[0, 0]
x = np.linspace(1, 10, 1000)
pareto = stats.pareto(b=alpha, scale=x_min)
ax1.plot(x, pareto.pdf(x), 'b-', linewidth=2)
ax1.fill_between(x, pareto.pdf(x), alpha=0.3)
ax1.set_xlabel('x')
ax1.set_ylabel('f(x)')
ax1.set_title(f'Pareto PDF (Î±={alpha})')

# Plot 2: PDF (log-log scale)
ax2 = axes[0, 1]
x = np.logspace(0, 3, 1000)
ax2.loglog(x, pareto.pdf(x), 'b-', linewidth=2)
ax2.set_xlabel('x (log scale)')
ax2.set_ylabel('f(x) (log scale)')
ax2.set_title('Log-Log Plot (Should be straight line)')
ax2.grid(True, alpha=0.3)

# Plot 3: CCDF (survival function)
ax3 = axes[1, 0]
x = np.logspace(0, 3, 1000)
ax3.loglog(x, 1 - pareto.cdf(x), 'b-', linewidth=2)
ax3.set_xlabel('x (log scale)')
ax3.set_ylabel('P(X > x) (log scale)')
ax3.set_title('Complementary CDF (Log-Log)')
ax3.grid(True, alpha=0.3)

# Plot 4: Different Î± values
ax4 = axes[1, 1]
x = np.linspace(1, 5, 1000)
for a in [1.5, 2.0, 2.5, 3.0, 4.0]:
    pareto_a = stats.pareto(b=a, scale=1)
    ax4.plot(x, pareto_a.pdf(x), label=f'Î± = {a}')
ax4.set_xlabel('x')
ax4.set_ylabel('f(x)')
ax4.set_title('Effect of Î± on PDF')
ax4.legend()

plt.tight_layout()
plt.show()
```

---

## Power Laws in Networks

Many real networks follow power law degree distributions:

### Examples

| Network | Î± (degree distribution) |
|---------|------------------------|
| World Wide Web | â‰ˆ 2.1 |
| Citation networks | â‰ˆ 3.0 |
| Social networks | 2.0 - 3.0 |
| Protein interactions | â‰ˆ 2.5 |
| Power grid | â‰ˆ 4.0 |

### The "Hub" Effect

```
Power law networks have HUBS â€” highly connected nodes

    â—‹           â—‹
     \         /
      \   â—   /        â— = Hub (very high degree)
       \ /|\ /         â—‹ = Regular nodes (low degree)
        â—â”€â”¼â”€â—
       / \|/ \
      /   â—   \
     /         \
    â—‹           â—‹

A few hubs connect to most of the network!
```

---

## Truncated Power Laws

Real-world power laws often have **cutoffs**:

```
f(x) âˆ x^(-Î±) Ã— exp(-x/x_max)

â€¢ Power law behavior for small x
â€¢ Exponential cutoff for large x
â€¢ x_max = characteristic scale where cutoff occurs
```

### Why Truncation?

- **Physical limits:** Maximum city size, maximum wealth
- **Finite sample:** We don't observe infinite data
- **Mechanism changes:** Different processes at extremes

---

## Common Mistakes to Avoid âš ï¸

### Mistake 1: Claiming Power Law Without Testing

âŒ **Wrong:** "This histogram looks heavy-tailed, must be power law!"

âœ… **Correct:** Use statistical tests (log-likelihood ratio, KS test)
Many distributions have heavy tails (log-normal, stretched exponential)

---

### Mistake 2: Fitting Entire Range

âŒ **Wrong:** Fitting power law from x = 0

âœ… **Correct:** Power laws only hold **above some x_min**
The lower part often follows different distribution

---

### Mistake 3: Linear Regression on Log-Log

âŒ **Wrong:** Using OLS regression on log-transformed data

âœ… **Correct:** Use Maximum Likelihood Estimation (MLE)
OLS gives biased estimates for power laws

---

### Mistake 4: Ignoring x_min

âŒ **Wrong:** "Î± = 2" (without specifying x_min)

âœ… **Correct:** Both Î± AND x_min are needed to fully specify the distribution

---

### Mistake 5: Assuming Infinite Mean Always

âŒ **Wrong:** "Power laws have infinite mean"

âœ… **Correct:** Mean is infinite only if Î± â‰¤ 1 (for Pareto parameterization)
Many real power laws have Î± > 2 and finite mean

---

## Practice Problems ğŸ“

### Problem 1: Basic Pareto
For X ~ Pareto(x_min = 100, Î± = 2), find P(X > 200).

<details>
<summary>Click for Answer</summary>

```
P(X > x) = (x_min / x)^Î±

P(X > 200) = (100 / 200)^2
           = (0.5)^2
           = 0.25 = 25%
```

</details>

---

### Problem 2: Finding the Mean
For X ~ Pareto(x_min = 1000, Î± = 3), find the mean.

<details>
<summary>Click for Answer</summary>

```
E[X] = Î± Ã— x_min / (Î± - 1)

E[X] = 3 Ã— 1000 / (3 - 1)
     = 3000 / 2
     = 1500

The mean (1500) is higher than x_min (1000) due to heavy tail!
```

</details>

---

### Problem 3: Percentile
For X ~ Pareto(x_min = 50, Î± = 1.5), find the 95th percentile.

<details>
<summary>Click for Answer</summary>

```
Quantile function: x_p = x_min / (1 - p)^(1/Î±)

x_0.95 = 50 / (1 - 0.95)^(1/1.5)
       = 50 / (0.05)^(0.667)
       = 50 / 0.136
       â‰ˆ 368

The top 5% have values above 368 (compared to minimum of 50!)
```

</details>

---

### Problem 4: 80/20 Check
For Pareto with Î± = 1.16, verify the 80/20 rule.

<details>
<summary>Click for Answer</summary>

```
For Pareto, top (1-p) fraction owns:
Fraction of total = p^(1 - 1/Î±)

Top 20% (p = 0.8):
Fraction = 0.8^(1 - 1/1.16)
         = 0.8^(1 - 0.862)
         = 0.8^0.138
         â‰ˆ 0.80

Yes! Top 20% owns about 80% of total when Î± â‰ˆ 1.16
```

</details>

---

### Problem 5: Comparing Extremes
If X ~ Pareto(1, 2) and Y ~ Exponential(1), compare P(X > 10) vs P(Y > 10).

<details>
<summary>Click for Answer</summary>

```
Power Law (Pareto):
P(X > 10) = (1/10)^2 = 0.01 = 1%

Exponential:
P(Y > 10) = e^(-10) â‰ˆ 0.0000454 = 0.00454%

Ratio: 1% / 0.00454% â‰ˆ 220

The power law gives extreme events 220Ã— more probability!
This is the essence of "heavy tail."
```

</details>

---

## Applications Summary

| Field | Application | What follows Power Law |
|-------|-------------|----------------------|
| **Economics** | Wealth inequality | Income, firm sizes |
| **Sociology** | Social influence | Followers, citations |
| **Technology** | Internet | Website traffic, file sizes |
| **Natural Science** | Catastrophes | Earthquakes, fires, floods |
| **Biology** | Ecology | Species abundance, gene expression |
| **Linguistics** | Language | Word frequencies |
| **Urban Planning** | Demographics | City sizes |
| **Finance** | Risk | Market crashes, returns |

---

## Summary: The Essence of Power Law

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    POWER LAW DISTRIBUTION                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   "The mathematics of extreme inequality"                        â”‚
â”‚                                                                  â”‚
â”‚   BASIC FORM:                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  P(X > x) âˆ x^(-Î±+1)                                     â”‚   â”‚
â”‚   â”‚                                                          â”‚   â”‚
â”‚   â”‚  Or equivalently: P(X = x) âˆ x^(-Î±)                      â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â”‚   KEY FEATURES:                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  â€¢ Heavy tail: Extreme events are NOT rare!              â”‚   â”‚
â”‚   â”‚  â€¢ Scale-free: Same pattern at all scales                â”‚   â”‚
â”‚   â”‚  â€¢ 80/20 rule: Few entities dominate                     â”‚   â”‚
â”‚   â”‚  â€¢ May have infinite mean/variance                       â”‚   â”‚
â”‚   â”‚  â€¢ Straight line on log-log plot                         â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â”‚   ARISES FROM:                                                   â”‚
â”‚   â€¢ Preferential attachment ("rich get richer")                  â”‚
â”‚   â€¢ Self-organized criticality                                   â”‚
â”‚   â€¢ Multiplicative processes                                     â”‚
â”‚   â€¢ Optimization under constraints                               â”‚
â”‚                                                                  â”‚
â”‚   COMMON FORMS:                                                  â”‚
â”‚   â€¢ Pareto distribution (continuous)                             â”‚
â”‚   â€¢ Zipf's law (discrete, ranked)                               â”‚
â”‚   â€¢ Power law with cutoff (truncated)                            â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Why Power Laws Matter

> **"Power laws reveal that extreme events are not anomalies â€” they're built into the system."**

Understanding power laws helps you:

| Insight | Implication |
|---------|-------------|
| **Expect extremes** | Plan for outliers, not just averages |
| **Avoid underestimating risk** | "Once in a century" events happen often |
| **Understand inequality** | Few winners, many losers is natural |
| **Design robust systems** | Networks, economies, infrastructure |
| **Model correctly** | Don't use normal distribution for everything |

The world is more extreme than we intuitively expect. Power laws quantify just how extreme! ğŸš€

---

*From wealth to websites, earthquakes to epidemics â€” when the math goes extreme, power laws explain why!* âš¡