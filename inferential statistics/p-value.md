# The p-value
## The Most Misunderstood Number in Statistics ğŸ²

---

## The Question That Started It All

Imagine you flip a coin 10 times and get **9 heads**.

Is this coin fair? Or is it biased?

- A fair coin *could* give 9 heads... it's just unlikely
- But how unlikely is "unlikely enough" to suspect cheating?

**The p-value answers exactly this question!**

---

## ğŸ“– Story: The Suspicious Dice

Rafiq runs a board game cafÃ© in Dhaka. A customer complains that the house dice are loaded (biased). Rafiq rolls the dice 60 times and gets the following:

| Face | Expected (Fair) | Observed |
|------|-----------------|----------|
| 1 | 10 | 5 |
| 2 | 10 | 8 |
| 3 | 10 | 9 |
| 4 | 10 | 11 |
| 5 | 10 | 12 |
| 6 | 10 | 15 |

The 6 appeared more often than expected. But is this just luck, or is the die actually biased?

**Rafiq calculates the p-value = 0.23 (23%)**

This means: "If the die were fair, there's a 23% chance of seeing results this extreme or more extreme just by random chance."

23% isn't that rare, so Rafiq concludes: **"No strong evidence the die is loaded."**

---

## What Exactly IS a p-value?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚                    THE p-VALUE                               â”‚
â”‚                                                             â”‚
â”‚   Definition:                                               â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                               â”‚
â”‚   The probability of obtaining results AT LEAST AS          â”‚
â”‚   EXTREME as what we observed, ASSUMING the null            â”‚
â”‚   hypothesis (Hâ‚€) is TRUE.                                  â”‚
â”‚                                                             â”‚
â”‚   In symbols:                                               â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                              â”‚
â”‚   p-value = P(data this extreme or more | Hâ‚€ is true)      â”‚
â”‚                                                             â”‚
â”‚   Key insight:                                              â”‚
â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                              â”‚
â”‚   Small p-value = Data is UNLIKELY under Hâ‚€                â”‚
â”‚                 = Evidence AGAINST Hâ‚€                       â”‚
â”‚                                                             â”‚
â”‚   Large p-value = Data is CONSISTENT with Hâ‚€               â”‚
â”‚                 = No strong evidence against Hâ‚€             â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## The p-value in Plain English

### What It Measures

```
"IF the null hypothesis were true,
 HOW SURPRISING would our data be?"

p = 0.01 (1%)   â†’ VERY surprising! Something's probably wrong with Hâ‚€
p = 0.05 (5%)   â†’ Quite surprising. Maybe Hâ‚€ isn't true?
p = 0.20 (20%)  â†’ Not that surprising. Hâ‚€ seems reasonable.
p = 0.80 (80%)  â†’ Not surprising at all. Hâ‚€ fits the data well.
```

### The Analogy: Court Trial

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   COURTROOM ANALOGY                                          â”‚
â”‚                                                             â”‚
â”‚   Hâ‚€ = "The defendant is innocent" (assumed true)           â”‚
â”‚   Evidence = The data we collected                          â”‚
â”‚   p-value = How likely is this evidence if truly innocent?  â”‚
â”‚                                                             â”‚
â”‚   Small p-value:                                            â”‚
â”‚   "This evidence would be very unlikely if the defendant    â”‚
â”‚    were truly innocent. Something doesn't add up."          â”‚
â”‚   â†’ Reject innocence (convict)                              â”‚
â”‚                                                             â”‚
â”‚   Large p-value:                                            â”‚
â”‚   "This evidence is consistent with innocence.              â”‚
â”‚    Nothing suspicious here."                                â”‚
â”‚   â†’ Cannot reject innocence (acquit)                        â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Visualizing the p-value

### One-Tailed Test (Right)

```
Hâ‚€: Î¼ = 100
Hâ‚: Î¼ > 100
Observed: XÌ„ = 108

                    Distribution under Hâ‚€
                    
                         â•­â”€â”€â”€â•®
                       â•­â”€â•¯   â•°â”€â•®
                      â•­â•¯       â•°â•®
                     â•­â•¯         â•°â•®
                    â•­â•¯           â•°â•®
                   â•­â•¯             â•°â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â† p-value
                  â•­â•¯              â”‚â•°â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    (shaded area)
                 â•­â•¯               â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
                â•¯                 â”‚    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
               â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                       100       108
                       (Hâ‚€)    (observed)
                       
p-value = P(XÌ„ â‰¥ 108 | Î¼ = 100)
        = Area in the shaded region
```

### One-Tailed Test (Left)

```
Hâ‚€: Î¼ = 100
Hâ‚: Î¼ < 100
Observed: XÌ„ = 92

                    Distribution under Hâ‚€
                    
                              â•­â”€â”€â”€â•®
                            â•­â”€â•¯   â•°â”€â•®
                           â•­â•¯       â•°â•®
                          â•­â•¯         â•°â•®
                         â•­â•¯           â•°â•®
          â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•¯             â•°â•®
         â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚               â•°â•®
        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â”‚                 â•°â•®
       â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯â”€â”€â”€â”€â”€
                      92        100
                  (observed)    (Hâ‚€)
                       
p-value = P(XÌ„ â‰¤ 92 | Î¼ = 100)
```

### Two-Tailed Test

```
Hâ‚€: Î¼ = 100
Hâ‚: Î¼ â‰  100
Observed: XÌ„ = 108

                    Distribution under Hâ‚€
                    
                         â•­â”€â”€â”€â•®
                       â•­â”€â•¯   â•°â”€â•®
                      â•­â•¯       â•°â•®
                     â•­â•¯         â•°â•®
                    â•­â•¯           â•°â•®
        â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•¯             â•°â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
       â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚             â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    â”‚             â”‚    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                   92     100    108
                   â”‚             â”‚
                   â””â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜
                    Both tails!
                       
p-value = P(|XÌ„ - 100| â‰¥ 8 | Î¼ = 100)
        = P(XÌ„ â‰¤ 92) + P(XÌ„ â‰¥ 108)
        = 2 Ã— P(XÌ„ â‰¥ 108)  [by symmetry]
```

---

## How to Interpret p-values

### The Decision Rule

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   DECISION RULE                                              â”‚
â”‚                                                             â”‚
â”‚   Choose a significance level Î± (typically 0.05)            â”‚
â”‚                                                             â”‚
â”‚   If p-value â‰¤ Î±:                                           â”‚
â”‚       â†’ REJECT Hâ‚€                                           â”‚
â”‚       â†’ "Statistically significant"                         â”‚
â”‚       â†’ "Evidence against Hâ‚€"                               â”‚
â”‚                                                             â”‚
â”‚   If p-value > Î±:                                           â”‚
â”‚       â†’ FAIL TO REJECT Hâ‚€                                   â”‚
â”‚       â†’ "Not statistically significant"                     â”‚
â”‚       â†’ "Insufficient evidence against Hâ‚€"                  â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Strength of Evidence Scale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                â”‚
â”‚   p-VALUE INTERPRETATION GUIDE                                  â”‚
â”‚   (Informal scale â€” use with caution!)                         â”‚
â”‚                                                                â”‚
â”‚   p > 0.10        No evidence against Hâ‚€                       â”‚
â”‚   0.05 < p â‰¤ 0.10  Weak evidence against Hâ‚€                    â”‚
â”‚   0.01 < p â‰¤ 0.05  Moderate evidence against Hâ‚€                â”‚
â”‚   0.001 < p â‰¤ 0.01 Strong evidence against Hâ‚€                  â”‚
â”‚   p â‰¤ 0.001       Very strong evidence against Hâ‚€              â”‚
â”‚                                                                â”‚
â”‚   âš ï¸ Warning: These are just guidelines, not strict rules!     â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Visual: The p-value Spectrum

```
Strong evidence                                      No evidence
against Hâ‚€                                          against Hâ‚€

â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
0    0.001    0.01      0.05     0.10          0.50            1

     â”‚         â”‚          â”‚        â”‚
     â”‚         â”‚          â”‚        â”‚
     â–¼         â–¼          â–¼        â–¼
   
"Highly    "Very    "Statistically  "Not
significant" significant" significant" significant"

â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                       Î± = 0.05
                    (common threshold)
```

---

## What p-value IS and IS NOT

### What p-value IS âœ…

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   âœ… p-value IS:                                            â”‚
â”‚                                                             â”‚
â”‚   â€¢ P(data this extreme or more | Hâ‚€ true)                 â”‚
â”‚   â€¢ A measure of compatibility between data and Hâ‚€          â”‚
â”‚   â€¢ Evidence against Hâ‚€ (smaller = more evidence)          â”‚
â”‚   â€¢ A continuous measure (not just "significant" or not)   â”‚
â”‚   â€¢ Calculated assuming Hâ‚€ is true                         â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### What p-value IS NOT âŒ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   âŒ p-value is NOT:                                        â”‚
â”‚                                                             â”‚
â”‚   â€¢ P(Hâ‚€ is true)                                          â”‚
â”‚   â€¢ P(Hâ‚ is true)                                          â”‚
â”‚   â€¢ The probability the result is due to chance            â”‚
â”‚   â€¢ The probability of making a wrong decision             â”‚
â”‚   â€¢ A measure of effect size or importance                 â”‚
â”‚   â€¢ A measure of how "true" or "real" the effect is        â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Common Misinterpretations (IMPORTANT!)

### Misinterpretation 1: "Probability Hâ‚€ is True"

âŒ **Wrong:** "p = 0.03 means there's only 3% chance Hâ‚€ is true"

âœ… **Correct:** "p = 0.03 means IF Hâ‚€ were true, there's only 3% chance of seeing data this extreme"

```
The difference:

WRONG:  P(Hâ‚€ true | data) = 0.03     â† Posterior probability
RIGHT:  P(data this extreme | Hâ‚€ true) = 0.03  â† p-value

These are VERY different!
(Related by Bayes' theorem, but NOT equal)
```

### Misinterpretation 2: "Due to Chance"

âŒ **Wrong:** "p = 0.05 means 5% probability results are due to chance"

âœ… **Correct:** "p = 0.05 means IF only chance were operating (Hâ‚€ true), we'd see results this extreme 5% of the time"

### Misinterpretation 3: "1 - p = Probability Effect is Real"

âŒ **Wrong:** "p = 0.01, so there's 99% chance the effect is real"

âœ… **Correct:** "p = 0.01 means the data is inconsistent with Hâ‚€, but we need more than p-value to estimate effect probability"

### Misinterpretation 4: "Replication Probability"

âŒ **Wrong:** "p = 0.05 means there's 95% chance we'll get the same result if we repeat"

âœ… **Correct:** The p-value says nothing about future replications

### Misinterpretation 5: "Effect Size"

âŒ **Wrong:** "p = 0.001 means the effect is very large"

âœ… **Correct:** Small p can come from tiny effects with huge samples

```
Example:
Study A: Effect = 0.1, n = 10,000  â†’ p = 0.001 (tiny effect, huge n)
Study B: Effect = 5.0, n = 20      â†’ p = 0.04  (large effect, small n)

Study A has smaller p but MUCH smaller effect!
```

---

## The Mathematical Formula

### General Definition

```
For test statistic T with observed value t_obs:

ONE-TAILED (right): p = P(T â‰¥ t_obs | Hâ‚€)
ONE-TAILED (left):  p = P(T â‰¤ t_obs | Hâ‚€)
TWO-TAILED:         p = P(|T| â‰¥ |t_obs| | Hâ‚€)
                      = 2 Ã— P(T â‰¥ |t_obs| | Hâ‚€)  [if symmetric]
```

### For Z-test

```
Test statistic: Z = (XÌ„ - Î¼â‚€) / (Ïƒ/âˆšn)

p-value (two-tailed) = 2 Ã— [1 - Î¦(|z|)]

Where Î¦ is the standard normal CDF
```

### For t-test

```
Test statistic: t = (XÌ„ - Î¼â‚€) / (s/âˆšn)

p-value (two-tailed) = 2 Ã— P(T > |t|)

Where T follows t-distribution with df = n-1
```

---

## ğŸ“– Complete Example: Medicine Trial

### The Scenario

A pharmaceutical company claims their new headache pill works in 30 minutes on average. A researcher suspects it takes longer. She tests 25 patients.

**Results:**
- Sample mean: XÌ„ = 34 minutes
- Sample std dev: s = 8 minutes
- Sample size: n = 25

### Step-by-Step Calculation

**Step 1: State Hypotheses**
```
Hâ‚€: Î¼ = 30 (pill works as claimed)
Hâ‚: Î¼ > 30 (pill takes longer)

This is a RIGHT-TAILED test
```

**Step 2: Calculate Test Statistic**
```
       XÌ„ - Î¼â‚€      34 - 30       4
t = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ = â”€â”€â”€ = 2.5
      s/âˆšn         8/âˆš25       1.6

t = 2.5 with df = 24
```

**Step 3: Calculate p-value**
```
p-value = P(t > 2.5 | df = 24)

Using t-table or software:
p-value â‰ˆ 0.0098 â‰ˆ 1%
```

**Step 4: Interpret**
```
p-value = 0.0098 < Î± = 0.05

INTERPRETATION:
"If the pill truly worked in 30 minutes on average,
there's only about 1% chance of observing a sample mean
of 34 minutes or higher in a sample of 25 patients."

CONCLUSION:
"This is unlikely. We reject Hâ‚€ and conclude the pill
likely takes longer than claimed (p = 0.01)."
```

### Visual

```
                    Distribution if Hâ‚€ true (Î¼ = 30)
                    
                              â•­â”€â”€â”€â•®
                            â•­â”€â•¯   â•°â”€â•®
                           â•­â•¯       â•°â•®
                          â•­â•¯         â•°â•®
                         â•­â•¯           â•°â•®
                        â•­â•¯             â•°â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  â† p = 0.01
                       â•­â•¯               â”‚â•°â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    (1% area)
                      â•­â•¯                â”‚  â–ˆâ–ˆâ–ˆâ–ˆ
                     â•¯                  â”‚    â–ˆâ–ˆ
                    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                             30        34
                            (Hâ‚€)    (observed)
                            
Our data (34 min) is in the extreme right tail!
```

---

## p-values and Sample Size

### The Relationship

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   IMPORTANT: p-value depends on SAMPLE SIZE!                â”‚
â”‚                                                             â”‚
â”‚   Same effect size, different n:                            â”‚
â”‚                                                             â”‚
â”‚   n = 10:   p = 0.15   (not significant)                   â”‚
â”‚   n = 50:   p = 0.02   (significant at 0.05)               â”‚
â”‚   n = 500:  p = 0.0001 (highly significant)                â”‚
â”‚                                                             â”‚
â”‚   With large enough n, even TINY effects become            â”‚
â”‚   "statistically significant"!                              â”‚
â”‚                                                             â”‚
â”‚   This is why effect size matters, not just p-value!       â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Visual: Same Effect, Different n

```
Small n (n=20)                    Large n (n=2000)

      â•­â”€â”€â”€â”€â”€â”€â”€â”€â•®                        â•­â”€â”€â•®
    â•­â”€â•¯        â•°â”€â•®                    â•­â”€â•¯  â•°â”€â•®
   â•­â•¯            â•°â•®                  â•­â•¯      â•°â•®
  â•­â•¯              â•°â•®                â•­â•¯        â•°â•®
 â•­â•¯                â•°â–‘â–‘â–‘â–‘â–‘          â•­â•¯          â•°â–ˆ
â•­â•¯                  â”‚â•°â–‘â–‘â–‘â–‘â–‘â–‘     â•­â•¯             â”‚â–ˆ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”¼â”€â”€
                  Î¼â‚€ â”‚ XÌ„                       Î¼â‚€â”‚XÌ„
                     â”‚                           â”‚
                   Wide                       Narrow
               distribution                distribution
                     â”‚                           â”‚
             Large p-value               Small p-value
          (effect hidden in            (effect clearly
              noise)                     visible)
```

---

## p-value vs Effect Size

### Why Both Matter

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   STATISTICAL SIGNIFICANCE â‰  PRACTICAL IMPORTANCE           â”‚
â”‚                                                             â”‚
â”‚   p-value tells us: "Is there likely an effect?"           â”‚
â”‚   Effect size tells us: "How BIG is the effect?"           â”‚
â”‚                                                             â”‚
â”‚   We need BOTH for complete understanding!                  â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example: Two Studies

| Study | Effect | Sample Size | p-value | Conclusion |
|-------|--------|-------------|---------|------------|
| A | 0.5 point IQ increase | 50,000 | 0.001 | "Significant" but trivial |
| B | 15 point IQ increase | 30 | 0.08 | "Not significant" but meaningful |

**Study A:** Tiny effect detected with massive sample
**Study B:** Large effect missed due to small sample

### The Right Approach

```
Always report:
1. p-value (statistical significance)
2. Effect size (practical significance)
3. Confidence interval (precision)

Example:
"The treatment reduced pain by 2.5 points (95% CI: 1.8-3.2)
on a 10-point scale, p < 0.001, Cohen's d = 0.8 (large effect)."
```

---

## Common Effect Size Measures

### Cohen's d (for means)

```
        XÌ„ - Î¼â‚€       Difference in means
d = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ = â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         s          Standard deviation

Interpretation:
â€¢ |d| < 0.2:  Small effect
â€¢ |d| â‰ˆ 0.5:  Medium effect  
â€¢ |d| > 0.8:  Large effect
```

### Correlation r

```
â€¢ |r| < 0.1:  Small
â€¢ |r| â‰ˆ 0.3:  Medium
â€¢ |r| > 0.5:  Large
```

### Odds Ratio / Risk Ratio

For comparing proportions or risks between groups.

---

## The p-value Controversy

### Criticisms of p-values

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   WHY p-VALUES ARE CONTROVERSIAL                             â”‚
â”‚                                                             â”‚
â”‚   1. Often misinterpreted (as shown above)                  â”‚
â”‚                                                             â”‚
â”‚   2. Encourage binary thinking ("significant" vs "not")     â”‚
â”‚      instead of continuous evidence                         â”‚
â”‚                                                             â”‚
â”‚   3. p-hacking: Manipulating analysis to get p < 0.05      â”‚
â”‚                                                             â”‚
â”‚   4. Publication bias: Only "significant" results publish  â”‚
â”‚                                                             â”‚
â”‚   5. Don't tell us what we really want to know:            â”‚
â”‚      P(hypothesis | data), not P(data | hypothesis)        â”‚
â”‚                                                             â”‚
â”‚   6. Depend heavily on sample size                          â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### The ASA Statement (2016)

The American Statistical Association released a statement on p-values:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   ASA PRINCIPLES ON p-VALUES                                 â”‚
â”‚                                                             â”‚
â”‚   1. p-values can indicate incompatibility between data    â”‚
â”‚      and a statistical model                                â”‚
â”‚                                                             â”‚
â”‚   2. p-values do NOT measure probability that Hâ‚€ is true   â”‚
â”‚                                                             â”‚
â”‚   3. Scientific conclusions should NOT be based only on    â”‚
â”‚      whether p < 0.05                                       â”‚
â”‚                                                             â”‚
â”‚   4. Proper reporting requires transparency                 â”‚
â”‚                                                             â”‚
â”‚   5. p-value does NOT measure effect size or importance    â”‚
â”‚                                                             â”‚
â”‚   6. By itself, p-value does NOT provide good evidence     â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Best Practices

### Do's âœ…

```
âœ… Report exact p-values (p = 0.032, not just p < 0.05)
âœ… Always report effect sizes alongside p-values
âœ… Include confidence intervals
âœ… Consider practical significance, not just statistical
âœ… Pre-register your analysis plan
âœ… Report all analyses, not just significant ones
âœ… Use p-values as one piece of evidence, not the only one
âœ… Understand what p-value does and doesn't mean
```

### Don'ts âŒ

```
âŒ Don't say "p = 0.05 means 5% chance Hâ‚€ is true"
âŒ Don't treat p = 0.049 and p = 0.051 as fundamentally different
âŒ Don't p-hack (try many analyses until one works)
âŒ Don't ignore effect size
âŒ Don't conclude "no effect" just because p > 0.05
âŒ Don't use p-value as the sole criterion for decisions
âŒ Don't confuse statistical and practical significance
```

---

## Python Implementation

### Calculating p-values

```python
import numpy as np
from scipy import stats

# ======================
# ONE-SAMPLE T-TEST
# ======================
def calculate_p_value_ttest(data, mu_0, alternative='two-sided'):
    """
    Calculate p-value for one-sample t-test
    
    Parameters:
    - data: sample data
    - mu_0: hypothesized mean under Hâ‚€
    - alternative: 'two-sided', 'greater', or 'less'
    """
    n = len(data)
    x_bar = np.mean(data)
    s = np.std(data, ddof=1)
    
    # Test statistic
    t_stat = (x_bar - mu_0) / (s / np.sqrt(n))
    df = n - 1
    
    # p-value
    if alternative == 'two-sided':
        p_value = 2 * (1 - stats.t.cdf(abs(t_stat), df))
    elif alternative == 'greater':
        p_value = 1 - stats.t.cdf(t_stat, df)
    elif alternative == 'less':
        p_value = stats.t.cdf(t_stat, df)
    
    return t_stat, p_value

# Example
data = np.array([34, 32, 36, 35, 33, 37, 31, 35, 34, 36])
mu_0 = 30

t_stat, p_value = calculate_p_value_ttest(data, mu_0, alternative='greater')
print(f"Sample mean: {np.mean(data):.2f}")
print(f"t-statistic: {t_stat:.4f}")
print(f"p-value: {p_value:.6f}")

# Using scipy directly
t_stat_scipy, p_value_scipy = stats.ttest_1samp(data, mu_0)
print(f"\nScipy results:")
print(f"t-statistic: {t_stat_scipy:.4f}")
print(f"p-value (two-sided): {p_value_scipy:.6f}")
```

### Z-test for Proportion

```python
import numpy as np
from scipy import stats

def z_test_proportion(successes, n, p_0, alternative='two-sided'):
    """
    Z-test for population proportion
    
    Parameters:
    - successes: number of successes
    - n: sample size
    - p_0: hypothesized proportion under Hâ‚€
    - alternative: 'two-sided', 'greater', or 'less'
    """
    p_hat = successes / n
    
    # Standard error under Hâ‚€
    se = np.sqrt(p_0 * (1 - p_0) / n)
    
    # Z-statistic
    z_stat = (p_hat - p_0) / se
    
    # p-value
    if alternative == 'two-sided':
        p_value = 2 * (1 - stats.norm.cdf(abs(z_stat)))
    elif alternative == 'greater':
        p_value = 1 - stats.norm.cdf(z_stat)
    elif alternative == 'less':
        p_value = stats.norm.cdf(z_stat)
    
    return z_stat, p_value, p_hat

# Example: Coin flip (65 heads in 100 flips)
z_stat, p_value, p_hat = z_test_proportion(65, 100, 0.5, 'two-sided')
print(f"Sample proportion: {p_hat:.4f}")
print(f"Z-statistic: {z_stat:.4f}")
print(f"p-value: {p_value:.6f}")

if p_value < 0.05:
    print("Reject Hâ‚€: Evidence of bias")
else:
    print("Fail to reject Hâ‚€: No strong evidence of bias")
```

### Visualizing p-value

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

def visualize_p_value(test_stat, df=None, test_type='z', alternative='two-sided'):
    """
    Visualize p-value on the appropriate distribution
    """
    fig, ax = plt.subplots(figsize=(10, 6))
    
    # Create x values
    if test_type == 'z':
        x = np.linspace(-4, 4, 1000)
        y = stats.norm.pdf(x)
        dist = stats.norm
        title = "Standard Normal Distribution"
    else:  # t-distribution
        x = np.linspace(-4, 4, 1000)
        y = stats.t.pdf(x, df)
        dist = stats.t(df)
        title = f"t-Distribution (df={df})"
    
    # Plot distribution
    ax.plot(x, y, 'b-', linewidth=2, label='Distribution under Hâ‚€')
    ax.fill_between(x, y, alpha=0.1)
    
    # Shade p-value region
    if alternative == 'two-sided':
        # Right tail
        x_right = x[x >= abs(test_stat)]
        y_right = stats.norm.pdf(x_right) if test_type == 'z' else stats.t.pdf(x_right, df)
        ax.fill_between(x_right, y_right, color='red', alpha=0.5, label='p-value region')
        
        # Left tail
        x_left = x[x <= -abs(test_stat)]
        y_left = stats.norm.pdf(x_left) if test_type == 'z' else stats.t.pdf(x_left, df)
        ax.fill_between(x_left, y_left, color='red', alpha=0.5)
        
        p_value = 2 * (1 - dist.cdf(abs(test_stat)))
        
    elif alternative == 'greater':
        x_shade = x[x >= test_stat]
        y_shade = stats.norm.pdf(x_shade) if test_type == 'z' else stats.t.pdf(x_shade, df)
        ax.fill_between(x_shade, y_shade, color='red', alpha=0.5, label='p-value region')
        p_value = 1 - dist.cdf(test_stat)
        
    else:  # less
        x_shade = x[x <= test_stat]
        y_shade = stats.norm.pdf(x_shade) if test_type == 'z' else stats.t.pdf(x_shade, df)
        ax.fill_between(x_shade, y_shade, color='red', alpha=0.5, label='p-value region')
        p_value = dist.cdf(test_stat)
    
    # Add vertical line at test statistic
    ax.axvline(x=test_stat, color='red', linestyle='--', linewidth=2, 
               label=f'Test statistic = {test_stat:.2f}')
    if alternative == 'two-sided':
        ax.axvline(x=-test_stat, color='red', linestyle='--', linewidth=2)
    
    ax.set_xlabel('Test Statistic Value', fontsize=12)
    ax.set_ylabel('Probability Density', fontsize=12)
    ax.set_title(f'{title}\np-value = {p_value:.4f}', fontsize=14)
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    return p_value

# Example
p = visualize_p_value(test_stat=2.5, df=24, test_type='t', alternative='greater')
print(f"p-value: {p:.6f}")
```

### Effect Size Calculation

```python
import numpy as np

def cohens_d(group1, group2=None, mu_0=None):
    """
    Calculate Cohen's d effect size
    
    For one-sample: compare group1 to mu_0
    For two-sample: compare group1 to group2
    """
    if group2 is not None:
        # Two-sample Cohen's d
        n1, n2 = len(group1), len(group2)
        var1, var2 = np.var(group1, ddof=1), np.var(group2, ddof=1)
        
        # Pooled standard deviation
        pooled_std = np.sqrt(((n1 - 1) * var1 + (n2 - 1) * var2) / (n1 + n2 - 2))
        
        d = (np.mean(group1) - np.mean(group2)) / pooled_std
    else:
        # One-sample Cohen's d
        d = (np.mean(group1) - mu_0) / np.std(group1, ddof=1)
    
    # Interpretation
    abs_d = abs(d)
    if abs_d < 0.2:
        interpretation = "negligible"
    elif abs_d < 0.5:
        interpretation = "small"
    elif abs_d < 0.8:
        interpretation = "medium"
    else:
        interpretation = "large"
    
    return d, interpretation

# Example
data = np.array([34, 32, 36, 35, 33, 37, 31, 35, 34, 36])
d, interp = cohens_d(data, mu_0=30)
print(f"Cohen's d: {d:.4f} ({interp} effect)")
```

---

## Practice Problems ğŸ“

### Problem 1: Interpretation
A study reports p = 0.03. Which statement is correct?
a) There's 3% chance Hâ‚€ is true
b) There's 97% chance Hâ‚ is true
c) If Hâ‚€ were true, data this extreme would occur ~3% of the time
d) The effect has 3% chance of being real

<details>
<summary>Click for Answer</summary>

**Answer: (c)**

The p-value is the probability of observing data this extreme 
(or more extreme) IF the null hypothesis were true.

- (a) is wrong: p-value â‰  P(Hâ‚€ is true)
- (b) is wrong: p-value â‰  P(Hâ‚ is true)
- (d) is wrong: p-value doesn't measure "realness" of effect

</details>

---

### Problem 2: Calculation
In a Z-test, you get Z = 1.8 (one-tailed, right). What's the p-value?

<details>
<summary>Click for Answer</summary>

```
p-value = P(Z â‰¥ 1.8)
        = 1 - Î¦(1.8)
        = 1 - 0.9641
        = 0.0359

p-value â‰ˆ 0.036 or 3.6%

At Î± = 0.05, this would be significant (reject Hâ‚€).
At Î± = 0.01, this would not be significant.
```

</details>

---

### Problem 3: Two-Tailed Test
For a two-tailed test, t = 2.3 with df = 20. Find the p-value.

<details>
<summary>Click for Answer</summary>

```
p-value = 2 Ã— P(t > 2.3 | df = 20)

Using t-table or calculator:
P(t > 2.3 | df = 20) â‰ˆ 0.016

p-value = 2 Ã— 0.016 = 0.032

p-value â‰ˆ 0.032 or 3.2%

This is significant at Î± = 0.05 (since 0.032 < 0.05)
```

</details>

---

### Problem 4: Sample Size Effect
Two studies test the same hypothesis with the same effect size (d = 0.3):
- Study A: n = 50, p = 0.12
- Study B: n = 200, p = 0.008

Why are the p-values so different?

<details>
<summary>Click for Answer</summary>

```
The p-value depends on BOTH effect size AND sample size!

With same effect size d:
â€¢ Larger n â†’ Smaller standard error (SE = Ïƒ/âˆšn)
â€¢ Smaller SE â†’ Larger test statistic
â€¢ Larger test statistic â†’ Smaller p-value

Study B has 4Ã— the sample size of Study A, giving:
â€¢ âˆš4 = 2Ã— larger test statistic
â€¢ Much smaller p-value

This shows why p-value alone doesn't measure effect importance!
Both studies found the SAME effect, but only Study B has
"statistical significance."

LESSON: Always report effect size alongside p-value!
```

</details>

---

### Problem 5: Critical Thinking
A researcher gets p = 0.048 and concludes the effect is "significant" at Î± = 0.05. A second researcher gets p = 0.052 on the same research question and concludes "no effect." Is there really a fundamental difference?

<details>
<summary>Click for Answer</summary>

```
NO! This illustrates the problem with binary thinking.

p = 0.048 and p = 0.052 are essentially the same strength 
of evidence. The arbitrary threshold of 0.05 makes them 
look fundamentally different when they're not.

Better approach:
â€¢ Report exact p-values: "p = 0.048" and "p = 0.052"
â€¢ Both indicate "weak to moderate evidence against Hâ‚€"
â€¢ Report effect sizes and confidence intervals
â€¢ Don't treat 0.05 as a magical boundary

The difference between 0.048 and 0.052 is statistically
and practically negligible. The dichotomy of 
"significant/not significant" is misleading here.
```

</details>

---

## Summary: The Essence of p-value

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        THE p-VALUE                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   "How surprising is our data if Hâ‚€ were true?"                 â”‚
â”‚                                                                  â”‚
â”‚   DEFINITION:                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  p-value = P(data this extreme or more | Hâ‚€ is true)    â”‚   â”‚
â”‚   â”‚                                                          â”‚   â”‚
â”‚   â”‚  NOT the probability Hâ‚€ is true!                        â”‚   â”‚
â”‚   â”‚  NOT the probability of "due to chance"!                â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â”‚   INTERPRETATION:                                                â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  Small p (< Î±):  Data inconsistent with Hâ‚€              â”‚   â”‚
â”‚   â”‚                  â†’ Reject Hâ‚€                            â”‚   â”‚
â”‚   â”‚                                                          â”‚   â”‚
â”‚   â”‚  Large p (> Î±):  Data consistent with Hâ‚€                â”‚   â”‚
â”‚   â”‚                  â†’ Fail to reject Hâ‚€                    â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â”‚   REMEMBER:                                                      â”‚
â”‚   â€¢ p-value depends on sample size                              â”‚
â”‚   â€¢ Statistical significance â‰  practical importance             â”‚
â”‚   â€¢ Always report effect size too!                              â”‚
â”‚   â€¢ p = 0.049 and p = 0.051 are essentially the same           â”‚
â”‚   â€¢ p-value is evidence, not proof                              â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## The Bottom Line

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚   The p-value is a useful tool, but:                            â”‚
â”‚                                                                  â”‚
â”‚   â€¢ It's NOT the probability your hypothesis is true            â”‚
â”‚   â€¢ It's NOT a measure of effect size                           â”‚
â”‚   â€¢ It's NOT the final answer                                   â”‚
â”‚                                                                  â”‚
â”‚   Use p-values ALONGSIDE:                                        â”‚
â”‚   â€¢ Effect sizes (Cohen's d, r, etc.)                           â”‚
â”‚   â€¢ Confidence intervals                                         â”‚
â”‚   â€¢ Domain knowledge                                             â”‚
â”‚   â€¢ Replication studies                                          â”‚
â”‚   â€¢ Common sense!                                                â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

> **"The p-value tells us how surprised we should be by the data if there were no effect. It doesn't tell us whether there IS an effect, how BIG the effect is, or how IMPORTANT it is. For those questions, we need more than just a p-value."**

Master the p-value, but remember: it's just one piece of the statistical puzzle! ğŸ§©

---

*From probability to practice, from misunderstanding to mastery â€” that's the journey of the p-value!* ğŸ“Š