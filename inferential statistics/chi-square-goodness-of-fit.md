# Chi-Square Goodness of Fit Test
## Does Your Data Fit the Expected Pattern? ğŸ¯

---

## What is Goodness of Fit?

The Chi-Square Goodness of Fit test determines whether your observed data **fits** (matches) a specific expected distribution. It answers: "Does what I observed match what I expected?"

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   CHI-SQUARE GOODNESS OF FIT TEST                            â”‚
â”‚                                                             â”‚
â”‚   Purpose:                                                  â”‚
â”‚   Test whether observed frequencies match expected          â”‚
â”‚   frequencies from a hypothesized distribution              â”‚
â”‚                                                             â”‚
â”‚   Question:                                                 â”‚
â”‚   "Does my data fit the expected pattern?"                 â”‚
â”‚                                                             â”‚
â”‚   Examples:                                                 â”‚
â”‚   â€¢ Is this die fair? (expect equal frequencies)           â”‚
â”‚   â€¢ Do births occur equally across weekdays?               â”‚
â”‚   â€¢ Does this follow a specific ratio (like 9:3:3:1)?     â”‚
â”‚   â€¢ Is the slot machine paying out as advertised?          â”‚
â”‚                                                             â”‚
â”‚   ONE categorical variable with k categories               â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“– Story: The Suspicious Slot Machine

Rahim owns a small casino in Cox's Bazar. A customer complains that the slot machine seems rigged â€” it never lands on the jackpot symbol!

The machine has 5 symbols, and the manufacturer claims each should appear equally (20% each):
- ğŸ’ Cherry
- ğŸ‹ Lemon  
- ğŸ”” Bell
- â­ Star
- ğŸ’ Diamond (Jackpot)

Rahim records 500 spins:

| Symbol | ğŸ’ Cherry | ğŸ‹ Lemon | ğŸ”” Bell | â­ Star | ğŸ’ Diamond |
|--------|-----------|----------|---------|---------|------------|
| **Observed** | 95 | 110 | 105 | 120 | 70 |

**Question:** Is the machine fair, or is it rigged to reduce jackpots?

---

## The Hypotheses

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   HYPOTHESES FOR GOODNESS OF FIT                             â”‚
â”‚                                                             â”‚
â”‚   Hâ‚€: The data FITS the expected distribution               â”‚
â”‚       (Observed frequencies match expected frequencies)     â”‚
â”‚       "The machine is fair"                                â”‚
â”‚                                                             â”‚
â”‚   Hâ‚: The data does NOT fit the expected distribution       â”‚
â”‚       (Observed frequencies differ from expected)          â”‚
â”‚       "The machine is NOT fair"                            â”‚
â”‚                                                             â”‚
â”‚   This is always a TWO-SIDED test conceptually,            â”‚
â”‚   but uses the RIGHT TAIL of chi-square distribution       â”‚
â”‚   (we only care if Ï‡Â² is "too large")                      â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## The Formula

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   CHI-SQUARE GOODNESS OF FIT FORMULA                         â”‚
â”‚                                                             â”‚
â”‚              k   (Oáµ¢ - Eáµ¢)Â²                                 â”‚
â”‚        Ï‡Â² = Î£  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                 â”‚
â”‚             i=1     Eáµ¢                                      â”‚
â”‚                                                             â”‚
â”‚   Where:                                                    â”‚
â”‚   â€¢ Oáµ¢ = Observed frequency in category i                  â”‚
â”‚   â€¢ Eáµ¢ = Expected frequency in category i                  â”‚
â”‚   â€¢ k = number of categories                               â”‚
â”‚                                                             â”‚
â”‚   Degrees of Freedom:                                       â”‚
â”‚   df = k - 1                                               â”‚
â”‚                                                             â”‚
â”‚   Why k - 1?                                               â”‚
â”‚   Once you know k-1 frequencies and the total,             â”‚
â”‚   the last frequency is determined!                        â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Understanding the Formula

```
Each term (Oáµ¢ - Eáµ¢)Â²/Eáµ¢ measures:

(Oáµ¢ - Eáµ¢)Â² : How far is observed from expected?
             Squared to make all values positive
             and penalize large deviations more

    Eáµ¢     : Divide by expected to STANDARDIZE
             A difference of 10 matters more when
             expected is 20 than when expected is 200


Ï‡Â² = Sum of all standardized squared deviations

Small Ï‡Â² â†’ Good fit (observed â‰ˆ expected)
Large Ï‡Â² â†’ Poor fit (observed â‰  expected)
```

---

## Solving the Slot Machine Problem

### Step 1: State the Hypotheses

```
Hâ‚€: All symbols appear with equal probability (20% each)
    P(ğŸ’) = P(ğŸ‹) = P(ğŸ””) = P(â­) = P(ğŸ’) = 0.20

Hâ‚: The symbols do NOT appear with equal probability
    (At least one probability differs from 0.20)

Î± = 0.05
```

### Step 2: Calculate Expected Frequencies

```
If Hâ‚€ is true (all equally likely):

Expected for each symbol = Total spins Ã— P(each symbol)
                        = 500 Ã— 0.20
                        = 100

| Symbol | Observed (O) | Expected (E) |
|--------|--------------|--------------|
| ğŸ’     | 95           | 100          |
| ğŸ‹     | 110          | 100          |
| ğŸ””     | 105          | 100          |
| â­     | 120          | 100          |
| ğŸ’     | 70           | 100          |
| Total  | 500          | 500          |
```

### Step 3: Check Conditions

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   CONDITIONS FOR CHI-SQUARE GOODNESS OF FIT                  â”‚
â”‚                                                             â”‚
â”‚   1. RANDOM SAMPLE                                          â”‚
â”‚      Observations are randomly selected âœ“                  â”‚
â”‚                                                             â”‚
â”‚   2. INDEPENDENCE                                           â”‚
â”‚      Each observation is independent âœ“                     â”‚
â”‚      (Each spin is independent)                            â”‚
â”‚                                                             â”‚
â”‚   3. EXPECTED COUNT CONDITION                               â”‚
â”‚      All expected frequencies â‰¥ 5 âœ“                        â”‚
â”‚      (All are 100, which is â‰¥ 5)                          â”‚
â”‚                                                             â”‚
â”‚   All conditions satisfied! Proceed with test.             â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Step 4: Calculate Chi-Square Statistic

```
       (O - E)Â²
Ï‡Â² = Î£ â”€â”€â”€â”€â”€â”€â”€â”€â”€
          E

| Symbol | O   | E   | O - E | (O-E)Â² | (O-E)Â²/E |
|--------|-----|-----|-------|--------|----------|
| ğŸ’     | 95  | 100 | -5    | 25     | 0.25     |
| ğŸ‹     | 110 | 100 | +10   | 100    | 1.00     |
| ğŸ””     | 105 | 100 | +5    | 25     | 0.25     |
| â­     | 120 | 100 | +20   | 400    | 4.00     |
| ğŸ’     | 70  | 100 | -30   | 900    | 9.00     |
|--------|-----|-----|-------|--------|----------|
| Total  | 500 | 500 |   0   |        | Ï‡Â²=14.50 |

Ï‡Â² = 0.25 + 1.00 + 0.25 + 4.00 + 9.00 = 14.50
```

### Step 5: Find Degrees of Freedom and Critical Value

```
df = k - 1 = 5 - 1 = 4

For Î± = 0.05 and df = 4:
Ï‡Â²_critical = 9.488

p-value = P(Ï‡Â² > 14.50 | df = 4) â‰ˆ 0.006
```

### Step 6: Visualize the Test

```
                Chi-Square Distribution (df = 4)
                
    â”‚
    â”‚â•²
    â”‚ â•²
    â”‚  â•²
    â”‚   â•²
    â”‚    â•²
    â”‚     â•²â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â”‚              â•²
    â”‚               â•²â”€â”€â”€â”€â”€â”€â”€â”€
    â”‚                       â•²â”€â”€â”€â”€â”€â”€â”€â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
                             9.488  14.50         Ï‡Â²
                               â”‚       â”‚
                         Critical   Our Ï‡Â²
                          Value   
                               â”‚
                          â—„â”€â”€â”€â”€â”´â”€â”€â”€â”€â–º
                         Rejection
                          Region
                          
    Ï‡Â² = 14.50 falls in the rejection region!
```

### Step 7: Make a Decision

```
METHOD 1: Using Critical Value
Ï‡Â² = 14.50 > Ï‡Â²_critical = 9.488
â†’ REJECT Hâ‚€

METHOD 2: Using P-value
p-value = 0.006 < Î± = 0.05
â†’ REJECT Hâ‚€
```

### Step 8: State the Conclusion

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   CONCLUSION                                                 â”‚
â”‚                                                             â”‚
â”‚   At the Î± = 0.05 significance level, we REJECT Hâ‚€.        â”‚
â”‚   There is statistically significant evidence that the     â”‚
â”‚   slot machine is NOT fair (Ï‡Â² = 14.50, df = 4, p = 0.006).â”‚
â”‚                                                             â”‚
â”‚   Looking at the data:                                      â”‚
â”‚   â€¢ Diamond (ğŸ’) appeared 70 times (expected: 100)         â”‚
â”‚   â€¢ This is 30% LESS than expected!                        â”‚
â”‚   â€¢ Star (â­) appeared 120 times (expected: 100)           â”‚
â”‚   â€¢ This is 20% MORE than expected                         â”‚
â”‚                                                             â”‚
â”‚   The customer's complaint appears justified!              â”‚
â”‚   The machine seems rigged to reduce jackpots.             â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Which Category Contributed Most?

```
Looking at individual (O-E)Â²/E contributions:

| Symbol | (O-E)Â²/E | % of Ï‡Â² |
|--------|----------|---------|
| ğŸ’     | 9.00     | 62.1%   | â† Biggest contributor!
| â­     | 4.00     | 27.6%   |
| ğŸ‹     | 1.00     | 6.9%    |
| ğŸ””     | 0.25     | 1.7%    |
| ğŸ’     | 0.25     | 1.7%    |

Diamond alone contributes 62% of the chi-square value!
This is the main source of "unfairness."
```

---

## Types of Expected Distributions

### Type 1: Equal Proportions (Uniform)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   EQUAL/UNIFORM DISTRIBUTION                                 â”‚
â”‚                                                             â”‚
â”‚   All categories expected to be equal                       â”‚
â”‚                                                             â”‚
â”‚   Expected for each = Total / k                            â”‚
â”‚                                                             â”‚
â”‚   Examples:                                                 â”‚
â”‚   â€¢ Fair die: Each face = n/6                              â”‚
â”‚   â€¢ Fair coin: Heads = Tails = n/2                         â”‚
â”‚   â€¢ Days of week: Each day = n/7                           â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Type 2: Specified Proportions

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   SPECIFIED PROPORTIONS                                      â”‚
â”‚                                                             â”‚
â”‚   Each category has a specified probability                â”‚
â”‚                                                             â”‚
â”‚   Expected for category i = Total Ã— páµ¢                     â”‚
â”‚                                                             â”‚
â”‚   Examples:                                                 â”‚
â”‚   â€¢ Genetics: 9:3:3:1 ratio                               â”‚
â”‚   â€¢ M&M colors: Company-stated percentages                 â”‚
â”‚   â€¢ Market share: Based on prior data                      â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Type 3: Theoretical Distribution

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   THEORETICAL DISTRIBUTION                                   â”‚
â”‚                                                             â”‚
â”‚   Expected from a probability distribution                  â”‚
â”‚                                                             â”‚
â”‚   Expected = Total Ã— P(X = xáµ¢) from distribution          â”‚
â”‚                                                             â”‚
â”‚   Examples:                                                 â”‚
â”‚   â€¢ Poisson: Testing if counts follow Poisson             â”‚
â”‚   â€¢ Binomial: Testing if data is binomial                 â”‚
â”‚   â€¢ Normal: Testing if data is normal (with bins)         â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“– Example 2: Is the Die Fair?

A gambler rolls a die 120 times and records:

| Face | 1 | 2 | 3 | 4 | 5 | 6 |
|------|---|---|---|---|---|---|
| **Observed** | 25 | 17 | 15 | 23 | 24 | 16 |

Is the die fair at Î± = 0.05?

### Solution

```
Hâ‚€: Die is fair (each face has probability 1/6)
Hâ‚: Die is not fair
Î± = 0.05

Expected for each face = 120 Ã— (1/6) = 20

| Face | O  | E  | O - E | (O-E)Â² | (O-E)Â²/E |
|------|----|----|-------|--------|----------|
| 1    | 25 | 20 | +5    | 25     | 1.25     |
| 2    | 17 | 20 | -3    | 9      | 0.45     |
| 3    | 15 | 20 | -5    | 25     | 1.25     |
| 4    | 23 | 20 | +3    | 9      | 0.45     |
| 5    | 24 | 20 | +4    | 16     | 0.80     |
| 6    | 16 | 20 | -4    | 16     | 0.80     |
|------|----|----|-------|--------|----------|
| Total| 120| 120|   0   |        | Ï‡Â² = 5.00|

df = 6 - 1 = 5
Ï‡Â²_critical (Î± = 0.05, df = 5) = 11.07
p-value = P(Ï‡Â² > 5.00 | df = 5) â‰ˆ 0.416

Ï‡Â² = 5.00 < 11.07 â†’ FAIL TO REJECT Hâ‚€

CONCLUSION:
At Î± = 0.05, there is insufficient evidence to conclude 
the die is unfair (Ï‡Â² = 5.00, df = 5, p = 0.416).

The observed variations are within normal random chance.
```

---

## ğŸ“– Example 3: Mendelian Genetics (Specified Ratios)

A biologist crosses pea plants. Mendel's law predicts a 9:3:3:1 phenotype ratio. She observes 556 offspring:

| Phenotype | Round Yellow | Round Green | Wrinkled Yellow | Wrinkled Green |
|-----------|--------------|-------------|-----------------|----------------|
| **Observed** | 315 | 108 | 101 | 32 |
| **Expected Ratio** | 9 | 3 | 3 | 1 |

### Solution

```
Hâ‚€: Offspring follow 9:3:3:1 ratio (Mendelian inheritance)
Hâ‚: Offspring do NOT follow 9:3:3:1 ratio
Î± = 0.05

Step 1: Calculate expected frequencies
Total parts = 9 + 3 + 3 + 1 = 16
Total offspring = 556

Expected:
â€¢ Round Yellow:    556 Ã— 9/16 = 312.75
â€¢ Round Green:     556 Ã— 3/16 = 104.25
â€¢ Wrinkled Yellow: 556 Ã— 3/16 = 104.25
â€¢ Wrinkled Green:  556 Ã— 1/16 = 34.75

Step 2: Calculate Ï‡Â²
| Phenotype        | O   | E      | (O-E)Â²/E |
|------------------|-----|--------|----------|
| Round Yellow     | 315 | 312.75 | 0.016    |
| Round Green      | 108 | 104.25 | 0.135    |
| Wrinkled Yellow  | 101 | 104.25 | 0.101    |
| Wrinkled Green   | 32  | 34.75  | 0.218    |
|------------------|-----|--------|----------|
| Total            | 556 | 556    | Ï‡Â² = 0.47|

Step 3: Find critical value
df = 4 - 1 = 3
Ï‡Â²_critical (Î± = 0.05, df = 3) = 7.815
p-value â‰ˆ 0.925

Step 4: Decision
Ï‡Â² = 0.47 < 7.815 â†’ FAIL TO REJECT Hâ‚€

CONCLUSION:
The data is consistent with Mendelian 9:3:3:1 ratio 
(Ï‡Â² = 0.47, df = 3, p = 0.925).

This is remarkably good fit! Mendel's laws are supported.
(Historically, this data was crucial in validating genetics!)
```

### Visual: How Close is the Fit?

```
                Expected vs Observed

Round Yellow:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 315 (E: 312.75)
               â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ Expected

Round Green:   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 108 (E: 104.25)
               â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ Expected

Wrinkled Yel:  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 101 (E: 104.25)
               â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ Expected

Wrinkled Grn:  â–ˆâ–ˆâ–ˆ 32 (E: 34.75)
               â–ˆâ–ˆâ–ˆ Expected

Almost perfect match! Ï‡Â² = 0.47 (very small)
```

---

## ğŸ“– Example 4: M&M Color Distribution

Mars Inc. claims M&M colors are distributed as:
- Brown: 13%
- Red: 13%
- Yellow: 14%
- Green: 16%
- Orange: 20%
- Blue: 24%

You count 500 M&Ms from various bags:

| Color | Brown | Red | Yellow | Green | Orange | Blue |
|-------|-------|-----|--------|-------|--------|------|
| **Observed** | 70 | 85 | 65 | 75 | 90 | 115 |
| **Claimed %** | 13% | 13% | 14% | 16% | 20% | 24% |

### Solution

```
Hâ‚€: Colors match claimed distribution
Hâ‚: Colors do NOT match claimed distribution
Î± = 0.05

Expected frequencies:
â€¢ Brown:  500 Ã— 0.13 = 65
â€¢ Red:    500 Ã— 0.13 = 65
â€¢ Yellow: 500 Ã— 0.14 = 70
â€¢ Green:  500 Ã— 0.16 = 80
â€¢ Orange: 500 Ã— 0.20 = 100
â€¢ Blue:   500 Ã— 0.24 = 120

| Color  | O   | E   | (O-E)Â²/E |
|--------|-----|-----|----------|
| Brown  | 70  | 65  | 0.385    |
| Red    | 85  | 65  | 6.154    |
| Yellow | 65  | 70  | 0.357    |
| Green  | 75  | 80  | 0.313    |
| Orange | 90  | 100 | 1.000    |
| Blue   | 115 | 120 | 0.208    |
|--------|-----|-----|----------|
| Total  | 500 | 500 | Ï‡Â² = 8.42|

df = 6 - 1 = 5
Ï‡Â²_critical (Î± = 0.05, df = 5) = 11.07
p-value â‰ˆ 0.134

Ï‡Â² = 8.42 < 11.07 â†’ FAIL TO REJECT Hâ‚€

CONCLUSION:
At Î± = 0.05, there is insufficient evidence that the 
M&M distribution differs from what Mars claims 
(Ï‡Â² = 8.42, df = 5, p = 0.134).

Note: Red had 85 vs expected 65 â€” this contributed most
to Ï‡Â². But overall, the fit is acceptable.
```

---

## ğŸ“– Example 5: Day of Week Births

A hospital wants to know if births are equally distributed across days of the week. Data from 700 births:

| Day | Sun | Mon | Tue | Wed | Thu | Fri | Sat |
|-----|-----|-----|-----|-----|-----|-----|-----|
| **Births** | 84 | 110 | 115 | 108 | 105 | 98 | 80 |

### Solution

```
Hâ‚€: Births are equally distributed across days
Hâ‚: Births are NOT equally distributed
Î± = 0.05

Expected for each day = 700/7 = 100

| Day | O   | E   | (O-E)Â²/E |
|-----|-----|-----|----------|
| Sun | 84  | 100 | 2.56     |
| Mon | 110 | 100 | 1.00     |
| Tue | 115 | 100 | 2.25     |
| Wed | 108 | 100 | 0.64     |
| Thu | 105 | 100 | 0.25     |
| Fri | 98  | 100 | 0.04     |
| Sat | 80  | 100 | 4.00     |
|-----|-----|-----|----------|
| Total|700 | 700 | Ï‡Â²=10.74 |

df = 7 - 1 = 6
Ï‡Â²_critical (Î± = 0.05, df = 6) = 12.59
p-value â‰ˆ 0.097

Ï‡Â² = 10.74 < 12.59 â†’ FAIL TO REJECT Hâ‚€

CONCLUSION:
At Î± = 0.05, there is insufficient evidence that births
are unequally distributed across days (Ï‡Â² = 10.74, df = 6, 
p = 0.097).

However, note p = 0.097 is close to 0.05. There's a hint
that weekends (Sun=84, Sat=80) have fewer births, possibly 
due to fewer scheduled C-sections/inductions. At Î± = 0.10,
we would reject Hâ‚€!
```

---

## ğŸ“– Example 6: Testing for Poisson Distribution

A call center receives calls. Are the number of calls per minute Poisson distributed?

Data from 200 one-minute intervals:

| Calls/minute | 0 | 1 | 2 | 3 | 4 | 5+ |
|--------------|---|---|---|---|---|----|
| **Observed** | 18 | 45 | 56 | 42 | 27 | 12 |

The mean number of calls = 2.3 per minute.

### Solution

```
Hâ‚€: Data follows Poisson distribution with Î» = 2.3
Hâ‚: Data does NOT follow Poisson distribution
Î± = 0.05

Calculate Poisson probabilities for Î» = 2.3:
P(X=0) = e^(-2.3) Ã— 2.3^0 / 0! = 0.1003
P(X=1) = e^(-2.3) Ã— 2.3^1 / 1! = 0.2306
P(X=2) = e^(-2.3) Ã— 2.3^2 / 2! = 0.2652
P(X=3) = e^(-2.3) Ã— 2.3^3 / 3! = 0.2033
P(X=4) = e^(-2.3) Ã— 2.3^4 / 4! = 0.1169
P(Xâ‰¥5) = 1 - sum of above = 0.0837

Expected frequencies = 200 Ã— P(X=k):

| Calls | O  | E     | (O-E)Â²/E |
|-------|----|-------|----------|
| 0     | 18 | 20.06 | 0.212    |
| 1     | 45 | 46.12 | 0.027    |
| 2     | 56 | 53.04 | 0.165    |
| 3     | 42 | 40.66 | 0.044    |
| 4     | 27 | 23.38 | 0.561    |
| 5+    | 12 | 16.74 | 1.343    |
|-------|----|----- -|----------|
| Total |200 | 200   | Ï‡Â² = 2.35|

df = 6 - 1 - 1 = 4  (subtract 1 for estimated Î»)
Ï‡Â²_critical (Î± = 0.05, df = 4) = 9.488
p-value â‰ˆ 0.672

Ï‡Â² = 2.35 < 9.488 â†’ FAIL TO REJECT Hâ‚€

CONCLUSION:
The data is consistent with a Poisson distribution 
(Ï‡Â² = 2.35, df = 4, p = 0.672).

The call arrivals can be modeled as Poisson with Î» = 2.3.
```

### Note on Degrees of Freedom

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   DEGREES OF FREEDOM ADJUSTMENT                              â”‚
â”‚                                                             â”‚
â”‚   Basic formula: df = k - 1                                 â”‚
â”‚                                                             â”‚
â”‚   BUT: If you ESTIMATE parameters from the data,           â”‚
â”‚   subtract 1 for EACH estimated parameter:                 â”‚
â”‚                                                             â”‚
â”‚   df = k - 1 - (number of estimated parameters)            â”‚
â”‚                                                             â”‚
â”‚   Examples:                                                 â”‚
â”‚   â€¢ Testing uniform: df = k - 1 (nothing estimated)        â”‚
â”‚   â€¢ Testing Poisson: df = k - 1 - 1 (estimated Î»)         â”‚
â”‚   â€¢ Testing Normal: df = k - 1 - 2 (estimated Î¼ and Ïƒ)    â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Step-by-Step Procedure

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   GOODNESS OF FIT TEST: STEP BY STEP                         â”‚
â”‚                                                             â”‚
â”‚   1. STATE HYPOTHESES                                       â”‚
â”‚      Hâ‚€: Data fits the specified distribution              â”‚
â”‚      Hâ‚: Data does not fit the distribution                â”‚
â”‚                                                             â”‚
â”‚   2. CALCULATE EXPECTED FREQUENCIES                         â”‚
â”‚      E = n Ã— p for each category                           â”‚
â”‚      Or E = n/k for uniform distribution                   â”‚
â”‚                                                             â”‚
â”‚   3. CHECK CONDITIONS                                       â”‚
â”‚      â€¢ Random sample                                        â”‚
â”‚      â€¢ Independent observations                             â”‚
â”‚      â€¢ All expected frequencies â‰¥ 5                        â”‚
â”‚                                                             â”‚
â”‚   4. CALCULATE TEST STATISTIC                               â”‚
â”‚      Ï‡Â² = Î£ (O - E)Â² / E                                   â”‚
â”‚                                                             â”‚
â”‚   5. FIND DEGREES OF FREEDOM                                â”‚
â”‚      df = k - 1 - (estimated parameters)                   â”‚
â”‚                                                             â”‚
â”‚   6. FIND CRITICAL VALUE OR P-VALUE                         â”‚
â”‚      From chi-square table or software                     â”‚
â”‚                                                             â”‚
â”‚   7. MAKE DECISION                                          â”‚
â”‚      Reject Hâ‚€ if Ï‡Â² > Ï‡Â²_critical                         â”‚
â”‚      Or if p-value < Î±                                     â”‚
â”‚                                                             â”‚
â”‚   8. STATE CONCLUSION                                       â”‚
â”‚      In context of the problem                             â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Critical Values Table

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                â”‚
â”‚   CHI-SQUARE CRITICAL VALUES FOR GOODNESS OF FIT               â”‚
â”‚                                                                â”‚
â”‚    df â”‚  Î±=0.10  â”‚  Î±=0.05  â”‚  Î±=0.01  â”‚  Î±=0.001            â”‚
â”‚   â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€            â”‚
â”‚     1 â”‚   2.706  â”‚   3.841  â”‚   6.635  â”‚  10.828             â”‚
â”‚     2 â”‚   4.605  â”‚   5.991  â”‚   9.210  â”‚  13.816             â”‚
â”‚     3 â”‚   6.251  â”‚   7.815  â”‚  11.345  â”‚  16.266             â”‚
â”‚     4 â”‚   7.779  â”‚   9.488  â”‚  13.277  â”‚  18.467             â”‚
â”‚     5 â”‚   9.236  â”‚  11.070  â”‚  15.086  â”‚  20.515             â”‚
â”‚     6 â”‚  10.645  â”‚  12.592  â”‚  16.812  â”‚  22.458             â”‚
â”‚     7 â”‚  12.017  â”‚  14.067  â”‚  18.475  â”‚  24.322             â”‚
â”‚     8 â”‚  13.362  â”‚  15.507  â”‚  20.090  â”‚  26.124             â”‚
â”‚     9 â”‚  14.684  â”‚  16.919  â”‚  21.666  â”‚  27.877             â”‚
â”‚    10 â”‚  15.987  â”‚  18.307  â”‚  23.209  â”‚  29.588             â”‚
â”‚                                                                â”‚
â”‚   Reject Hâ‚€ if Ï‡Â² > critical value                            â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## When Expected Counts Are Too Small

### What If E < 5?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   HANDLING SMALL EXPECTED FREQUENCIES                        â”‚
â”‚                                                             â”‚
â”‚   If any E < 5, the chi-square approximation may be poor   â”‚
â”‚                                                             â”‚
â”‚   OPTIONS:                                                  â”‚
â”‚                                                             â”‚
â”‚   1. COMBINE CATEGORIES                                     â”‚
â”‚      Merge adjacent categories until E â‰¥ 5                 â”‚
â”‚      (df decreases accordingly)                            â”‚
â”‚                                                             â”‚
â”‚   2. EXACT TEST                                             â”‚
â”‚      Use exact multinomial test                            â”‚
â”‚      (computationally intensive)                           â”‚
â”‚                                                             â”‚
â”‚   3. SIMULATION                                             â”‚
â”‚      Monte Carlo simulation for p-value                    â”‚
â”‚                                                             â”‚
â”‚   4. COLLECT MORE DATA                                      â”‚
â”‚      If possible, increase sample size                     â”‚
â”‚                                                             â”‚
â”‚   5. USE CORRECTION                                         â”‚
â”‚      Some use Yates' correction (controversial)            â”‚
â”‚                                                             â”‚
â”‚   RULE OF THUMB:                                            â”‚
â”‚   â€¢ All E â‰¥ 5: Good                                        â”‚
â”‚   â€¢ All E â‰¥ 1 and 80% â‰¥ 5: Acceptable                     â”‚
â”‚   â€¢ Any E < 1: Problematic                                 â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example: Combining Categories

```
Original data with small expected counts:

| Category | O  | E    |
|----------|----|----- |
| A        | 45 | 40   | âœ“
| B        | 30 | 35   | âœ“
| C        | 8  | 10   | âœ“
| D        | 4  | 3    | âœ— E < 5
| E        | 3  | 2    | âœ— E < 5
| Total    | 90 | 90   |

Solution: Combine D and E into "D or E":

| Category | O  | E    |
|----------|----|----- |
| A        | 45 | 40   | âœ“
| B        | 30 | 35   | âœ“
| C        | 8  | 10   | âœ“
| D or E   | 7  | 5    | âœ“ Now E â‰¥ 5!
| Total    | 90 | 90   |

df = 4 - 1 = 3 (reduced from 4)
```

---

## Python Implementation

### Complete Goodness of Fit Function

```python
import numpy as np
from scipy import stats

def goodness_of_fit_test(observed, expected=None, probabilities=None, alpha=0.05):
    """
    Chi-Square Goodness of Fit Test
    
    Parameters:
    - observed: list/array of observed frequencies
    - expected: list/array of expected frequencies (optional)
    - probabilities: list/array of expected probabilities (optional)
    - alpha: significance level
    
    Provide either 'expected' OR 'probabilities', not both.
    If neither provided, assumes uniform distribution.
    """
    observed = np.array(observed)
    n = observed.sum()
    k = len(observed)
    
    # Calculate expected frequencies
    if expected is not None:
        expected = np.array(expected)
    elif probabilities is not None:
        probabilities = np.array(probabilities)
        if not np.isclose(probabilities.sum(), 1.0):
            print(f"âš ï¸ Warning: Probabilities sum to {probabilities.sum()}, not 1.0")
        expected = n * probabilities
    else:
        # Uniform distribution
        expected = np.array([n/k] * k)
    
    # Check condition
    small_expected = (expected < 5).sum()
    if small_expected > 0:
        print(f"âš ï¸ Warning: {small_expected} categories have expected frequency < 5")
    
    # Calculate chi-square statistic
    chi_sq = np.sum((observed - expected)**2 / expected)
    
    # Degrees of freedom
    df = k - 1
    
    # p-value
    p_value = 1 - stats.chi2.cdf(chi_sq, df)
    
    # Critical value
    chi_critical = stats.chi2.ppf(1 - alpha, df)
    
    # Decision
    reject = chi_sq > chi_critical
    
    # Contributions to chi-square
    contributions = (observed - expected)**2 / expected
    
    return {
        'chi_square': chi_sq,
        'df': df,
        'p_value': p_value,
        'chi_critical': chi_critical,
        'reject_null': reject,
        'alpha': alpha,
        'observed': observed,
        'expected': expected,
        'contributions': contributions,
        'residuals': (observed - expected) / np.sqrt(expected)
    }

def print_gof_results(result, categories=None):
    """Pretty print the goodness of fit results"""
    k = len(result['observed'])
    if categories is None:
        categories = [f"Cat {i+1}" for i in range(k)]
    
    print("=" * 60)
    print("CHI-SQUARE GOODNESS OF FIT TEST")
    print("=" * 60)
    
    print(f"\n{'Category':<15} {'Observed':>10} {'Expected':>10} {'(O-E)Â²/E':>10}")
    print("-" * 50)
    for i, cat in enumerate(categories):
        print(f"{cat:<15} {result['observed'][i]:>10.0f} "
              f"{result['expected'][i]:>10.2f} "
              f"{result['contributions'][i]:>10.3f}")
    print("-" * 50)
    print(f"{'Total':<15} {result['observed'].sum():>10.0f} "
          f"{result['expected'].sum():>10.2f} "
          f"{result['chi_square']:>10.3f}")
    
    print(f"\nTest Statistics:")
    print(f"  Ï‡Â² = {result['chi_square']:.4f}")
    print(f"  df = {result['df']}")
    print(f"  p-value = {result['p_value']:.4f}")
    print(f"  Critical value (Î±={result['alpha']}) = {result['chi_critical']:.4f}")
    
    print(f"\nDecision: ", end="")
    if result['reject_null']:
        print("REJECT Hâ‚€")
        print("  The data does NOT fit the expected distribution.")
    else:
        print("FAIL TO REJECT Hâ‚€")
        print("  The data is consistent with the expected distribution.")

# ============================================
# EXAMPLES
# ============================================

# Example 1: Slot Machine
print("\n" + "=" * 60)
print("EXAMPLE 1: SLOT MACHINE")
print("=" * 60)

observed = [95, 110, 105, 120, 70]  # Cherry, Lemon, Bell, Star, Diamond
categories = ['ğŸ’ Cherry', 'ğŸ‹ Lemon', 'ğŸ”” Bell', 'â­ Star', 'ğŸ’ Diamond']

result = goodness_of_fit_test(observed)  # Uniform expected
print_gof_results(result, categories)

# Example 2: Mendelian Genetics (9:3:3:1)
print("\n" + "=" * 60)
print("EXAMPLE 2: MENDELIAN GENETICS (9:3:3:1 ratio)")
print("=" * 60)

observed = [315, 108, 101, 32]
probabilities = [9/16, 3/16, 3/16, 1/16]
categories = ['Round Yellow', 'Round Green', 'Wrinkled Yellow', 'Wrinkled Green']

result = goodness_of_fit_test(observed, probabilities=probabilities)
print_gof_results(result, categories)

# Example 3: Die Fairness
print("\n" + "=" * 60)
print("EXAMPLE 3: DIE FAIRNESS")
print("=" * 60)

observed = [25, 17, 15, 23, 24, 16]
categories = ['Face 1', 'Face 2', 'Face 3', 'Face 4', 'Face 5', 'Face 6']

result = goodness_of_fit_test(observed)
print_gof_results(result, categories)
```

### Visualization Function

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

def visualize_goodness_of_fit(observed, expected, categories=None, title="Goodness of Fit"):
    """Visualize observed vs expected frequencies"""
    
    k = len(observed)
    if categories is None:
        categories = [f"Cat {i+1}" for i in range(k)]
    
    x = np.arange(k)
    width = 0.35
    
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))
    
    # Plot 1: Bar chart comparison
    ax1 = axes[0]
    bars1 = ax1.bar(x - width/2, observed, width, label='Observed', color='steelblue')
    bars2 = ax1.bar(x + width/2, expected, width, label='Expected', color='coral')
    
    ax1.set_xlabel('Category', fontsize=12)
    ax1.set_ylabel('Frequency', fontsize=12)
    ax1.set_title(f'{title}\nObserved vs Expected Frequencies', fontsize=14)
    ax1.set_xticks(x)
    ax1.set_xticklabels(categories, rotation=45, ha='right')
    ax1.legend()
    ax1.grid(True, alpha=0.3, axis='y')
    
    # Add value labels
    for bar in bars1:
        height = bar.get_height()
        ax1.annotate(f'{height:.0f}',
                    xy=(bar.get_x() + bar.get_width()/2, height),
                    xytext=(0, 3), textcoords="offset points",
                    ha='center', va='bottom', fontsize=9)
    for bar in bars2:
        height = bar.get_height()
        ax1.annotate(f'{height:.1f}',
                    xy=(bar.get_x() + bar.get_width()/2, height),
                    xytext=(0, 3), textcoords="offset points",
                    ha='center', va='bottom', fontsize=9)
    
    # Plot 2: Contribution to chi-square
    ax2 = axes[1]
    contributions = (np.array(observed) - np.array(expected))**2 / np.array(expected)
    colors = ['green' if c < 1 else 'orange' if c < 4 else 'red' for c in contributions]
    
    bars = ax2.bar(categories, contributions, color=colors)
    ax2.set_xlabel('Category', fontsize=12)
    ax2.set_ylabel('(O - E)Â² / E', fontsize=12)
    ax2.set_title('Contribution to Chi-Square\n(Green < 1, Orange < 4, Red â‰¥ 4)', fontsize=14)
    ax2.set_xticklabels(categories, rotation=45, ha='right')
    ax2.grid(True, alpha=0.3, axis='y')
    
    chi_sq = contributions.sum()
    ax2.axhline(y=chi_sq/k, color='black', linestyle='--', 
                label=f'Average contribution = {chi_sq/k:.2f}')
    ax2.legend()
    
    plt.tight_layout()
    plt.show()
    
    return chi_sq

def visualize_chi_square_test(chi_sq, df, alpha=0.05):
    """Visualize the chi-square test result"""
    
    chi_critical = stats.chi2.ppf(1 - alpha, df)
    p_value = 1 - stats.chi2.cdf(chi_sq, df)
    
    fig, ax = plt.subplots(figsize=(12, 6))
    
    x_max = max(chi_sq * 1.5, chi_critical * 1.5, df * 3)
    x = np.linspace(0.01, x_max, 500)
    y = stats.chi2.pdf(x, df)
    
    # Distribution
    ax.plot(x, y, 'b-', linewidth=2, label=f'Ï‡Â² distribution (df={df})')
    ax.fill_between(x, y, alpha=0.1)
    
    # Rejection region
    x_reject = x[x >= chi_critical]
    y_reject = stats.chi2.pdf(x_reject, df)
    ax.fill_between(x_reject, y_reject, color='red', alpha=0.4,
                    label=f'Rejection region (Î±={alpha})')
    
    # Critical value line
    ax.axvline(chi_critical, color='red', linestyle='--', linewidth=1.5,
               label=f'Critical value = {chi_critical:.3f}')
    
    # Test statistic line
    ax.axvline(chi_sq, color='green', linewidth=2.5,
               label=f'Ï‡Â² = {chi_sq:.3f}')
    
    decision = "REJECT Hâ‚€" if chi_sq > chi_critical else "FAIL TO REJECT Hâ‚€"
    ax.set_title(f'Chi-Square Goodness of Fit Test\n{decision} (p-value = {p_value:.4f})',
                fontsize=14)
    ax.set_xlabel('Ï‡Â²', fontsize=12)
    ax.set_ylabel('Density', fontsize=12)
    ax.legend(loc='upper right')
    ax.grid(True, alpha=0.3)
    ax.set_xlim(0, x_max)
    
    plt.tight_layout()
    plt.show()

# Visualize the slot machine example
observed = [95, 110, 105, 120, 70]
expected = [100, 100, 100, 100, 100]
categories = ['Cherry', 'Lemon', 'Bell', 'Star', 'Diamond']

chi_sq = visualize_goodness_of_fit(observed, expected, categories, "Slot Machine Test")
visualize_chi_square_test(chi_sq, df=4)
```

---

## Common Applications

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   COMMON APPLICATIONS OF GOODNESS OF FIT TEST               â”‚
â”‚                                                             â”‚
â”‚   1. FAIRNESS TESTING                                       â”‚
â”‚      â€¢ Dice, coins, random number generators               â”‚
â”‚      â€¢ Lottery and gambling devices                        â”‚
â”‚      â€¢ A/B test random assignment                          â”‚
â”‚                                                             â”‚
â”‚   2. GENETICS                                               â”‚
â”‚      â€¢ Mendelian inheritance ratios                        â”‚
â”‚      â€¢ Hardy-Weinberg equilibrium                          â”‚
â”‚      â€¢ Gene frequency distributions                        â”‚
â”‚                                                             â”‚
â”‚   3. DISTRIBUTION FITTING                                   â”‚
â”‚      â€¢ Testing for Poisson (arrivals, events)             â”‚
â”‚      â€¢ Testing for Normal distribution                     â”‚
â”‚      â€¢ Testing for Exponential (waiting times)            â”‚
â”‚                                                             â”‚
â”‚   4. MARKET RESEARCH                                        â”‚
â”‚      â€¢ Brand preference distributions                      â”‚
â”‚      â€¢ Customer demographic matching                       â”‚
â”‚      â€¢ Response rate verification                          â”‚
â”‚                                                             â”‚
â”‚   5. QUALITY CONTROL                                        â”‚
â”‚      â€¢ Defect distribution across shifts                  â”‚
â”‚      â€¢ Product category verification                       â”‚
â”‚      â€¢ Equipment calibration testing                       â”‚
â”‚                                                             â”‚
â”‚   6. SOCIAL SCIENCES                                        â”‚
â”‚      â€¢ Population distribution verification               â”‚
â”‚      â€¢ Survey response patterns                            â”‚
â”‚      â€¢ Behavior frequency analysis                         â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Practice Problems ğŸ“

### Problem 1: Coin Flipping
A coin is flipped 200 times: 118 heads, 82 tails. Is the coin fair at Î± = 0.05?

<details>
<summary>Click for Solution</summary>

```
Hâ‚€: Coin is fair (P(H) = P(T) = 0.5)
Hâ‚: Coin is not fair
Î± = 0.05

Expected: 200 Ã— 0.5 = 100 each

| Outcome | O   | E   | (O-E)Â²/E |
|---------|-----|-----|----------|
| Heads   | 118 | 100 | 3.24     |
| Tails   | 82  | 100 | 3.24     |
| Total   | 200 | 200 | Ï‡Â² = 6.48|

df = 2 - 1 = 1
Ï‡Â²_critical (Î± = 0.05, df = 1) = 3.841
p-value = 0.011

Ï‡Â² = 6.48 > 3.841 â†’ REJECT Hâ‚€

Conclusion: At Î± = 0.05, there is significant evidence 
the coin is not fair (Ï‡Â² = 6.48, p = 0.011).
The coin appears biased toward heads.
```

</details>

---

### Problem 2: Customer Preferences
A company claims its 3 products are equally preferred. Survey of 150 customers:
- Product A: 65
- Product B: 50
- Product C: 35

Test at Î± = 0.05.

<details>
<summary>Click for Solution</summary>

```
Hâ‚€: Products are equally preferred (1/3 each)
Hâ‚: Products are not equally preferred
Î± = 0.05

Expected: 150 Ã— (1/3) = 50 each

| Product | O  | E  | (O-E)Â²/E |
|---------|----|----|----------|
| A       | 65 | 50 | 4.50     |
| B       | 50 | 50 | 0.00     |
| C       | 35 | 50 | 4.50     |
| Total   |150 |150 | Ï‡Â² = 9.00|

df = 3 - 1 = 2
Ï‡Â²_critical (Î± = 0.05, df = 2) = 5.991
p-value = 0.011

Ï‡Â² = 9.00 > 5.991 â†’ REJECT Hâ‚€

Conclusion: Products are NOT equally preferred.
Product A is most preferred (43%), Product C least (23%).
```

</details>

---

### Problem 3: Blood Type Distribution
A region's blood type distribution is claimed to be: O: 45%, A: 40%, B: 11%, AB: 4%.
Sample of 500 people: O: 210, A: 215, B: 50, AB: 25.
Does the sample match the claimed distribution at Î± = 0.05?

<details>
<summary>Click for Solution</summary>

```
Hâ‚€: Blood types match claimed distribution
Hâ‚: Blood types do not match claimed distribution
Î± = 0.05

Expected frequencies:
O:  500 Ã— 0.45 = 225
A:  500 Ã— 0.40 = 200
B:  500 Ã— 0.11 = 55
AB: 500 Ã— 0.04 = 20

| Type | O   | E   | (O-E)Â²/E |
|------|-----|-----|----------|
| O    | 210 | 225 | 1.00     |
| A    | 215 | 200 | 1.13     |
| B    | 50  | 55  | 0.45     |
| AB   | 25  | 20  | 1.25     |
| Total| 500 | 500 | Ï‡Â² = 3.83|

df = 4 - 1 = 3
Ï‡Â²_critical (Î± = 0.05, df = 3) = 7.815
p-value = 0.280

Ï‡Â² = 3.83 < 7.815 â†’ FAIL TO REJECT Hâ‚€

Conclusion: The sample is consistent with the claimed 
blood type distribution (Ï‡Â² = 3.83, p = 0.280).
```

</details>

---

### Problem 4: Last Digit Fraud Detection
Fraudulent data often has unnatural digit patterns. The last digits of 200 expense reports:

| Digit | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 |
|-------|---|---|---|---|---|---|---|---|---|---|
| Count | 35| 12| 18| 15| 22| 38| 14| 16| 18| 12|

Are the digits uniformly distributed (as expected in natural data)?

<details>
<summary>Click for Solution</summary>

```
Hâ‚€: Last digits are uniformly distributed (10% each)
Hâ‚: Last digits are not uniformly distributed
Î± = 0.05

Expected: 200 Ã— 0.10 = 20 each

| Digit | O  | E  | (O-E)Â²/E |
|-------|----|----|----------|
| 0     | 35 | 20 | 11.25    |
| 1     | 12 | 20 | 3.20     |
| 2     | 18 | 20 | 0.20     |
| 3     | 15 | 20 | 1.25     |
| 4     | 22 | 20 | 0.20     |
| 5     | 38 | 20 | 16.20    |
| 6     | 14 | 20 | 1.80     |
| 7     | 16 | 20 | 0.80     |
| 8     | 18 | 20 | 0.20     |
| 9     | 12 | 20 | 3.20     |
|-------|----|----|----------|
| Total | 200| 200| Ï‡Â² =38.30|

df = 10 - 1 = 9
Ï‡Â²_critical (Î± = 0.05, df = 9) = 16.919
p-value < 0.0001

Ï‡Â² = 38.30 > 16.919 â†’ REJECT Hâ‚€

Conclusion: The last digits are NOT uniformly distributed!
Digits 0 and 5 appear far more often than expected 
(35 and 38 vs expected 20). This is a red flag for 
potential fraud â€” people tend to round to 0 and 5!
```

</details>

---

## Summary: The Essence of Goodness of Fit

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚            CHI-SQUARE GOODNESS OF FIT TEST                       â”‚
â”‚            â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                       â”‚
â”‚                                                                  â”‚
â”‚   PURPOSE:                                                       â”‚
â”‚   Test if observed data fits an expected distribution           â”‚
â”‚                                                                  â”‚
â”‚   THE FORMULA:                                                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚              (Observed - Expected)Â²                      â”‚   â”‚
â”‚   â”‚       Ï‡Â² = Î£ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”‚   â”‚
â”‚   â”‚                   Expected                               â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â”‚   DEGREES OF FREEDOM:                                            â”‚
â”‚   df = k - 1 - (number of estimated parameters)                 â”‚
â”‚                                                                  â”‚
â”‚   CONDITIONS:                                                    â”‚
â”‚   â€¢ Random sample                                               â”‚
â”‚   â€¢ Independent observations                                     â”‚
â”‚   â€¢ All expected frequencies â‰¥ 5                                â”‚
â”‚                                                                  â”‚
â”‚   INTERPRETATION:                                                â”‚
â”‚   â€¢ Small Ï‡Â² â†’ Good fit (observed â‰ˆ expected)                  â”‚
â”‚   â€¢ Large Ï‡Â² â†’ Poor fit (observed â‰  expected)                  â”‚
â”‚                                                                  â”‚
â”‚   APPLICATIONS:                                                  â”‚
â”‚   â€¢ Fairness testing (dice, coins, RNG)                        â”‚
â”‚   â€¢ Genetics (Mendelian ratios)                                 â”‚
â”‚   â€¢ Distribution fitting (Poisson, Normal)                      â”‚
â”‚   â€¢ Fraud detection (digit analysis)                            â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Quick Reference Card

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 GOODNESS OF FIT QUICK REFERENCE                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   FORMULA: Ï‡Â² = Î£ (O - E)Â² / E                                  â”‚
â”‚                                                                  â”‚
â”‚   EXPECTED FREQUENCIES:                                          â”‚
â”‚   â€¢ Uniform: E = n / k                                          â”‚
â”‚   â€¢ Specified: E = n Ã— páµ¢                                       â”‚
â”‚                                                                  â”‚
â”‚   DEGREES OF FREEDOM:                                            â”‚
â”‚   df = k - 1 - (estimated parameters)                           â”‚
â”‚                                                                  â”‚
â”‚   CRITICAL VALUES (Î± = 0.05):                                    â”‚
â”‚   df=1: 3.841 â”‚ df=2: 5.991 â”‚ df=3: 7.815 â”‚ df=4: 9.488        â”‚
â”‚   df=5: 11.07 â”‚ df=6: 12.59 â”‚ df=7: 14.07 â”‚ df=8: 15.51        â”‚
â”‚                                                                  â”‚
â”‚   CONDITIONS:                                                    â”‚
â”‚   âœ“ Random sample                                               â”‚
â”‚   âœ“ Independent observations                                    â”‚
â”‚   âœ“ All E â‰¥ 5 (or combine categories)                          â”‚
â”‚                                                                  â”‚
â”‚   DECISION: Reject Hâ‚€ if Ï‡Â² > Ï‡Â²_critical                       â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

> **"The Goodness of Fit test answers a simple but powerful question: Does reality match expectation? When the gap is too large to blame on chance, something interesting is happening â€” whether it's a rigged slot machine, genetic mutation, or fraudulent data!"**

From testing dice fairness to detecting fraud, the Goodness of Fit test is your tool for comparing what IS to what SHOULD BE! ğŸ¯

---

*From observed to expected, from data to distribution â€” that's the power of Goodness of Fit!* ğŸ“Š