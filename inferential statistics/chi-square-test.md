# Chi-Square Test
## The Test for Categorical Data ğŸ“Š

---

## What is the Chi-Square Test?

The Chi-Square (Ï‡Â²) test is a statistical test used to analyze **categorical data** â€” data that can be divided into groups or categories. It answers questions like:

- Does this die roll fairly?
- Is there a relationship between gender and voting preference?
- Do different treatments have different success rates?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   CHI-SQUARE TEST                                            â”‚
â”‚                                                             â”‚
â”‚   Purpose: Analyze categorical (count) data                â”‚
â”‚                                                             â”‚
â”‚   Core Question:                                            â”‚
â”‚   "Is the difference between what we OBSERVED and what     â”‚
â”‚   we EXPECTED large enough to be statistically significant?"â”‚
â”‚                                                             â”‚
â”‚   Key Formula:                                              â”‚
â”‚                   (Observed - Expected)Â²                    â”‚
â”‚         Ï‡Â² = Î£ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”‚
â”‚                      Expected                               â”‚
â”‚                                                             â”‚
â”‚   Compares: Observed frequencies vs Expected frequencies   â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## The Three Types of Chi-Square Tests

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   THREE TYPES OF CHI-SQUARE TESTS                            â”‚
â”‚                                                             â”‚
â”‚   1. GOODNESS OF FIT TEST                                   â”‚
â”‚      Does our data fit a specific distribution?            â”‚
â”‚      "Is this die fair?"                                   â”‚
â”‚      One categorical variable                              â”‚
â”‚                                                             â”‚
â”‚   2. TEST OF INDEPENDENCE                                   â”‚
â”‚      Are two categorical variables related?                â”‚
â”‚      "Is smoking related to lung cancer?"                  â”‚
â”‚      Two categorical variables, one sample                 â”‚
â”‚                                                             â”‚
â”‚   3. TEST OF HOMOGENEITY                                    â”‚
â”‚      Do different populations have same distribution?      â”‚
â”‚      "Do men and women have same voting patterns?"         â”‚
â”‚      One categorical variable, multiple populations        â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## The Chi-Square Distribution

### What Does It Look Like?

```
                    Chi-Square Distribution
                    
    â”‚
    â”‚â•²
    â”‚ â•²
    â”‚  â•²   df = 1
    â”‚   â•²
    â”‚    â•²
    â”‚     â•²
    â”‚      â•²â”€â”€â”€â”€  df = 3
    â”‚         â•²
    â”‚          â•²â”€â”€â”€â”€â”€â”€  df = 5
    â”‚            â•²
    â”‚             â•²â”€â”€â”€â”€â”€â”€â”€â”€  df = 10
    â”‚               â•²
    â”‚                â•²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
    0                                        Ï‡Â²
    
    Properties:
    â€¢ Always positive (Ï‡Â² â‰¥ 0)
    â€¢ Right-skewed (especially for small df)
    â€¢ Becomes more symmetric as df increases
    â€¢ Mean = df, Variance = 2Ã—df
```

### Key Properties

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   CHI-SQUARE DISTRIBUTION PROPERTIES                         â”‚
â”‚                                                             â”‚
â”‚   â€¢ Notation: Ï‡Â² ~ Ï‡Â²(df)                                  â”‚
â”‚   â€¢ Domain: [0, âˆ) â€” always non-negative                   â”‚
â”‚   â€¢ Mean (Î¼) = df                                          â”‚
â”‚   â€¢ Variance (ÏƒÂ²) = 2 Ã— df                                 â”‚
â”‚   â€¢ Shape: Right-skewed, approaches normal as df â†’ âˆ      â”‚
â”‚                                                             â”‚
â”‚   Degrees of Freedom depend on test type:                  â”‚
â”‚   â€¢ Goodness of Fit: df = k - 1                           â”‚
â”‚   â€¢ Independence: df = (r - 1)(c - 1)                     â”‚
â”‚   â€¢ Homogeneity: df = (r - 1)(c - 1)                      â”‚
â”‚                                                             â”‚
â”‚   Where: k = categories, r = rows, c = columns            â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## The Chi-Square Formula

### The Core Calculation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   CHI-SQUARE TEST STATISTIC                                  â”‚
â”‚                                                             â”‚
â”‚              k   (Oáµ¢ - Eáµ¢)Â²                                 â”‚
â”‚        Ï‡Â² = Î£  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                 â”‚
â”‚             i=1     Eáµ¢                                      â”‚
â”‚                                                             â”‚
â”‚   Where:                                                    â”‚
â”‚   â€¢ Oáµ¢ = Observed frequency in category i                  â”‚
â”‚   â€¢ Eáµ¢ = Expected frequency in category i                  â”‚
â”‚   â€¢ k = number of categories                               â”‚
â”‚                                                             â”‚
â”‚   Interpretation:                                           â”‚
â”‚   â€¢ Small Ï‡Â² â†’ Observed â‰ˆ Expected (good fit)             â”‚
â”‚   â€¢ Large Ï‡Â² â†’ Observed â‰  Expected (poor fit)             â”‚
â”‚                                                             â”‚
â”‚   The test is always ONE-TAILED (right tail)               â”‚
â”‚   We only care if Ï‡Â² is "too large"                        â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why Square the Difference?

```
Without squaring:
â€¢ Positive and negative differences would cancel out
â€¢ Total could be zero even with bad fit!

With squaring:
â€¢ All differences become positive
â€¢ Larger differences are penalized more heavily
â€¢ Dividing by E standardizes the contribution
```

---

# Part 1: Chi-Square Goodness of Fit Test
## *Does our data fit the expected distribution?*

---

## When to Use Goodness of Fit Test

- Testing if a die is fair
- Testing if births are equally distributed across days
- Testing if observed ratios match theoretical ratios
- Testing if data follows a specific distribution

---

## ğŸ“– Story: Is the Casino Die Fair?

Rafiq suspects a casino is using loaded dice. He secretly records 600 rolls of a die:

| Outcome | 1 | 2 | 3 | 4 | 5 | 6 |
|---------|---|---|---|---|---|---|
| **Observed** | 89 | 95 | 105 | 115 | 108 | 88 |

**Question:** Is the die fair, or is there evidence of cheating?

### Step 1: State the Hypotheses

```
Hâ‚€: The die is fair (all outcomes equally likely)
    P(1) = P(2) = P(3) = P(4) = P(5) = P(6) = 1/6

Hâ‚: The die is NOT fair (outcomes not equally likely)

Î± = 0.05
```

### Step 2: Calculate Expected Frequencies

```
If the die is fair, each outcome should appear 1/6 of the time:

Expected for each outcome = Total rolls Ã— (1/6)
                         = 600 Ã— (1/6)
                         = 100

| Outcome | Observed (O) | Expected (E) |
|---------|--------------|--------------|
| 1       | 89           | 100          |
| 2       | 95           | 100          |
| 3       | 105          | 100          |
| 4       | 115          | 100          |
| 5       | 108          | 100          |
| 6       | 88           | 100          |
| Total   | 600          | 600          |
```

### Step 3: Calculate Chi-Square Statistic

```
       (O - E)Â²
Ï‡Â² = Î£ â”€â”€â”€â”€â”€â”€â”€â”€â”€
          E

| Outcome | O    | E    | O - E  | (O-E)Â² | (O-E)Â²/E |
|---------|------|------|--------|--------|----------|
| 1       | 89   | 100  | -11    | 121    | 1.21     |
| 2       | 95   | 100  | -5     | 25     | 0.25     |
| 3       | 105  | 100  | +5     | 25     | 0.25     |
| 4       | 115  | 100  | +15    | 225    | 2.25     |
| 5       | 108  | 100  | +8     | 64     | 0.64     |
| 6       | 88   | 100  | -12    | 144    | 1.44     |
|---------|------|------|--------|--------|----------|
| Total   | 600  | 600  |   0    |        | Ï‡Â² = 6.04|
```

### Step 4: Find Degrees of Freedom and Critical Value

```
df = k - 1 = 6 - 1 = 5

For Î± = 0.05 and df = 5:
Ï‡Â²_critical = 11.07

Or find p-value:
p-value = P(Ï‡Â² > 6.04 | df = 5) â‰ˆ 0.303
```

### Step 5: Make a Decision

```
Ï‡Â² = 6.04 < Ï‡Â²_critical = 11.07

OR

p-value = 0.303 > Î± = 0.05

DECISION: FAIL TO REJECT Hâ‚€
```

### Step 6: State the Conclusion

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   CONCLUSION                                                 â”‚
â”‚                                                             â”‚
â”‚   At the Î± = 0.05 significance level, there is             â”‚
â”‚   INSUFFICIENT evidence to conclude that the die is        â”‚
â”‚   unfair (Ï‡Â² = 6.04, df = 5, p = 0.303).                  â”‚
â”‚                                                             â”‚
â”‚   The observed differences from expected frequencies       â”‚
â”‚   could reasonably occur by chance with a fair die.       â”‚
â”‚                                                             â”‚
â”‚   Rafiq cannot prove the casino is cheating.               â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“– Example 2: Genetics (Mendelian Ratios)

A biologist crosses plants and observes offspring phenotypes. Mendelian genetics predicts a 9:3:3:1 ratio.

**Observed:** 315 round yellow, 108 round green, 101 wrinkled yellow, 32 wrinkled green

**Total:** 556 plants

### Solution

```
Step 1: Hypotheses
Hâ‚€: Offspring follow 9:3:3:1 ratio
Hâ‚: Offspring do NOT follow 9:3:3:1 ratio
Î± = 0.05

Step 2: Expected frequencies (based on 9:3:3:1)
Total parts = 9 + 3 + 3 + 1 = 16

Expected:
â€¢ Round Yellow: 556 Ã— 9/16 = 312.75
â€¢ Round Green: 556 Ã— 3/16 = 104.25
â€¢ Wrinkled Yellow: 556 Ã— 3/16 = 104.25
â€¢ Wrinkled Green: 556 Ã— 1/16 = 34.75

Step 3: Calculate Ï‡Â²
| Phenotype        | O    | E      | (O-E)Â²/E |
|------------------|------|--------|----------|
| Round Yellow     | 315  | 312.75 | 0.016    |
| Round Green      | 108  | 104.25 | 0.135    |
| Wrinkled Yellow  | 101  | 104.25 | 0.101    |
| Wrinkled Green   | 32   | 34.75  | 0.218    |
|------------------|------|--------|----------|
| Total            | 556  | 556    | Ï‡Â² = 0.47|

Step 4: Critical value
df = 4 - 1 = 3
Ï‡Â²_critical (Î± = 0.05, df = 3) = 7.815
p-value â‰ˆ 0.925

Step 5: Decision
Ï‡Â² = 0.47 < 7.815 â†’ FAIL TO REJECT Hâ‚€

Conclusion: The data is consistent with Mendelian 9:3:3:1 ratio.
This is a classic result that supported Mendel's theory!
```

---

# Part 2: Chi-Square Test of Independence
## *Are two categorical variables related?*

---

## When to Use Test of Independence

- Is there a relationship between smoking and lung cancer?
- Is education level related to political preference?
- Is customer satisfaction related to product type?
- Is treatment type related to recovery outcome?

---

## ğŸ“– Story: Smoking and Lung Cancer

Dr. Fatima studies the relationship between smoking and lung cancer. She collects data from 1,000 patients:

```
                    CONTINGENCY TABLE (Observed)
                    
                    â”‚  Lung Cancer  â”‚  No Cancer  â”‚  Total
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€
    Smoker          â”‚      90       â”‚     210     â”‚   300
    Non-Smoker      â”‚      60       â”‚     640     â”‚   700
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€
    Total           â”‚     150       â”‚     850     â”‚  1000
```

**Question:** Is smoking related to (associated with) lung cancer?

### Step 1: State the Hypotheses

```
Hâ‚€: Smoking and lung cancer are INDEPENDENT
    (No relationship between them)

Hâ‚: Smoking and lung cancer are NOT independent
    (There IS a relationship)

Î± = 0.05
```

### Step 2: Calculate Expected Frequencies

```
If Hâ‚€ is true (variables are independent):

Expected = (Row Total Ã— Column Total) / Grand Total

Eâ‚â‚ (Smoker, Cancer) = (300 Ã— 150) / 1000 = 45
Eâ‚â‚‚ (Smoker, No Cancer) = (300 Ã— 850) / 1000 = 255
Eâ‚‚â‚ (Non-Smoker, Cancer) = (700 Ã— 150) / 1000 = 105
Eâ‚‚â‚‚ (Non-Smoker, No Cancer) = (700 Ã— 850) / 1000 = 595

                    EXPECTED FREQUENCIES
                    
                    â”‚  Lung Cancer  â”‚  No Cancer  â”‚  Total
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€
    Smoker          â”‚      45       â”‚     255     â”‚   300
    Non-Smoker      â”‚     105       â”‚     595     â”‚   700
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€
    Total           â”‚     150       â”‚     850     â”‚  1000
```

### Step 3: Check Expected Count Condition

```
All expected counts should be â‰¥ 5:
45, 255, 105, 595 â€” all â‰¥ 5 âœ“

Condition satisfied!
```

### Step 4: Calculate Chi-Square Statistic

```
       (O - E)Â²
Ï‡Â² = Î£ â”€â”€â”€â”€â”€â”€â”€â”€â”€
          E

| Cell            | O    | E    | O - E  | (O-E)Â²  | (O-E)Â²/E |
|-----------------|------|------|--------|---------|----------|
| Smoker+Cancer   | 90   | 45   | +45    | 2025    | 45.00    |
| Smoker+NoCancer | 210  | 255  | -45    | 2025    | 7.94     |
| NonSmkr+Cancer  | 60   | 105  | -45    | 2025    | 19.29    |
| NonSmkr+NoCancer| 640  | 595  | +45    | 2025    | 3.40     |
|-----------------|------|------|--------|---------|----------|
| Total           | 1000 | 1000 |   0    |         | Ï‡Â²=75.63 |
```

### Step 5: Find Degrees of Freedom and Critical Value

```
df = (rows - 1) Ã— (columns - 1)
   = (2 - 1) Ã— (2 - 1)
   = 1 Ã— 1
   = 1

For Î± = 0.05 and df = 1:
Ï‡Â²_critical = 3.841

p-value = P(Ï‡Â² > 75.63 | df = 1) < 0.0001
```

### Step 6: Make a Decision

```
Ï‡Â² = 75.63 >> Ï‡Â²_critical = 3.841

p-value < 0.0001 << Î± = 0.05

DECISION: REJECT Hâ‚€
```

### Step 7: State the Conclusion

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   CONCLUSION                                                 â”‚
â”‚                                                             â”‚
â”‚   At Î± = 0.05, there is STRONG evidence of a relationship  â”‚
â”‚   between smoking and lung cancer (Ï‡Â² = 75.63, df = 1,    â”‚
â”‚   p < 0.0001).                                             â”‚
â”‚                                                             â”‚
â”‚   Smoking and lung cancer are NOT independent.             â”‚
â”‚                                                             â”‚
â”‚   Looking at the data:                                      â”‚
â”‚   â€¢ Smokers: 90/300 = 30% have lung cancer                â”‚
â”‚   â€¢ Non-smokers: 60/700 = 8.6% have lung cancer           â”‚
â”‚                                                             â”‚
â”‚   Smokers have ~3.5Ã— higher rate of lung cancer!          â”‚
â”‚                                                             â”‚
â”‚   âš ï¸ Note: This shows ASSOCIATION, not necessarily        â”‚
â”‚   CAUSATION (though in this case, causation is proven).   â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Visual: Observed vs Expected

```
                OBSERVED                      EXPECTED (if independent)
                
    Cancer  â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â”‚ 90            Cancer  â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â”‚ 45
    No Canc â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚ 210           No Canc â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚ 255
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ Smoker                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ Smoker
            
    Cancer  â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â”‚ 60            Cancer  â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚ 105
    No Canc â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚ 640           No Canc â”‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”‚ 595
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ Non-Smoker            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ Non-Smoker

    Smokers have WAY more cancer than expected if independent!
```

---

## ğŸ“– Example 3: Education and Political Preference

A survey asks 500 people about education and political preference:

```
                    â”‚ Liberal â”‚ Conservative â”‚ Independent â”‚ Total
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
    High School     â”‚   40    â”‚      80      â”‚     30      â”‚  150
    College         â”‚   70    â”‚      70      â”‚     60      â”‚  200
    Graduate        â”‚   60    â”‚      30      â”‚     60      â”‚  150
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
    Total           â”‚  170    â”‚     180      â”‚    150      â”‚  500
```

### Solution

```
Hâ‚€: Education and political preference are independent
Hâ‚: Education and political preference are related
Î± = 0.05

Expected frequencies: E = (Row Total Ã— Col Total) / 500

| Cell                    | O  | E    | (O-E)Â²/E |
|-------------------------|----|------|----------|
| HS + Liberal            | 40 | 51   | 2.37     |
| HS + Conservative       | 80 | 54   | 12.52    |
| HS + Independent        | 30 | 45   | 5.00     |
| College + Liberal       | 70 | 68   | 0.06     |
| College + Conservative  | 70 | 72   | 0.06     |
| College + Independent   | 60 | 60   | 0.00     |
| Grad + Liberal          | 60 | 51   | 1.59     |
| Grad + Conservative     | 30 | 54   | 10.67    |
| Grad + Independent      | 60 | 45   | 5.00     |
|-------------------------|----|------|----------|
| Total                   |500 | 500  | Ï‡Â²=37.27 |

df = (3-1)(3-1) = 4
Ï‡Â²_critical (Î±=0.05, df=4) = 9.488
p-value < 0.0001

Ï‡Â² = 37.27 > 9.488 â†’ REJECT Hâ‚€

Conclusion: There IS a significant relationship between 
education level and political preference.

Observations:
â€¢ High school: More conservative
â€¢ Graduate: More liberal and independent
â€¢ College: Relatively balanced
```

---

# Part 3: Chi-Square Test of Homogeneity
## *Do different populations have the same distribution?*

---

## When to Use Test of Homogeneity

- Do men and women have the same voting patterns?
- Do different age groups have the same brand preferences?
- Do patients from different hospitals have the same recovery rates?

---

## Test of Independence vs Homogeneity

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   INDEPENDENCE vs HOMOGENEITY                                â”‚
â”‚                                                             â”‚
â”‚   TEST OF INDEPENDENCE:                                      â”‚
â”‚   â€¢ ONE sample from ONE population                         â”‚
â”‚   â€¢ Two variables measured on each subject                 â”‚
â”‚   â€¢ Question: Are the two variables related?               â”‚
â”‚   â€¢ Example: Survey 1000 people, ask about smoking AND    â”‚
â”‚     cancer status                                          â”‚
â”‚                                                             â”‚
â”‚   TEST OF HOMOGENEITY:                                       â”‚
â”‚   â€¢ Multiple samples from DIFFERENT populations            â”‚
â”‚   â€¢ One variable measured                                  â”‚
â”‚   â€¢ Question: Same distribution across populations?        â”‚
â”‚   â€¢ Example: Sample from Men and Women separately,        â”‚
â”‚     ask about voting preference                            â”‚
â”‚                                                             â”‚
â”‚   MATHEMATICALLY: Same calculation!                         â”‚
â”‚   The difference is in study design and interpretation.    â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“– Example 4: Treatment Effectiveness Across Hospitals

Three hospitals use different treatments. Do they have the same recovery rates?

```
                    â”‚ Recovered â”‚ Not Recovered â”‚ Total
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
    Hospital A      â”‚    80     â”‚      20       â”‚  100
    Hospital B      â”‚    90     â”‚      60       â”‚  150
    Hospital C      â”‚   130     â”‚      70       â”‚  200
    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
    Total           â”‚   300     â”‚     150       â”‚  450
```

### Solution

```
Hâ‚€: Recovery rates are the SAME across all hospitals
Hâ‚: Recovery rates DIFFER between hospitals
Î± = 0.05

Expected frequencies:
E = (Row Total Ã— Col Total) / 450

| Cell              | O   | E     | (O-E)Â²/E |
|-------------------|-----|-------|----------|
| A + Recovered     | 80  | 66.67 | 2.67     |
| A + Not Recovered | 20  | 33.33 | 5.33     |
| B + Recovered     | 90  | 100   | 1.00     |
| B + Not Recovered | 60  | 50    | 2.00     |
| C + Recovered     | 130 | 133.33| 0.08     |
| C + Not Recovered | 70  | 66.67 | 0.17     |
|-------------------|-----|-------|----------|
| Total             | 450 | 450   | Ï‡Â²=11.25 |

df = (3-1)(2-1) = 2
Ï‡Â²_critical (Î±=0.05, df=2) = 5.991
p-value â‰ˆ 0.0036

Ï‡Â² = 11.25 > 5.991 â†’ REJECT Hâ‚€

Conclusion: Recovery rates DIFFER significantly across hospitals.

Recovery Rates:
â€¢ Hospital A: 80/100 = 80%
â€¢ Hospital B: 90/150 = 60%
â€¢ Hospital C: 130/200 = 65%

Hospital A has significantly better outcomes!
```

---

## Critical Values Table

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                â”‚
â”‚   CHI-SQUARE CRITICAL VALUES                                    â”‚
â”‚                                                                â”‚
â”‚    df â”‚  Î±=0.10  â”‚  Î±=0.05  â”‚  Î±=0.025 â”‚  Î±=0.01  â”‚  Î±=0.001 â”‚
â”‚   â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚     1 â”‚   2.706  â”‚   3.841  â”‚   5.024  â”‚   6.635  â”‚  10.828  â”‚
â”‚     2 â”‚   4.605  â”‚   5.991  â”‚   7.378  â”‚   9.210  â”‚  13.816  â”‚
â”‚     3 â”‚   6.251  â”‚   7.815  â”‚   9.348  â”‚  11.345  â”‚  16.266  â”‚
â”‚     4 â”‚   7.779  â”‚   9.488  â”‚  11.143  â”‚  13.277  â”‚  18.467  â”‚
â”‚     5 â”‚   9.236  â”‚  11.070  â”‚  12.833  â”‚  15.086  â”‚  20.515  â”‚
â”‚     6 â”‚  10.645  â”‚  12.592  â”‚  14.449  â”‚  16.812  â”‚  22.458  â”‚
â”‚     7 â”‚  12.017  â”‚  14.067  â”‚  16.013  â”‚  18.475  â”‚  24.322  â”‚
â”‚     8 â”‚  13.362  â”‚  15.507  â”‚  17.535  â”‚  20.090  â”‚  26.124  â”‚
â”‚     9 â”‚  14.684  â”‚  16.919  â”‚  19.023  â”‚  21.666  â”‚  27.877  â”‚
â”‚    10 â”‚  15.987  â”‚  18.307  â”‚  20.483  â”‚  23.209  â”‚  29.588  â”‚
â”‚    15 â”‚  22.307  â”‚  24.996  â”‚  27.488  â”‚  30.578  â”‚  37.697  â”‚
â”‚    20 â”‚  28.412  â”‚  31.410  â”‚  34.170  â”‚  37.566  â”‚  45.315  â”‚
â”‚                                                                â”‚
â”‚   If Ï‡Â² > critical value â†’ REJECT Hâ‚€                          â”‚
â”‚                                                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Assumptions and Conditions

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   CONDITIONS FOR CHI-SQUARE TEST                             â”‚
â”‚                                                             â”‚
â”‚   1. RANDOM SAMPLE                                          â”‚
â”‚      Data must be randomly selected                         â”‚
â”‚                                                             â”‚
â”‚   2. INDEPENDENT OBSERVATIONS                               â”‚
â”‚      Each observation must be independent                   â”‚
â”‚      Each subject counted in only one cell                 â”‚
â”‚                                                             â”‚
â”‚   3. EXPECTED COUNT CONDITION                               â”‚
â”‚      All expected frequencies should be â‰¥ 5               â”‚
â”‚      (Some texts say â‰¥ 1 with 80% â‰¥ 5)                    â”‚
â”‚                                                             â”‚
â”‚   4. CATEGORICAL DATA                                       â”‚
â”‚      Variables must be categorical (not continuous)        â”‚
â”‚                                                             â”‚
â”‚   IF EXPECTED < 5:                                          â”‚
â”‚   â€¢ Combine categories if logical                          â”‚
â”‚   â€¢ Use Fisher's Exact Test (for 2Ã—2 tables)              â”‚
â”‚   â€¢ Use simulation-based methods                           â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Effect Size: CramÃ©r's V

### Measuring Strength of Association

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                             â”‚
â”‚   CRAMÃ‰R'S V                                                 â”‚
â”‚                                                             â”‚
â”‚   Measures the STRENGTH of association (effect size)       â”‚
â”‚   for chi-square test of independence/homogeneity          â”‚
â”‚                                                             â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                 â”‚
â”‚             â”‚     Ï‡Â²                                        â”‚
â”‚   V =      â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                  â”‚
â”‚           âˆš  n Ã— (k - 1)                                    â”‚
â”‚                                                             â”‚
â”‚   Where:                                                    â”‚
â”‚   â€¢ Ï‡Â² = chi-square statistic                              â”‚
â”‚   â€¢ n = total sample size                                  â”‚
â”‚   â€¢ k = min(rows, columns)                                 â”‚
â”‚                                                             â”‚
â”‚   INTERPRETATION:                                           â”‚
â”‚   V â‰ˆ 0.1: Small effect                                    â”‚
â”‚   V â‰ˆ 0.3: Medium effect                                   â”‚
â”‚   V â‰ˆ 0.5: Large effect                                    â”‚
â”‚                                                             â”‚
â”‚   Range: 0 (no association) to 1 (perfect association)     â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example: Smoking and Cancer Effect Size

```
Ï‡Â² = 75.63
n = 1000
k = min(2, 2) = 2

V = âˆš(75.63 / (1000 Ã— (2-1)))
  = âˆš(75.63 / 1000)
  = âˆš0.07563
  = 0.275

V â‰ˆ 0.28 â†’ Medium effect size

There's a moderately strong association between 
smoking and lung cancer.
```

---

## Chi-Square vs Other Tests

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚   WHEN TO USE WHAT?                                              â”‚
â”‚                                                                  â”‚
â”‚   CHI-SQUARE TEST:                                               â”‚
â”‚   â€¢ Categorical variables (counts/frequencies)                  â”‚
â”‚   â€¢ Comparing observed vs expected distributions               â”‚
â”‚   â€¢ Testing independence/homogeneity                           â”‚
â”‚                                                                  â”‚
â”‚   T-TEST / Z-TEST:                                               â”‚
â”‚   â€¢ Continuous variables (means)                                â”‚
â”‚   â€¢ Comparing group means                                       â”‚
â”‚                                                                  â”‚
â”‚   FISHER'S EXACT TEST:                                           â”‚
â”‚   â€¢ 2Ã—2 tables with small expected counts (< 5)               â”‚
â”‚   â€¢ More accurate than chi-square for small samples            â”‚
â”‚                                                                  â”‚
â”‚   MCNEMAR'S TEST:                                                â”‚
â”‚   â€¢ Paired categorical data (before/after)                     â”‚
â”‚   â€¢ Same subjects measured twice                                â”‚
â”‚                                                                  â”‚
â”‚   G-TEST (Likelihood Ratio):                                    â”‚
â”‚   â€¢ Alternative to chi-square                                   â”‚
â”‚   â€¢ Better for small samples or sparse data                    â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Python Implementation

### Complete Chi-Square Functions

```python
import numpy as np
from scipy import stats

def chi_square_goodness_of_fit(observed, expected=None, alpha=0.05):
    """
    Chi-Square Goodness of Fit Test
    
    Parameters:
    - observed: list/array of observed frequencies
    - expected: list/array of expected frequencies (default: equal)
    - alpha: significance level
    """
    observed = np.array(observed)
    n = observed.sum()
    k = len(observed)
    
    if expected is None:
        expected = np.array([n/k] * k)
    else:
        expected = np.array(expected)
    
    # Check condition
    if (expected < 5).any():
        print("âš ï¸ Warning: Some expected frequencies < 5")
    
    # Calculate chi-square
    chi_sq = np.sum((observed - expected)**2 / expected)
    
    # Degrees of freedom
    df = k - 1
    
    # p-value
    p_value = 1 - stats.chi2.cdf(chi_sq, df)
    
    # Critical value
    chi_critical = stats.chi2.ppf(1 - alpha, df)
    
    # Decision
    reject = chi_sq > chi_critical
    
    return {
        'chi_square': chi_sq,
        'df': df,
        'p_value': p_value,
        'chi_critical': chi_critical,
        'reject_null': reject,
        'observed': observed,
        'expected': expected
    }

# Example: Die fairness
observed = [89, 95, 105, 115, 108, 88]
result = chi_square_goodness_of_fit(observed)

print("=" * 50)
print("CHI-SQUARE GOODNESS OF FIT TEST")
print("=" * 50)
print(f"Observed: {result['observed']}")
print(f"Expected: {result['expected']}")
print(f"\nÏ‡Â² = {result['chi_square']:.4f}")
print(f"df = {result['df']}")
print(f"p-value = {result['p_value']:.4f}")
print(f"Critical value (Î±=0.05) = {result['chi_critical']:.4f}")
print(f"Decision: {'Reject Hâ‚€' if result['reject_null'] else 'Fail to reject Hâ‚€'}")
```

### Test of Independence

```python
import numpy as np
from scipy import stats

def chi_square_independence(contingency_table, alpha=0.05):
    """
    Chi-Square Test of Independence
    
    Parameters:
    - contingency_table: 2D array of observed frequencies
    - alpha: significance level
    """
    observed = np.array(contingency_table)
    rows, cols = observed.shape
    n = observed.sum()
    
    # Row and column totals
    row_totals = observed.sum(axis=1)
    col_totals = observed.sum(axis=0)
    
    # Expected frequencies
    expected = np.outer(row_totals, col_totals) / n
    
    # Check condition
    if (expected < 5).any():
        print("âš ï¸ Warning: Some expected frequencies < 5")
        print(f"   Cells with E < 5: {(expected < 5).sum()}")
    
    # Calculate chi-square
    chi_sq = np.sum((observed - expected)**2 / expected)
    
    # Degrees of freedom
    df = (rows - 1) * (cols - 1)
    
    # p-value
    p_value = 1 - stats.chi2.cdf(chi_sq, df)
    
    # Critical value
    chi_critical = stats.chi2.ppf(1 - alpha, df)
    
    # Effect size (CramÃ©r's V)
    cramers_v = np.sqrt(chi_sq / (n * (min(rows, cols) - 1)))
    
    # Decision
    reject = chi_sq > chi_critical
    
    return {
        'chi_square': chi_sq,
        'df': df,
        'p_value': p_value,
        'chi_critical': chi_critical,
        'cramers_v': cramers_v,
        'reject_null': reject,
        'observed': observed,
        'expected': expected
    }

# Example: Smoking and Lung Cancer
observed = np.array([
    [90, 210],   # Smoker: Cancer, No Cancer
    [60, 640]    # Non-Smoker: Cancer, No Cancer
])

result = chi_square_independence(observed)

print("\n" + "=" * 50)
print("CHI-SQUARE TEST OF INDEPENDENCE")
print("=" * 50)
print("Observed frequencies:")
print(result['observed'])
print("\nExpected frequencies:")
print(result['expected'].round(2))
print(f"\nÏ‡Â² = {result['chi_square']:.4f}")
print(f"df = {result['df']}")
print(f"p-value = {result['p_value']:.6f}")
print(f"Critical value (Î±=0.05) = {result['chi_critical']:.4f}")
print(f"CramÃ©r's V = {result['cramers_v']:.4f} (effect size)")
print(f"Decision: {'Reject Hâ‚€' if result['reject_null'] else 'Fail to reject Hâ‚€'}")

# Using scipy directly
chi2, p, dof, expected = stats.chi2_contingency(observed)
print(f"\nScipy verification: Ï‡Â²={chi2:.4f}, p={p:.6f}")
```

### Visualization

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

def visualize_chi_square(df_values=[1, 3, 5, 10], x_max=20):
    """Visualize chi-square distributions with different df"""
    
    fig, ax = plt.subplots(figsize=(12, 6))
    
    x = np.linspace(0.01, x_max, 500)
    
    for df in df_values:
        y = stats.chi2.pdf(x, df)
        ax.plot(x, y, linewidth=2, label=f'df = {df}')
    
    ax.set_xlabel('Ï‡Â²', fontsize=12)
    ax.set_ylabel('Probability Density', fontsize=12)
    ax.set_title('Chi-Square Distribution for Various Degrees of Freedom', fontsize=14)
    ax.legend()
    ax.grid(True, alpha=0.3)
    ax.set_xlim(0, x_max)
    ax.set_ylim(0, 0.5)
    
    plt.tight_layout()
    plt.show()

def visualize_test_result(chi_sq, df, alpha=0.05):
    """Visualize chi-square test result"""
    
    fig, ax = plt.subplots(figsize=(12, 6))
    
    chi_critical = stats.chi2.ppf(1 - alpha, df)
    x = np.linspace(0.01, max(chi_sq * 1.5, chi_critical * 1.5), 500)
    y = stats.chi2.pdf(x, df)
    
    # Plot distribution
    ax.plot(x, y, 'b-', linewidth=2, label=f'Ï‡Â² distribution (df={df})')
    ax.fill_between(x, y, alpha=0.1)
    
    # Rejection region
    x_reject = x[x >= chi_critical]
    y_reject = stats.chi2.pdf(x_reject, df)
    ax.fill_between(x_reject, y_reject, color='red', alpha=0.4, 
                    label=f'Rejection region (Î±={alpha})')
    
    # Critical value
    ax.axvline(chi_critical, color='red', linestyle='--', linewidth=1.5,
               label=f'Critical value = {chi_critical:.3f}')
    
    # Test statistic
    ax.axvline(chi_sq, color='green', linewidth=2.5,
               label=f'Ï‡Â² = {chi_sq:.3f}')
    
    # p-value
    p_value = 1 - stats.chi2.cdf(chi_sq, df)
    decision = "REJECT Hâ‚€" if chi_sq > chi_critical else "FAIL TO REJECT Hâ‚€"
    
    ax.set_xlabel('Ï‡Â²', fontsize=12)
    ax.set_ylabel('Density', fontsize=12)
    ax.set_title(f'Chi-Square Test Result: {decision}\np-value = {p_value:.4f}', fontsize=14)
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()

# Visualize
visualize_chi_square()
visualize_test_result(chi_sq=75.63, df=1)
```

---

## Common Mistakes to Avoid âš ï¸

### Mistake 1: Using Percentages Instead of Counts

```
âŒ WRONG: Using percentages or proportions in the table

âœ… CORRECT: Always use raw counts (frequencies)

Chi-square requires COUNTS, not percentages!
```

### Mistake 2: Ignoring Expected Count Condition

```
âŒ WRONG: Running chi-square when expected counts < 5

âœ… CORRECT: 
   â€¢ Combine categories
   â€¢ Use Fisher's Exact Test (for 2Ã—2)
   â€¢ Report the violation
```

### Mistake 3: Confusing Independence with No Effect

```
âŒ WRONG: "Chi-square proves smoking CAUSES cancer"

âœ… CORRECT: Chi-square shows ASSOCIATION, not causation

The test shows variables are related, but can't prove
one causes the other!
```

### Mistake 4: Using Chi-Square for Continuous Data

```
âŒ WRONG: Applying chi-square to continuous variables

âœ… CORRECT: Use t-test or ANOVA for continuous data

Chi-square is for categorical data only!
```

### Mistake 5: Dependent Observations

```
âŒ WRONG: Same person counted in multiple cells

âœ… CORRECT: Each subject appears in exactly ONE cell

If observations are paired/matched, use McNemar's test.
```

---

## Practice Problems ğŸ“

### Problem 1: Goodness of Fit
A bag claims to have equal numbers of red, blue, green, and yellow candies. You sample 200 candies: 60 red, 45 blue, 55 green, 40 yellow. At Î± = 0.05, is the claim accurate?

<details>
<summary>Click for Solution</summary>

```
Hâ‚€: Colors are equally distributed (25% each)
Hâ‚: Colors are not equally distributed
Î± = 0.05

Expected: 200 Ã— 0.25 = 50 for each color

| Color  | O  | E  | (O-E)Â²/E |
|--------|----|----|----------|
| Red    | 60 | 50 | 2.00     |
| Blue   | 45 | 50 | 0.50     |
| Green  | 55 | 50 | 0.50     |
| Yellow | 40 | 50 | 2.00     |
| Total  |200 |200 | Ï‡Â²= 5.00 |

df = 4 - 1 = 3
Ï‡Â²_critical (Î±=0.05, df=3) = 7.815
p-value â‰ˆ 0.172

Ï‡Â² = 5.00 < 7.815 â†’ FAIL TO REJECT Hâ‚€

Conclusion: Insufficient evidence to reject the claim 
that colors are equally distributed.
```

</details>

---

### Problem 2: Test of Independence
Is there a relationship between exercise frequency and stress level?

```
              â”‚ Low Stress â”‚ High Stress â”‚ Total
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
Never         â”‚     30     â”‚     70      â”‚  100
Sometimes     â”‚     50     â”‚     50      â”‚  100
Regular       â”‚     70     â”‚     30      â”‚  100
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€
Total         â”‚    150     â”‚    150      â”‚  300
```

<details>
<summary>Click for Solution</summary>

```
Hâ‚€: Exercise frequency and stress are independent
Hâ‚: Exercise frequency and stress are related
Î± = 0.05

Expected frequencies (each cell):
E = (Row Total Ã— Col Total) / 300 = (100 Ã— 150) / 300 = 50

| Cell              | O  | E  | (O-E)Â²/E |
|-------------------|----|----|----------|
| Never + Low       | 30 | 50 | 8.00     |
| Never + High      | 70 | 50 | 8.00     |
| Sometimes + Low   | 50 | 50 | 0.00     |
| Sometimes + High  | 50 | 50 | 0.00     |
| Regular + Low     | 70 | 50 | 8.00     |
| Regular + High    | 30 | 50 | 8.00     |
| Total             |300 |300 | Ï‡Â²=32.00 |

df = (3-1)(2-1) = 2
Ï‡Â²_critical (Î±=0.05, df=2) = 5.991
p-value < 0.0001

Ï‡Â² = 32.00 >> 5.991 â†’ REJECT Hâ‚€

Conclusion: There IS a significant relationship between 
exercise frequency and stress level.

â€¢ Never exercise: 70% high stress
â€¢ Regular exercise: 30% high stress

Regular exercise is associated with lower stress!
```

</details>

---

### Problem 3: Degrees of Freedom
For a 4Ã—3 contingency table, what are the degrees of freedom?

<details>
<summary>Click for Solution</summary>

```
df = (rows - 1) Ã— (columns - 1)
   = (4 - 1) Ã— (3 - 1)
   = 3 Ã— 2
   = 6

Answer: df = 6
```

</details>

---

### Problem 4: Effect Size
Given Ï‡Â² = 25, n = 400, for a 3Ã—3 table, calculate CramÃ©r's V and interpret it.

<details>
<summary>Click for Solution</summary>

```
V = âˆš(Ï‡Â² / (n Ã— (k - 1)))
  = âˆš(25 / (400 Ã— (3 - 1)))
  = âˆš(25 / 800)
  = âˆš0.03125
  = 0.177

V â‰ˆ 0.18

Interpretation: Small to medium effect size

There is a statistically significant but relatively 
weak association between the variables.
```

</details>

---

## Summary: The Essence of Chi-Square

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                  â”‚
â”‚                    CHI-SQUARE TEST                               â”‚
â”‚                    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                               â”‚
â”‚                                                                  â”‚
â”‚   THE FORMULA:                                                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚              (Observed - Expected)Â²                      â”‚   â”‚
â”‚   â”‚       Ï‡Â² = Î£ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                      â”‚   â”‚
â”‚   â”‚                   Expected                               â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â”‚   THREE TYPES:                                                   â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  1. Goodness of Fit: Does data match distribution?      â”‚   â”‚
â”‚   â”‚     df = k - 1                                          â”‚   â”‚
â”‚   â”‚                                                          â”‚   â”‚
â”‚   â”‚  2. Independence: Are two variables related?            â”‚   â”‚
â”‚   â”‚     df = (r-1)(c-1)                                     â”‚   â”‚
â”‚   â”‚                                                          â”‚   â”‚
â”‚   â”‚  3. Homogeneity: Same distribution across groups?       â”‚   â”‚
â”‚   â”‚     df = (r-1)(c-1)                                     â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                  â”‚
â”‚   CONDITIONS:                                                    â”‚
â”‚   â€¢ Random sample                                               â”‚
â”‚   â€¢ Independent observations                                     â”‚
â”‚   â€¢ Expected frequencies â‰¥ 5                                    â”‚
â”‚   â€¢ Categorical data                                            â”‚
â”‚                                                                  â”‚
â”‚   KEY INSIGHT:                                                   â”‚
â”‚   Large Ï‡Â² â†’ Observed very different from Expected             â”‚
â”‚           â†’ Evidence against Hâ‚€                                 â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Quick Reference Card

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CHI-SQUARE QUICK REFERENCE                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   FORMULA: Ï‡Â² = Î£ (O - E)Â² / E                                  â”‚
â”‚                                                                  â”‚
â”‚   EXPECTED (Independence):                                       â”‚
â”‚   E = (Row Total Ã— Col Total) / Grand Total                     â”‚
â”‚                                                                  â”‚
â”‚   DEGREES OF FREEDOM:                                            â”‚
â”‚   â€¢ Goodness of Fit: df = k - 1                                 â”‚
â”‚   â€¢ Independence/Homogeneity: df = (r-1)(c-1)                   â”‚
â”‚                                                                  â”‚
â”‚   CRITICAL VALUES (Î± = 0.05):                                    â”‚
â”‚   df=1: 3.841 â”‚ df=2: 5.991 â”‚ df=3: 7.815 â”‚ df=4: 9.488        â”‚
â”‚                                                                  â”‚
â”‚   EFFECT SIZE (CramÃ©r's V):                                      â”‚
â”‚   V = âˆš(Ï‡Â² / (n Ã— (k-1)))                                       â”‚
â”‚   Small: ~0.1 â”‚ Medium: ~0.3 â”‚ Large: ~0.5                      â”‚
â”‚                                                                  â”‚
â”‚   DECISION: Reject Hâ‚€ if Ï‡Â² > Ï‡Â²_critical                       â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

> **"The chi-square test is elegantly simple: compare what you observed to what you expected. If the difference is too large to be explained by chance, something interesting is going on!"**

From testing dice fairness to discovering medical associations, the chi-square test is the go-to tool for categorical data! ğŸ“Š

---

*From observed to expected, from counts to conclusions â€” that's the power of chi-square!* ğŸ²